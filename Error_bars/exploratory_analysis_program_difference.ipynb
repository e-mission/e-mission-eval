{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/kshankar/e-mission/gis_branch_tests')\n",
    "\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.core.wrapper.user as ecwu\n",
    "\n",
    "import confusion_matrix_handling as cm_handling\n",
    "from confusion_matrix_handling import MODE_MAPPING_DICT\n",
    "import get_EC\n",
    "import helper_functions as hf\n",
    "\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.feature_selection as skfs\n",
    "import sklearn.pipeline as skp\n",
    "import sklearn.preprocessing as skpr\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as sklm\n",
    "import sklearn.svm as sksvm\n",
    "\n",
    "METERS_TO_MILES = 0.000621371 # 1 meter = 0.000621371 miles\n",
    "\n",
    "df_EI = pd.read_csv(r'Public_Dashboard/auxiliary_files/energy_intensity.csv') # r stands for raw string, only matters if the path is on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "\n",
    "chosen_program = 'all'\n",
    "all_user_list = []\n",
    "programs_all = {}\n",
    "for u in edb.get_uuid_db().find():         # add users to proper locations in programs \n",
    "    program = u[\"user_email\"].split(\"_\")[0]    # This info is in the Stage_uuids collection of the database\n",
    "    uuid = u[\"uuid\"]\n",
    "    if program not in programs_all.keys(): programs_all[program] = []\n",
    "    programs_all[program].append(uuid)\n",
    "    all_user_list.append(uuid)\n",
    "\n",
    "user_list = programs_all[chosen_program] if chosen_program is not 'all' else all_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_map = {}\n",
    "\n",
    "for u in user_list:\n",
    "    profile = ecwu.User(u).getProfile()\n",
    "    if 'curr_platform' in profile:\n",
    "        os_map[u] = profile['curr_platform']\n",
    "    else:\n",
    "        print(\"Removed a user who had no OS information.\")\n",
    "        user_list.remove(u) # Note: this removes u from programs_all[chosen_program] as well.\n",
    "        no_os_user = u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all trips in the program specified earlier\n",
    "# Then expand user inputs.\n",
    "# You could instead load the file that \"place_all_trips_in_pkl.py\" generates\n",
    "# expanded_labeled_trips = hf.get_expanded_labeled_trips(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanded_labeled_trips.drop(['start_loc','end_loc'],axis = 1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What modes can we properly sense without substituting a \"close enough\" energy intensity?\n",
    "drove alone, walk, bike,bus,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base mode map for GIS. Not directly used in this notebook but nice to see.\n",
    "gis_sensed_modes = {0 : 'no_sensed',    # UNKNOWN  #NOTE: this is important info to mention.\n",
    "        1 : 'walking',    # WALKING\n",
    "        2 : 'bicycling',    # BICYCLING\n",
    "        3 : 'bus',        # BUS\n",
    "        4 : 'train',      # TRAIN\n",
    "        5 : 'car',        # CAR\n",
    "        6 : 'air_or_hsr', # AIR_OR_HSR\n",
    "        7 : 'subway',      # SUBWAY\n",
    "        8 : 'train',      # TRAM\n",
    "        9 : 'train',      # LIGHT_RAIL\n",
    "}\n",
    "\n",
    "# Get error related info\n",
    "unit_dist_MCS_df = pd.read_csv(\"unit_distance_MCS.csv\").set_index(\"moment\")\n",
    "#android_EI_moments_df = pd.read_csv(\"android_EI_moments.csv\").set_index(\"mode\")\n",
    "#ios_EI_moments_df = pd.read_csv(\"ios_EI_moments.csv\").set_index(\"mode\")\n",
    "\n",
    "# Dictionary of energy intensities in kWH/PMT\n",
    "energy_dict = cm_handling.get_energy_dict(df_EI)\n",
    "#%store -r energy_consumption_df # to save time\n",
    "\n",
    "# sensed_car (maps via MODE_MAPPING_DICT) -> “Gas Car, sensed” in energy dict, \n",
    "# which is used for the ground truth car intensity in get_conditional_EI_expectation_and_variance(). \n",
    "# Then the sensed mode will show car, but the EI used will be based on a car with a 1.5 person load factor.\n",
    "#drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "#load_factor = 1#1.5\n",
    "#energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/load_factor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe was generated in place_all_trips_in_pkl.py\n",
    "df = pd.read_pickle(\"/tmp/Sensing_sensitivity_analysis/expanded_labeled_trips.pickle\")\n",
    "expanded_labeled_trips = df.copy()#df[df['program'] == 'vail'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips = hf.drop_unwanted_trips(expanded_labeled_trips,drop_not_a_trip=False)\n",
    "\n",
    "expanded_labeled_trips = hf.get_primary_modes(expanded_labeled_trips,energy_dict,MODE_MAPPING_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out mode distance proportions for each program\n",
    "program_proportions = pd.DataFrame(columns=['program','r', 'drove_alone_distance', 'shared_ride_distance','car_proportion', 'ebike_proportion', 'walk_proportion', 'drove_alone_proportion', 'shared_ride_proportion'])\n",
    "for program in expanded_labeled_trips['program'].unique():\n",
    "    program_df = expanded_labeled_trips[expanded_labeled_trips['program'] == program].copy()\n",
    "    proportions = hf.get_ratios_for_dataset(program_df)\n",
    "    proportions.update({'program': program})\n",
    "    \n",
    "    # Append row of proportions to the dataframe\n",
    "    program_proportions = program_proportions.append(proportions, ignore_index=True)\n",
    "\n",
    "# Get the proportions for the full dataset\n",
    "proportions = hf.get_ratios_for_dataset(expanded_labeled_trips)\n",
    "proportions.update({'program': 'all'})\n",
    "program_proportions = program_proportions.append(proportions, ignore_index=True)\n",
    "\n",
    "program_proportions = program_proportions.set_index(\"program\")\n",
    "#print(program_proportions.round(3).to_markdown())  # pip install tabulate\n",
    "program_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "# if you forget this step, the error for expected may be different, \n",
    "# since you might be relying on a different saved version of the EI_moments_dataframe\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "\n",
    "energy_consumption_df = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)\n",
    "energy_consumption_df['distance_miles'] = energy_consumption_df.distance*METERS_TO_MILES\n",
    "# %store energy_consumption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1\n",
    "car_EI_load_divider = (r+1)/(r+0.5)  # aka Michael's definition of load factor.\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_EI_load_divider})\n",
    "program_df = expanded_labeled_trips[expanded_labeled_trips['program'] == '4c'].copy()\n",
    "\n",
    "\n",
    "EC_4c = get_EC.compute_all_EC_values(program_df,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most recent update:\n",
    "May want to look at primary mode normalized by distance rather than value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trip_modes = expanded_labeled_trips[['mode_confirm','section_modes','primary_mode']].copy()\n",
    "\n",
    "#for i,ct in all_trip_modes.iterrows():\n",
    "\n",
    "for mode in ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike']:\n",
    "    #n_user_labels = all_trip_modes['mode_confirm'].count(mode)\n",
    "    mode_df = all_trip_modes[all_trip_modes['mode_confirm'] == mode]\n",
    "    section_mode_distance_dict_given_user_label = {}\n",
    "    for i,ct in mode_df.iterrows():\n",
    "        section_modes = ct['section_modes']\n",
    "\n",
    "    print(mode)\n",
    "    print(mode_df.primary_mode.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drove_alone_4c_df = program_df[program_df['mode_confirm'] == 'drove_alone']\n",
    "drove_alone_outliers = hf.get_outliers(drove_alone_4c_df,'error_for_confusion',100,15)[['distance','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "#drove_alone_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ride_4c_df = program_df[program_df['mode_confirm'] == 'shared_ride']\n",
    "shared_ride_outliers_low = hf.get_outliers(shared_ride_4c_df,'error_for_confusion',100,15)[['distance','distance_miles','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "shared_ride_outliers_high = hf.get_outliers(shared_ride_4c_df,'error_for_confusion',85,0)[['distance','distance_miles','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "fig.set_figwidth(15)\n",
    "shared_ride_outliers_high.primary_mode.hist(ax = axs[0])\n",
    "shared_ride_outliers_low.primary_mode.hist(ax = axs[1])\n",
    "\n",
    "axs[0].set_title(\"4c shared ride overestimates primary modes (above 85th percentile)\")\n",
    "axs[1].set_title(\"4c shared ride underestimates primary modes(below 15th percentile)\")\n",
    "\n",
    "# most of the overestimates are car. (blue)\n",
    "# most of the unerestimates are walking, bicycling, and no sensed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ride_outliers_high.distance_miles.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drove_alone_outliers.primary_mode.hist()\n",
    "plt.title(\"4c drove alone outlier primary modes (below the 15th percentile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convenction below: <user label>_<primary mode>\n",
    "drove_alone_car = drove_alone_4c_df[drove_alone_4c_df.primary_mode == 'car']\n",
    "shared_ride_car = shared_ride_4c_df[shared_ride_4c_df.primary_mode == 'car']\n",
    "\n",
    "EI_used_for_android_sensed_car = 1.189540\n",
    "EI_used_for_android_walking = 0.010464\n",
    "EI_for_drove_alone = 1.51517707\n",
    "EI_for_shared_ride = 0.757588535\n",
    "drove_alone_car_distance = drove_alone_car.distance.sum()*METERS_TO_MILES\n",
    "shared_ride_car_distance = shared_ride_car.distance.sum()*METERS_TO_MILES\n",
    "\n",
    "# the outliers below 15% account for -2390 kWH\n",
    "drove_alone_outlier_error = drove_alone_outliers.error_for_confusion.sum()\n",
    "shared_ride_outliers_high_error = shared_ride_outliers_high.error_for_confusion.sum()\n",
    "shared_ride_outliers_low_error = shared_ride_outliers_low.error_for_confusion.sum()\n",
    "\n",
    "# the drove alone trips in 4c where the primary mode is car account for -1754 kWH of error.\n",
    "print(f\"Errors for drove alone and shared ride when we predict car: {drove_alone_car.error_for_confusion.sum():.2f}, {shared_ride_car.error_for_confusion.sum():.2f}\")\n",
    "print(f\"Drove alone outlier errors sum: {drove_alone_outlier_error:.2f}\")\n",
    "print(f\"Shared ride outlier error for upper outliers, lower outliers: {shared_ride_outliers_high_error:.2f}, {shared_ride_outliers_low_error:.2f}\")\n",
    "\n",
    "print(\"\\nMost of the outlier error for drove alone is from walking.\")\n",
    "print(f\"Difference between sensed walking and drove alone EI: {EI_used_for_android_walking - EI_for_drove_alone:.4f}\")\n",
    "\n",
    "print(\"\\nMost of the overestimation outlier error for shared ride is from sensed car.\")\n",
    "print(f\"Difference between sensed car and shared ride EI: {EI_used_for_android_sensed_car - EI_for_shared_ride:.4f}\")\n",
    "\n",
    "print(\"\\nMost of the underestimation outlier error for shared ride is from no_sensed and walking.\")\n",
    "print(f\"Difference between no_sensed and shared ride EI: {android_EI_moments_df['mean(EI)']['no_sensed'] - EI_for_shared_ride:.4f}\")\n",
    "print(f\"Difference between sensed walking and shared ride EI: {EI_used_for_android_walking - EI_for_shared_ride:.4f}\")\n",
    "print(\"In either case, when we mispredict drove alone, we are guaranteed to have a higher error than for a similar shared ride trip.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -r energy_consumption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the energy consumption percent error as a function of dataset characteristics\n",
    "Make sure you've calculated program proportions and energy consumption for the full dataset first.\n",
    "Before analysis, keep track of whether you dropped not a trips in the \"helper_functions.drop_unwanted_trips()\" call. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot energy consumption by user labeled mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()\n",
    "\n",
    "hf.plot_energy_consumption_by_mode(program_df,'4c')\n",
    "hf.plot_energy_consumption_by_mode(energy_consumption_df[energy_consumption_df['program'] == 'pc'].copy(),'nrelop')\n",
    "hf.plot_energy_consumption_by_mode(energy_consumption_df,'all CEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(energy_consumption_df.query('program == \"pc\" & mode_confirm == \"train\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\" & mode_confirm == \"bus\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\" & mode_confirm == \"shared_ride\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\" & mode_confirm == \"e_car_shared_ride\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\" & mode_confirm == \"pilot_ebike\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\" & mode_confirm == \"drove_alone\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\"').error_for_confusion.sum(),\n",
    " energy_consumption_df.query('program == \"pc\"').expected.sum(),\n",
    " energy_consumption_df.query('program == \"pc\"').user_labeled.sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\"').groupby(\"mode_confirm\").sum().error_for_confusion.abs().sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"pc\"').groupby(\"mode_confirm\").sum().error_for_confusion.abs().sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.plot_energy_consumption_by_mode(energy_consumption_df[energy_consumption_df['program'] == 'pc'].query('mode_confirm == [\"drove_alone\", \"shared_ride\", \"pilot_ebike\", \"not_a_trip\", \"walk\"]').copy(),'nrelop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & mode_confirm == \"pilot_ebike\"').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & mode_confirm == \"drove_alone\"').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & mode_confirm == \"shared_ride\"').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & mode_confirm == \"bus\"').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"shared_ride\" | mode_confirm == \"drove_alone\")').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]], energy_consumption_df.query('program == \"4c\" & mode_confirm == \"pilot_ebike\"').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"shared_ride\" | mode_confirm == \"drove_alone\")').groupby('primary_mode').sum()[[\"distance_miles\", \"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_error_modes = ['drove_alone', 'pilot_ebike', 'bus', 'shared_ride', 'taxi']\n",
    "energy_consumption_df.query('program == \"4c\" & mode_confirm == @big_error_modes').groupby('primary_mode').sum()[[\"error_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\"').error_for_confusion.sum(), energy_consumption_df.query('program == \"4c\"').user_labeled.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into separate sets to check for variations\n",
    "\n",
    "We are now going to try and see if we can determine the source of the variation across programs.\n",
    "\n",
    "Here are the features that we plan to try\n",
    "- drove_alone_2_shared_ride\n",
    "- no_sensed_ratio\n",
    "- not_a_trip_ratio\n",
    "- e_bike_ratio\n",
    "- car_like_ratio\n",
    "- car_like_as_not_car\n",
    "- e_bike_as_car\n",
    "- e_bike_as_not_bike\n",
    "- car_to_non_car_motorized_user_label\n",
    "- car_to_non_car_motorized_sensed\n",
    "- mispredicted_as_walk\n",
    "- mispredicted_as_car\n",
    "\n",
    "First, let's take the data we have now and split it into 10 parts with shuffling to create 10 fake distributions and see what happens to the error calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting without shuffling leads to some larger car to other ratios\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=2)  # some splits might not have any ebike\n",
    "\n",
    "# The naive KFold gives us 10 separate arrays with 4283 train and 476 test trips\n",
    "# But what we really want is 9 training sets of trips (to simulate the 9 programs for training)\n",
    "# and one test set of trips \n",
    "# Note that our features are for sets of trips, not individual trips\n",
    "for train_index, test_index in kf.split(energy_consumption_df):\n",
    "    print(len(train_index), len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple crossvalidation splitters in sklearn but all of them split into one training and one test set at a time\n",
    "# if we want to split into k-1 training sets and k test sets, we are gonna have to do it ourselves\n",
    "# New code suggestion from https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html\n",
    "def get_set_splits(n_rounds = 50, n_splits_per_round=10):\n",
    "    from numpy.random import default_rng\n",
    "    large_size_splits = []\n",
    "    for round in range(n_rounds):\n",
    "        rng = default_rng()\n",
    "        trip_index = np.array(energy_consumption_df.index.copy())\n",
    "        rng.shuffle(trip_index)\n",
    "        # print(energy_consumption_df.index, trip_index)\n",
    "        splits = np.array_split(trip_index, n_splits_per_round)\n",
    "        large_size_splits.append(splits)\n",
    "    large_size_splits = np.array(large_size_splits).flatten()\n",
    "    print([len(s) for s in large_size_splits])\n",
    "    return large_size_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First round and splitting and plotting the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = get_set_splits(n_rounds = 50, n_splits_per_round=10)\n",
    "split_result_list = []\n",
    "for s in splits:\n",
    "    ERROR_COLS = ['error_for_confusion',\n",
    "       'error_for_prediction', 'expected', 'predicted', 'user_labeled', 'distance_miles', 'distance', 'duration']\n",
    "    curr_split_result = {'count': len(s)}\n",
    "    for e in ERROR_COLS:\n",
    "        curr_split_result[e] = energy_consumption_df.loc[s][e].sum()\n",
    "    # print(curr_split_result)\n",
    "    # print(f\"CHECK user_labeled {energy_consumption_df.loc[s].user_labeled.sum()}\")\n",
    "    # print(f\"CHECK error_for_confusion {energy_consumption_df.loc[s].error_for_confusion.sum()}\")\n",
    "    split_result_list.append(curr_split_result)\n",
    "split_results = pd.DataFrame(split_result_list)\n",
    "split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results.plot(subplots=True, layout=(3,3), figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results['error_pct_for_confusion'] = (split_results.error_for_confusion / split_results.user_labeled ) * 100\n",
    "split_results['error_pct_for_prediction'] = (split_results.error_for_prediction / split_results.user_labeled) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results[[\"expected\", \"predicted\", \"user_labeled\", \"distance_miles\", \"error_pct_for_confusion\", \"error_pct_for_prediction\"]].plot(subplots=True, layout=(3,2), figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = split_results.plot.scatter(x=[\"distance_miles\", \"distance_miles\"], y=[\"expected\", \"user_labeled\"], c=['blue'] * 500 + ['green'] * 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = split_results.plot.scatter(x=\"distance_miles\", y=\"error_pct_for_confusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomputing with the potential other factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomputing with the other potential factors\n",
    "def get_split_results(splits):\n",
    "    CAR_LIKE_MODES = ['drove_alone', 'shared_ride', 'taxi']\n",
    "    NON_CAR_MOTORIZED_MODES = ['bus', 'free_shuttle', 'train']\n",
    "    split_result_list = []\n",
    "    for s in splits:\n",
    "        ERROR_COLS = ['error_for_confusion',\n",
    "           'error_for_prediction', 'expected', 'predicted', 'user_labeled', 'distance_miles', 'distance', 'duration']\n",
    "        curr_split_trips = energy_consumption_df.loc[s]\n",
    "        curr_split_result = {'count': len(s)}\n",
    "        for e in ERROR_COLS:\n",
    "            curr_split_result[e] = curr_split_trips[e].sum()\n",
    "        curr_split_result['drove_alone_2_shared_ride'] = curr_split_trips.query('mode_confirm == \"drove_alone\"').distance.sum() / curr_split_trips.query('mode_confirm == \"shared_ride\"').distance.sum()\n",
    "        curr_split_result['no_sensed_ratio'] = curr_split_trips.query('primary_mode == \"no_sensed\"').distance.sum() / curr_split_trips.distance.sum()\n",
    "        curr_split_result['car_like_ratio'] = curr_split_trips.query('mode_confirm == @CAR_LIKE_MODES').distance.sum() / curr_split_trips.distance.sum()        \n",
    "        curr_split_result['e_bike_ratio'] = curr_split_trips.query('mode_confirm == \"pilot_ebike\"').distance.sum() / curr_split_trips.distance.sum()\n",
    "        curr_split_result['not_a_trip_ratio'] = curr_split_trips.query('mode_confirm == \"not_a_trip\"').distance.sum() / curr_split_trips.distance.sum()\n",
    "        \n",
    "        curr_split_result['car_like_as_not_car'] = curr_split_trips.query('mode_confirm == @CAR_LIKE_MODES & primary_mode != \"car\"').distance.sum() / curr_split_trips.query('mode_confirm == @CAR_LIKE_MODES').distance.sum()\n",
    "        curr_split_result['e_bike_as_car'] = curr_split_trips.query('mode_confirm == \"pilot_ebike\" & primary_mode == \"car\"').distance.sum() / curr_split_trips.query('mode_confirm == \"pilot_ebike\"').distance.sum()\n",
    "        curr_split_result['e_bike_as_not_car_bike'] = curr_split_trips.query('mode_confirm == \"pilot_ebike\" & primary_mode != [\"car\", \"bicycling\"]').distance.sum() / curr_split_trips.query('mode_confirm == \"pilot_ebike\"').distance.sum()\n",
    "\n",
    "        curr_split_result['non_car_2_car_user_label'] = curr_split_trips.query('mode_confirm == @NON_CAR_MOTORIZED_MODES').distance.sum() / curr_split_trips.query('mode_confirm == @CAR_LIKE_MODES').distance.sum()\n",
    "        curr_split_result['non_car_2_car_sensed'] = curr_split_trips.query('primary_mode == [\"bus\", \"train\"]').distance.sum() / curr_split_trips.query('primary_mode == \"car\"').distance.sum()\n",
    "        curr_split_result['mispredicted_as_walk'] = curr_split_trips.query('mode_confirm != \"walk\" & primary_mode == \"walking\"').distance.sum() / curr_split_trips.distance.sum()\n",
    "        curr_split_result['mispredicted_as_car'] = curr_split_trips.query('mode_confirm != @CAR_LIKE_MODES & primary_mode == \"car\"').distance.sum() / curr_split_trips.distance.sum()\n",
    "    \n",
    "        # if curr_split_result['drove_alone_2_shared_ride'] > 0.5:\n",
    "            # print(f\"CHECK: drove_alone %s, shared_ride %s\" % (curr_split_trips.query('mode_confirm == \"drove_alone\"').distance_miles.sum(),\n",
    "            #                                                   curr_split_trips.query('mode_confirm == \"shared_ride\"').distance_miles.sum()))\n",
    "        # print(curr_split_result)\n",
    "        # print(f\"CHECK user_labeled {energy_consumption_df.loc[s].user_labeled.sum()}\")\n",
    "        # print(f\"CHECK error_for_confusion {energy_consumption_df.loc[s].error_for_confusion.sum()}\")\n",
    "        split_result_list.append(curr_split_result)\n",
    "    split_results = pd.DataFrame(split_result_list)\n",
    "    split_results['error_pct_for_confusion'] = (split_results.error_for_confusion / split_results.user_labeled ) * 100\n",
    "    split_results['error_pct_for_prediction'] = (split_results.error_for_prediction / split_results.user_labeled) * 100\n",
    "    return split_results\n",
    "\n",
    "split_results = get_split_results(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results[[\"non_car_2_car_sensed\", \"non_car_2_car_user_label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results[['drove_alone_2_shared_ride', 'no_sensed_ratio', 'not_a_trip_ratio', \"e_bike_ratio\", \"mispredicted_as_walk\", \"mispredicted_as_car\", \"distance_miles\", \"error_pct_for_confusion\", \"non_car_2_car_user_label\"]].plot(subplots=True, layout=(3,3), figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2d = plt.subplots(nrows=3, ncols=4, figsize=(8,8), sharey=True)\n",
    "fig.tight_layout(h_pad = 3)\n",
    "axarray = ax2d.flatten()\n",
    "IND_VAR = ['drove_alone_2_shared_ride', 'no_sensed_ratio', 'car_like_ratio', 'e_bike_ratio', 'not_a_trip_ratio',\n",
    "           \"car_like_as_not_car\", \"e_bike_as_car\", \"e_bike_as_not_car_bike\", \n",
    "           \"non_car_2_car_user_label\", \"mispredicted_as_walk\", \"mispredicted_as_car\", 'distance_miles']\n",
    "DEP_VAR = 'error_pct_for_confusion'\n",
    "for iv, ax in zip(IND_VAR, axarray):\n",
    "    split_results.plot(x=iv, y=DEP_VAR, ax=ax, kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = pd.Series({\"linear\": sklm.LinearRegression(), \"lasso\": sklm.Lasso(), \"ridge\": sklm.Ridge(),\n",
    "                       \"bayesian\": sklm.ARDRegression(), \"sgd\": sklm.SGDRegressor(),\n",
    "                        \"svm_linear\": sksvm.SVR(kernel=\"linear\"), \"NuSVR\": sksvm.NuSVR(kernel=\"linear\")})\n",
    "std_estimators = estimators.apply(lambda e: skp.Pipeline([(\"scale\", skpr.StandardScaler()), (\"reg\", e)]))\n",
    "selectors = std_estimators.apply(lambda e: skfs.RFECV(e, step=1, importance_getter=\"named_steps.reg.coef_\"))\n",
    "fitted_selectors = selectors.apply(lambda s: s.fit(split_results[IND_VAR], split_results[DEP_VAR]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_sel_features = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: np.array(IND_VAR)[fs.support_]), index=fitted_selectors.index); estimator_sel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR, pd.Series(fitted_selectors.loc['linear'].estimator_['reg'].coef_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator_grid_scores = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: fs.grid_scores_), index=fitted_selectors.index); estimator_grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid_scores.transpose().drop(columns=['sgd']).plot(kind=\"box\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid_scores.transpose().plot(kind=\"box\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid_scores.transpose().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(IND_VAR)[skfs.SelectPercentile(skfs.f_regression, percentile=0.9).fit(split_results[IND_VAR], split_results[DEP_VAR]).get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(IND_VAR)[skfs.SelectPercentile(skfs.mutual_info_regression, percentile=0.9).fit(split_results[IND_VAR], split_results[DEP_VAR]).get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.mode_confirm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how to represent feature selection results across multiple runs\n",
    "\n",
    "- each run may result in a separate set of selected features\n",
    "- we first determine the support (aka included/not) values for each feature\n",
    "- we convert them to numbers\n",
    "- we add the the numbers\n",
    "- if we divide by the numer of interations, then the closeness to 2 will indicate how often the feature was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_false_df = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: fs.support_), index=fitted_selectors.index, columns=IND_VAR); true_false_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_feature_df = true_false_df.applymap(lambda tf: int(tf)); int_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_feature_df + int_feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how to represent scores across runs\n",
    "\n",
    "- each run will result in 6 scores per estimator\n",
    "- we can create a dataframe where the columns are the estimators and the rows are the scores\n",
    "- for each run, we just append the scores to the dataframe and then reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid_scores.transpose().append(estimator_grid_scores.transpose()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how to represent coefficients across runs\n",
    "\n",
    "For each run, we will presumably get the coefficients for only the last run. For the algorithms with stable results, this won't matter. We can have the rows as the algorithms and the columns as the features or vice versa, but we will need to have multiple rows, one for each run.\n",
    "\n",
    "Let's have the columns be the features, and the rows be the algo, run combinations.\n",
    "\n",
    "Some complications:\n",
    "- the SVM coefficients are in a 2-D array, but we can flatten them\n",
    "- we only get coeffiecients for the features that are meaningful?\n",
    "\n",
    "```\n",
    "drove_alone_2_shared_ride \tno_sensed_ratio \tnot_a_trip_ratio \te_bike_ratio \tmispredicted_as_walk \tmispredicted_as_car \tdistance_miles\n",
    "\n",
    "linear \tTrue \tTrue \tTrue \tFalse \tTrue \tTrue \tFalse\n",
    "linear \t-1.765813e+01 \t-5.202422e+01 \t99.113221 \t124.429262 \t46.013267 \tNaN\n",
    "\n",
    "or \n",
    "\n",
    "sgd \tTrue \tFalse \tFalse \tFalse \tFalse \tFalse \tTrue\n",
    "sgd \t-2.047909e+10 \t-7.597053e+10 \tNaN \tNaN \tNaN \tNaN\n",
    "\n",
    "or\n",
    "\n",
    "svm_linear \tTrue \tTrue \tTrue \tTrue \tFalse \tTrue \tFalse\n",
    "svm_linear \t-1.449385e+01 \t-6.055291e+00 \t4.868629 \t6.639475 \t9.626487 \tNaN\n",
    "```\n",
    "\n",
    "So we need to find the support, find the dicts by zipping and then create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_selectors['linear'].estimator_.coef_, np.pad(fitted_selectors['linear'].estimator_.coef_.copy(), (0,len(IND_VAR) - len(fitted_selectors['linear'].estimator_.coef_)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_selectors['svm_linear'].estimator_['reg'].coef_, np.pad(fitted_selectors['linear'].estimator_['reg'].coef_.copy(), (0,len(IND_VAR) - len(fitted_selectors['linear'].estimator_['reg'].coef_)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_selectors.apply(lambda fs: fs.estimator_['reg'].coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: fs.estimator_['reg'].coef_.flatten()), index=fitted_selectors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(np.array(IND_VAR)[fitted_selectors['svm_linear'].support_],fitted_selectors['svm_linear'].estimator_['reg'].coef_.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_coef = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: dict(zip(np.array(IND_VAR)[fs.support_], fs.estimator_['reg'].coef_.flatten()))), index=fitted_selectors.index); estimator_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_coef['run'] = [1] * len(estimator_coef); estimator_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_coef.loc[['svm_linear', 'NuSVR']].plot(kind=\"box\", figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figured it all out, starting the runs now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the splits first just in case we want to do something standard with them\n",
    "# TODO: Set a random seed\n",
    "\n",
    "split_reps = []\n",
    "for repetition in range(10):\n",
    "    splits = get_set_splits(n_rounds=50, n_splits_per_round=10)\n",
    "    split_reps.append(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    for run_2 in range(run, 10):\n",
    "        print(f\"Comparing {run} and {run_2}\")\n",
    "        if np.array_equal(split_reps[run][0], split_reps[run_2][0]):\n",
    "            print(f\"CHECK: split indices at index 0 for {run} and {run_2} are the same!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_int_feature_df = None\n",
    "all_estimator_grid_scores = None\n",
    "all_estimator_coef = None\n",
    "\n",
    "for run, splits in enumerate(split_reps):\n",
    "    # Get the split\n",
    "    print(f\"Running run {run} with {len(splits)} size\")\n",
    "    split_results = get_split_results(splits)\n",
    "    \n",
    "    # Creating new estimators and selectors\n",
    "    estimators = pd.Series({\"linear\": sklm.LinearRegression(), \"ridge\": sklm.Ridge(),\n",
    "                \"bayesian\": sklm.ARDRegression(),\n",
    "                \"svm_linear\": sksvm.SVR(kernel=\"linear\")})\n",
    "    print(f\"Created new estimators {len(estimators)}\")\n",
    "    std_estimators = estimators.apply(lambda e: skp.Pipeline([(\"scale\", skpr.StandardScaler()), (\"reg\", e)]))\n",
    "    print(f\"After combining with the pipeline {len(std_estimators)} \")\n",
    "    selectors = std_estimators.apply(lambda e: skfs.RFECV(e, step=1, importance_getter=\"named_steps.reg.coef_\"))\n",
    "    print(\"Created selectors, about to fit them\")\n",
    "\n",
    "    \n",
    "    # Fit the selectors\n",
    "    fitted_selectors = selectors.apply(lambda s: s.fit(split_results[IND_VAR], split_results[DEP_VAR]))\n",
    "    print(\"Finished fitting selectors, about to generate results\")\n",
    "    \n",
    "    # Combine the feature selection\n",
    "    curr_true_false_df = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: fs.support_), index=fitted_selectors.index, columns=IND_VAR)\n",
    "    curr_int_feature_df = curr_true_false_df.applymap(lambda tf: int(tf))\n",
    "    all_int_feature_df = curr_int_feature_df if all_int_feature_df is None else all_int_feature_df + curr_int_feature_df\n",
    "\n",
    "    # Combine the grid scores\n",
    "    curr_estimator_grid_scores = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: fs.grid_scores_), index=fitted_selectors.index).transpose()\n",
    "    curr_estimator_grid_scores['run'] = [run] * len(curr_estimator_grid_scores)\n",
    "    all_estimator_grid_scores = curr_estimator_grid_scores if all_estimator_grid_scores is None else all_estimator_grid_scores.append(curr_estimator_grid_scores)\n",
    "    \n",
    "    # Combine the coefficients\n",
    "    curr_estimator_coef = pd.DataFrame.from_records(fitted_selectors.apply(lambda fs: dict(zip(np.array(IND_VAR)[fs.support_], fs.estimator_['reg'].coef_.flatten()))), index=fitted_selectors.index)\n",
    "    curr_estimator_coef['run'] = [run] * len(curr_estimator_coef)\n",
    "    all_estimator_coef = curr_estimator_coef if all_estimator_coef is None else all_estimator_coef.append(curr_estimator_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_int_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_int_feature_df/10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, squeeze=True, figsize=(12,6))\n",
    "all_int_feature_df.transpose().plot(kind=\"bar\", ax=ax[0][0])\n",
    "all_int_feature_df.plot(kind=\"box\", ax=ax[0][1], rot=90)\n",
    "(all_int_feature_df/10).mean().plot(kind=\"bar\", ax=ax[1][0])\n",
    "all_int_feature_df.plot(kind=\"bar\", ax=ax[1][1])\n",
    "ax[1][1].hlines(y=5,xmin=-1,xmax=len(all_int_feature_df))\n",
    "ax[1][1].legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get three sets of feature selections\n",
    "\n",
    "- Only 10: drove_alone_2_shared_ride, car_like_ratio, car_like_as_not_car, e_bike_as_car, non_car_2_car_user_label, mispredicted_as_walk\n",
    "- All over 50%: drop e_bike_as_not_car_bike, distance_miles\n",
    "- Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_grid_scores.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_grid_scores.drop(columns='run').plot(kind=\"box\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_coef.loc[[\"svm_linear\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator_coef.loc[[\"svm_linear\"]].drop(columns=[\"mispredicted_as_walk\", \"distance_miles\", \"non_car_2_car_user_label\", \"run\"]).plot(kind=\"box\", rot=90, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we know that the svm family of estimators works well, let's try some non-linear models as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = pd.Series({\"svm_linear\": sksvm.SVR(kernel=\"linear\"), \"svm_poly\": sksvm.SVR(kernel=\"poly\"), \"svm_rbf\": sksvm.SVR(kernel=\"rbf\"),\n",
    "                        \"NuSVR_linear\": sksvm.NuSVR(kernel=\"linear\"), \"NuSVR_poly\": sksvm.NuSVR(kernel=\"poly\"), \"NuSVR_rbf\": sksvm.NuSVR(kernel=\"rbf\")})\n",
    "std_estimators = estimators.apply(lambda e: skp.Pipeline([(\"scale\", skpr.StandardScaler()), (\"reg\", e)]))\n",
    "split_results = get_split_results(split_reps[0])\n",
    "training_set = split_results.sample(frac=0.8)\n",
    "test_set = split_results.drop(labels=training_set.index)\n",
    "fitted_estimators = std_estimators.apply(lambda e: e.fit(training_set[IND_VAR], training_set[DEP_VAR]))\n",
    "scores = fitted_estimators.apply(lambda e: e.score(test_set[IND_VAR], test_set[DEP_VAR]))\n",
    "# coef = fitted_estimators[[\"svm_linear\", \"NuSVR_linear\"]].apply(lambda e: e.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame().append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(coef.loc[\"svm_linear\"].flatten()), len(IND_VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold5 = skm.KFold()\n",
    "\n",
    "all_svm_kernel_scores = pd.DataFrame()\n",
    "\n",
    "for run, split in enumerate(split_reps):\n",
    "    print(f\"About to run manual k-fold validation for run {run}\")\n",
    "    estimators = pd.Series({\"svm_linear\": sksvm.SVR(kernel=\"linear\"), \"svm_poly\": sksvm.SVR(kernel=\"poly\"), \"svm_rbf\": sksvm.SVR(kernel=\"rbf\"),\n",
    "                        \"NuSVR_linear\": sksvm.NuSVR(kernel=\"linear\"), \"NuSVR_poly\": sksvm.NuSVR(kernel=\"poly\"), \"NuSVR_rbf\": sksvm.NuSVR(kernel=\"rbf\")})\n",
    "    std_estimators = estimators.apply(lambda e: skp.Pipeline([(\"scale\", skpr.StandardScaler()), (\"reg\", e)]))\n",
    "    print(f\"Finished creating estimators for run {run}, about to featurize\")\n",
    "    split_results = get_split_results(split)\n",
    "    print(f\"Finished featurizing for run {run}, about to run cross-validation\")\n",
    "    for train_index, test_index in fold5.split(split_results):\n",
    "        print(f\"Split features into training {len(train_index)} and test {len(test_index)}\")\n",
    "        training_set = split_results.loc[train_index]\n",
    "        test_set = split_results.loc[test_index]\n",
    "        fitted_estimators = std_estimators.apply(lambda e: e.fit(training_set[IND_VAR], training_set[DEP_VAR]))\n",
    "        scores = fitted_estimators.apply(lambda e: e.score(test_set[IND_VAR], test_set[DEP_VAR]))\n",
    "        all_svm_kernel_scores = all_svm_kernel_scores.append(scores, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_svm_kernel_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_svm_kernel_scores.plot(kind=\"box\", grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_svm_kernel_scores.drop(columns=[\"NuSVR_poly\", \"svm_poly\"]).plot(kind=\"box\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the final estimator and then apply it to the individual programs\n",
    "\n",
    "I was going to apply it to the coefficients from this prior estimation, but it turns out that `GridSearchCV` makes it easier. It has a `best_estimator_` field and we can just apply the programs to the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR_OVER_HALF = IND_VAR.copy()\n",
    "IND_VAR_OVER_HALF.remove(\"e_bike_as_not_car_bike\")\n",
    "IND_VAR_OVER_HALF.remove(\"distance_miles\")\n",
    "\n",
    "IND_VAR_PERFECT_10 = [\"drove_alone_2_shared_ride\", \"car_like_ratio\", \"car_like_as_not_car\", \"e_bike_as_car\", \"non_car_2_car_user_label\", \"mispredicted_as_walk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters = {'svm__kernel': ('linear', 'rbf', 'sigmoid'), 'svm__C':[1, 10, 100], 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[0])\n",
    "clf.fit(split_results[IND_VAR], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_feature_check_results = pd.DataFrame(clf.cv_results_); all_feature_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_feature_check_results.mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(all_feature_check_results.params.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_check_results.query(\"mean_test_score > -10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_feature_check_results.query(\"mean_test_score >= -10\").mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(all_feature_check_results.query(\"mean_test_score >= -10\").params.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_feature_check_results.query(\"rank_test_score == 1\").mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(all_feature_check_results.query(\"rank_test_score == 1\").params.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'svm__kernel': ('linear', 'rbf', 'sigmoid'), 'svm__C':[1, 10, 100], 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[0])\n",
    "clf.fit(split_results[IND_VAR_OVER_HALF], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_half_feature_check_results = pd.DataFrame(clf.cv_results_); over_half_feature_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = over_half_feature_check_results.query(\"rank_test_score == 1\").mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(over_half_feature_check_results.query(\"rank_test_score == 1\").params.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'svm__kernel': ('linear', 'rbf', 'sigmoid'), 'svm__C':[1, 10, 30], 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[0])\n",
    "clf.fit(split_results[IND_VAR_PERFECT_10], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_10_feature_check_results = pd.DataFrame(clf.cv_results_); perfect_10_feature_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = perfect_10_feature_check_results.query(\"rank_test_score == 1\").mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(perfect_10_feature_check_results.query(\"rank_test_score == 1\").params.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_PERFECT_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final retraining, picking the split that resulted in the median and dropping unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the split which resulted in the median value for svm_linear\n",
    "print(all_svm_kernel_scores.svm_linear.median(), all_svm_kernel_scores.svm_linear.quantile(interpolation=\"nearest\"))\n",
    "median_row = all_svm_kernel_scores[all_svm_kernel_scores.svm_linear == all_svm_kernel_scores.svm_linear.quantile(interpolation=\"nearest\")]\n",
    "median_index = median_row.index.tolist()[0]\n",
    "print(median_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_reps_indices = np.split(np.array(range(0,len(all_svm_kernel_scores))), len(split_reps))\n",
    "for i, sri in enumerate(split_reps_indices):\n",
    "    if median_index in sri:\n",
    "        median_split_reps_index = i\n",
    "        \n",
    "print(median_split_reps_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR_FINAL = IND_VAR_OVER_HALF\n",
    "parameters = {'svm__C':range(1, 20, 2), 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[median_split_reps_index])\n",
    "clf.fit(split_results[IND_VAR_FINAL], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_check_results = pd.DataFrame(clf.cv_results_); second_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = second_check_results.mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(second_check_results.params.tolist())\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's create splits for the actual programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_splits_series = energy_consumption_df.groupby(\"program\").apply(lambda g: g.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results = get_split_results(program_specific_splits_series.values).set_index(program_specific_splits_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[IND_VAR_FINAL+[DEP_VAR]].plot(kind=\"bar\", subplots=True, layout=(3,4), sharex=True, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[\"predicted_error_pct_for_confusion\"] = clf.predict(program_specific_split_results[IND_VAR_FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[[\"error_pct_for_confusion\", \"predicted_error_pct_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(program_specific_split_results[IND_VAR_FINAL], program_specific_split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results[[\"drove_alone_2_shared_ride\", \"no_sensed_ratio\", \"not_a_trip_ratio\", \"mispredicted_as_walk\"]].plot(subplots=True, layout=(2,2), figsize=(6,6), sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_.coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"4c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_.coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"prepilot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_.coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"vail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\"').groupby(\"mode_confirm\").sum().error_for_confusion.abs().sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"prepilot\"').groupby(\"mode_confirm\").sum().error_for_confusion.abs().sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby('mode_confirm').sum()[[\"expected\", \"user_labeled\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = energy_consumption_df.query('program == \"prepilot\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby('mode_confirm').sum()[[\"expected\", \"user_labeled\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\"').groupby(\"mode_confirm\").sum()['distance_miles'].sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"prepilot\"').groupby(\"mode_confirm\").sum()['distance_miles'].sort_values().tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\"]].plot(kind=\"bar\")\n",
    "ax1 = energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"error_for_confusion\"]].plot(kind=\"bar\")\n",
    "ax, ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label_ec_4c = energy_consumption_df.query('program == \"4c\"').user_labeled.sum(); user_label_ec_4c\n",
    "user_label_ec_prepilot = energy_consumption_df.query('program == \"prepilot\"').user_labeled.sum(); user_label_ec_prepilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"4c\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\", \"error_for_confusion\"]] / user_label_ec_4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"prepilot\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\", \"error_for_confusion\"]] / user_label_ec_prepilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = energy_consumption_df.query('program == \"prepilot\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = energy_consumption_df.query('program == \"vail\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.query('program == \"vail\" & (mode_confirm == \"pilot_ebike\" | mode_confirm == \"drove_alone\" | mode_confirm == \"shared_ride\")').groupby(['mode_confirm', 'primary_mode']).sum()[[\"expected\", \"user_labeled\", \"error_for_confusion\"]] / user_label_ec_prepilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's bootstrap by creating splits with re-shuffling\n",
    "\n",
    "Before this, we have splits of 500 x 120, representing 500 fake programs with 120 trips per program\n",
    "But our actual program sizes are in the 1000s. So let's create programs of 6000 trips each, which is \n",
    "If we reshuffle and re-generate 10 times, we will end up with 100 fake programs of 6000 trips each\n",
    "\n",
    "Let's try to work with that instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_set_splits(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_size_splits = []\n",
    "for round in range(50):\n",
    "    large_size_splits.append(get_set_splits(n_splits=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_size_splits = np.array(large_size_splits).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results = get_split_results(large_size_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results[[\"drove_alone_2_shared_ride\", \"no_sensed_ratio\", \"not_a_trip_ratio\", \"mispredicted_as_walk\", 'misrepresented_car_like_as_no_sensed', 'non_car_2_car_user_label', 'e_bike_ratio', \"car_like_ratio\", 'error_pct_for_confusion']].plot(subplots=True, layout=(3,3), figsize=(12,12), sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR_FINAL = IND_VAR.copy() + ['misrepresented_car_like_as_no_sensed', 'car_like_ratio']\n",
    "IND_VAR_FINAL.remove('distance_miles')\n",
    "parameters = {'svm__C':range(1, 30, 2), 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[median_split_reps_index])\n",
    "clf.fit(split_results[IND_VAR_FINAL], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_check_results = pd.DataFrame(clf.cv_results_); third_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = third_check_results.mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(third_check_results.params.tolist())\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results = get_split_results(program_specific_splits_series.values).set_index(program_specific_splits_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.predict(program_specific_split_results[IND_VAR_FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[\"predicted_error_pct_for_confusion\"] = clf.best_estimator_.predict(program_specific_split_results[IND_VAR_FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[[\"error_pct_for_confusion\", \"predicted_error_pct_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"4c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"vail\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrying after removing the `mispredicted_as_car` as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_VAR_FINAL = IND_VAR.copy() + ['misrepresented_car_like_as_no_sensed', 'car_like_ratio']\n",
    "IND_VAR_FINAL.remove('distance_miles')\n",
    "IND_VAR_FINAL.remove('mispredicted_as_car')\n",
    "parameters = {'svm__C':range(7, 30, 2), 'svm__gamma': ('scale', 'auto')}\n",
    "svr = skp.Pipeline([(\"scaler\", skpr.StandardScaler()), (\"svm\", sksvm.SVR(kernel='linear'))])\n",
    "clf = skm.GridSearchCV(svr, parameters, verbose=2)\n",
    "split_results = get_split_results(split_reps[median_split_reps_index])\n",
    "clf.fit(split_results[IND_VAR_FINAL], split_results[DEP_VAR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_check_results = pd.DataFrame(clf.cv_results_); fourth_check_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fourth_check_results.mean_test_score.plot(kind=\"bar\")\n",
    "ax.set_xticklabels(fourth_check_results.params.tolist())\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.predict(program_specific_split_results[IND_VAR_FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[\"predicted_error_pct_for_confusion\"] = clf.best_estimator_.predict(program_specific_split_results[IND_VAR_FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_specific_split_results[[\"error_pct_for_confusion\", \"predicted_error_pct_for_confusion\"]].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.best_estimator_['svm'].coef_.flatten(), index=IND_VAR_FINAL) * program_specific_split_results[IND_VAR_FINAL].loc[\"4c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "73ac5b45931ab4dd3f8e07a8d0e5daf0146eed4821bf42374f6ac6fa4af28c83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
