{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uuid import UUID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/mallen2/alternate_branches/eval-compatible-server/e-mission-server')\n",
    "\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.decorations.trip_queries as esdtq\n",
    "import emission.core.wrapper.user as ecwu\n",
    "\n",
    "import confusion_matrix_handling as cm_handling\n",
    "from confusion_matrix_handling import MODE_MAPPING_DICT\n",
    "import get_EC\n",
    "import helper_functions as hf\n",
    "\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "\n",
    "METERS_TO_MILES = 0.000621371 # 1 meter = 0.000621371 miles\n",
    "\n",
    "df_EI = pd.read_csv(r'Public_Dashboard/auxiliary_files/energy_intensity.csv') # r stands for raw string, only matters if the path is on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "\n",
    "chosen_program = 'all'\n",
    "all_user_list = []\n",
    "programs_all = {}\n",
    "for u in edb.get_uuid_db().find():         # add users to proper locations in programs \n",
    "    program = u[\"user_email\"].split(\"_\")[0]    # This info is in the Stage_uuids collection of the database\n",
    "    uuid = u[\"uuid\"]\n",
    "    if program not in programs_all.keys(): programs_all[program] = []\n",
    "    programs_all[program].append(uuid)\n",
    "    all_user_list.append(uuid)\n",
    "\n",
    "user_list = programs_all[chosen_program] if chosen_program is not 'all' else all_user_list\n",
    "os_map = {}\n",
    "\n",
    "for u in user_list:\n",
    "    profile = ecwu.User(u).getProfile()\n",
    "    if 'curr_platform' in profile:\n",
    "        os_map[u] = profile['curr_platform']\n",
    "    else:\n",
    "        print(\"Removed a user who had no OS information.\")\n",
    "        user_list.remove(u) # Note: this removes u from programs_all[chosen_program] as well.\n",
    "        no_os_user = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all trips in the program specified earlier\n",
    "# Then expand user inputs.\n",
    "# You could instead load the file that \"place_all_trips_in_pkl.py\" generates\n",
    "expanded_labeled_trips = hf.get_expanded_labeled_trips(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we sense air_or_hsr, what are the trips like?\n",
    "sensed_modes_list = []\n",
    "user_modes_list = []\n",
    "section_lengths_list = []\n",
    "air_lengths_list = []\n",
    "\n",
    "for i,ct in expanded_labeled_trips.iterrows():\n",
    "    if len(ct['section_modes']) ==0: continue\n",
    "    if (\"air_or_hsr\" in ct['section_modes']) and (ct['mode_confirm'] != 'air') :\n",
    "        sensed_modes_list.append(ct['section_modes'])\n",
    "        user_modes_list.append(ct['mode_confirm'])\n",
    "        section_lengths_list.append(ct['section_distances'])\n",
    "\n",
    "        air_position = ct['section_modes'].index('air_or_hsr')\n",
    "\n",
    "        air_lengths_list.append(ct['section_distances'][air_position])\n",
    "\n",
    "sensed_air_df = pd.DataFrame({\"sensed_sections\": sensed_modes_list, \"mode_confirm\": user_modes_list, \"air_length\":air_lengths_list,\"section_lengths\": section_lengths_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensed_air_df['air_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What modes can we properly sense without substituting a \"close enough\" energy intensity?\n",
    "drove alone, walk, bike,bus,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.mode_confirm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base mode map for GIS. Not directly used in this notebook but nice to see.\n",
    "gis_sensed_modes = {0 : 'no_sensed',    # UNKNOWN  #NOTE: this is important info to mention.\n",
    "        1 : 'walking',    # WALKING\n",
    "        2 : 'bicycling',    # BICYCLING\n",
    "        3 : 'bus',        # BUS\n",
    "        4 : 'train',      # TRAIN\n",
    "        5 : 'car',        # CAR\n",
    "        6 : 'air_or_hsr', # AIR_OR_HSR\n",
    "        7 : 'subway',      # SUBWAY\n",
    "        8 : 'train',      # TRAM\n",
    "        9 : 'train',      # LIGHT_RAIL\n",
    "}\n",
    "\n",
    "# Get error related info\n",
    "unit_dist_MCS_df = pd.read_csv(\"unit_distance_MCS.csv\").set_index(\"moment\")\n",
    "#android_EI_moments_df = pd.read_csv(\"android_EI_moments.csv\").set_index(\"mode\")\n",
    "#ios_EI_moments_df = pd.read_csv(\"ios_EI_moments.csv\").set_index(\"mode\")\n",
    "\n",
    "# Dictionary of energy intensities in kWH/PMT\n",
    "energy_dict = cm_handling.get_energy_dict(df_EI)\n",
    "#%store -r energy_consumption_df # to save time\n",
    "\n",
    "# sensed_car (maps via MODE_MAPPING_DICT) -> “Gas Car, sensed” in energy dict, \n",
    "# which is used for the ground truth car intensity in get_conditional_EI_expectation_and_variance(). \n",
    "# Then the sensed mode will show car, but the EI used will be based on a car with a 1.5 person load factor.\n",
    "#drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "#load_factor = 1#1.5\n",
    "#energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/load_factor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe was generated in place_all_trips_in_pkl.py\n",
    "df = pd.read_pickle(\"/Users/mallen2/OpenPATH_Data/Sensing_sensitivity_analysis/expanded_labeled_trips.pickle\")\n",
    "expanded_labeled_trips = df.copy()#df[df['program'] == 'vail'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips = hf.drop_unwanted_trips(expanded_labeled_trips,drop_not_a_trip=False)\n",
    "\n",
    "# to double check when you're working later: 'not_a_trip' in expanded_labeled_trips.mode_confirm.unique()\n",
    "\n",
    "expanded_labeled_trips = hf.get_primary_modes(expanded_labeled_trips,energy_dict,MODE_MAPPING_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out mode distance proportions for each program\n",
    "program_proportions = pd.DataFrame(columns=['program','r', 'drove_alone_distance', 'shared_ride_distance','car_proportion', 'ebike_proportion', 'walk_proportion', 'drove_alone_proportion', 'shared_ride_proportion'])\n",
    "for program in expanded_labeled_trips['program'].unique():\n",
    "    program_df = expanded_labeled_trips[expanded_labeled_trips['program'] == program].copy()\n",
    "    proportions = hf.get_ratios_for_dataset(program_df)\n",
    "    proportions.update({'program': program})\n",
    "    \n",
    "    # Append row of proportions to the dataframe\n",
    "    program_proportions = program_proportions.append(proportions, ignore_index=True)\n",
    "\n",
    "# Get the proportions for the full dataset\n",
    "proportions = hf.get_ratios_for_dataset(expanded_labeled_trips)\n",
    "proportions.update({'program': 'all'})\n",
    "program_proportions = program_proportions.append(proportions, ignore_index=True)\n",
    "\n",
    "program_proportions = program_proportions.set_index(\"program\")\n",
    "#print(program_proportions.round(3).to_markdown())  # pip install tabulate\n",
    "program_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the confusion matrix to compute energy intensity expected values and variances given the predicted mode\n",
    "New approach for using the confusion matrix: update probability of mode x based on what we predict.\n",
    "To use the old approach, use get_conditional_EI_expectation_and_variance instead. This directly uses the columns for conditional distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the covariance between EI and length?\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "no_nan = expanded_labeled_trips[expanded_labeled_trips['mode_confirm'].notna()].copy()  \n",
    "\n",
    "no_nan['EI_friendly_mode'] = no_nan.mode_confirm.map(MODE_MAPPING_DICT)\n",
    "\n",
    "# for some reason EI friendly mode still ends up with nans, so I drop them again.\n",
    "no_nan = no_nan[no_nan['EI_friendly_mode'].notna()].copy()\n",
    "no_nan['EI'] = no_nan.EI_friendly_mode.map(energy_dict)\n",
    "\n",
    "EI_length_cov_matrix = np.cov(no_nan[['EI','distance_miles']].transpose())\n",
    "EI_length_cov = EI_length_cov_matrix[0][1]\n",
    "\n",
    "mixed_var_covar_EI_length = get_EC.get_mixed_variance_covariance_term_for_nonlinear_variance_propagation(no_nan['EI'],no_nan['distance_miles'])\n",
    "mixed_var_covar_length_EI = get_EC.get_mixed_variance_covariance_term_for_nonlinear_variance_propagation(no_nan['distance_miles'],no_nan['EI'])\n",
    "\n",
    "EI_length_cov, mixed_var_covar_EI_length, mixed_var_covar_length_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance(df):\n",
    "    df = df.copy()\n",
    "    df['distance_miles'] = df.distance*METERS_TO_MILES\n",
    "    no_nan = df[df['mode_confirm'].notna()].copy()  \n",
    "\n",
    "    no_nan['EI_friendly_mode'] = no_nan.mode_confirm.map(MODE_MAPPING_DICT)\n",
    "\n",
    "    # for some reason EI friendly mode still ends up with nans, so I drop them again.\n",
    "    no_nan = no_nan[no_nan['EI_friendly_mode'].notna()].copy()\n",
    "    no_nan['EI'] = no_nan.EI_friendly_mode.map(energy_dict)\n",
    "\n",
    "    EI_length_cov_matrix = np.cov(no_nan[['EI','distance_miles']].transpose())\n",
    "    EI_length_cov = EI_length_cov_matrix[0][1]\n",
    "    return EI_length_cov\n",
    "\n",
    "# This shows that the covariance is not consistent across programs.\n",
    "for program in expanded_labeled_trips.program.unique():\n",
    "    program_df = expanded_labeled_trips[expanded_labeled_trips.program == program].copy()\n",
    "    print(f\"program, covariance: {program}, {get_covariance(program_df):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primary_mode in expanded_labeled_trips.primary_mode.unique():\n",
    "    primary_mode_df = expanded_labeled_trips[expanded_labeled_trips.primary_mode == primary_mode].copy()\n",
    "    print(f\"primary mode, covariance: {primary_mode}, {get_covariance(primary_mode_df):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO idea: add prior mode distribution as input to get_Bayesian_conditional_EI_expectation_and_variance\n",
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "# if you forget this step, the error for expected may be different, \n",
    "# since you might be relying on a different saved version of the EI_moments_dataframe\n",
    "Bayesian_android_EI_moments_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "Bayesian_ios_EI_moments_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "\n",
    "energy_consumption_df = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,Bayesian_android_EI_moments_df,Bayesian_ios_EI_moments_df, \\\n",
    "    EI_length_cov, mixed_var_covar_EI_length, mixed_var_covar_length_EI, print_info=False)\n",
    "    \n",
    "energy_consumption_df['distance_miles'] = energy_consumption_df.distance*METERS_TO_MILES\n",
    "# %store energy_consumption_df\n",
    "\n",
    "# using the old method with all ceo, including not a trip: Percent errors for expected and for predicted, including outliers: 7.08, 12.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_sum = 0\n",
    "if include_autocovariance == True:\n",
    "    if n_trips >= 50: # not calculating autocov if we do not have a large timeseries sample\n",
    "        for k in range(1,3):\n",
    "            expected_autocov_k = lagged_auto_cov(df.expected,k)\n",
    "            cov_sum += (n_trips - k)*2*expected_autocov_k\n",
    "    # used median values of the autocovariance across users that I found. Maybe I should just ignore autocovariance for small sets of trips.\n",
    "    else:\n",
    "        cov_sum = (n_trips - 1)*2*5.5 + (n_trips - 2)*2*0.95  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_auto_cov_map = {}\n",
    "for user in energy_consumption_df.user_id.unique():\n",
    "    df = energy_consumption_df[energy_consumption_df.user_id == user].copy()\n",
    "\n",
    "    auto_cov_list = []\n",
    "    for k in range(1,3):\n",
    "        expected_autocov_k = get_EC.lagged_auto_cov(df.expected,k)\n",
    "        auto_cov_list.append(expected_autocov_k)\n",
    "    user_auto_cov_map[user] = auto_cov_list\n",
    "\n",
    "energy_consumption_df['auto_cov'] = energy_consumption_df.user_id.map(user_auto_cov_map)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.auto_cov[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at how the covariance between EI and length impacts the variance estimates.\n",
    "In the fold results datafrane, trip_level_within_2_sd_proportion tells you how many trip EC estimates in the test set for that fold are within 2 standard deviations from the user labeled value.\n",
    "error_over_sd tells you how many standard deviations from the truth the aggregate EC estimate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More folds leads to smaller test sets and smaller aggregate energy consumption errors relative to the standard deviation.\n",
    "kf = KFold(5, shuffle=True, random_state=2) \n",
    "\n",
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "# if you forget this step, the error for expected may be different, \n",
    "# since you might be relying on a different saved version of the EI_moments_dataframe\n",
    "Bayesian_android_EI_moments_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "Bayesian_ios_EI_moments_df = cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "\n",
    "# This dataframe will store the proportions we calculate for each split of the training dataset.\n",
    "fold_results = pd.DataFrame(columns=['trip_level_within_2_sd_proportion', 'total_expected_EC', 'total_user_labeled_EC','percent_error', 'signed_error', 'aggregate_sd'])\n",
    "\n",
    "for train_index, test_index in kf.split(expanded_labeled_trips):\n",
    "    # Calculate ratios.\n",
    "    # Calculate EC percent error.\n",
    "    # Append to dataframe\n",
    "    training_set = expanded_labeled_trips.iloc[train_index].copy()\n",
    "    test_set = expanded_labeled_trips.iloc[test_index].copy()\n",
    "\n",
    "    training_set['distance_miles'] = training_set.distance*METERS_TO_MILES\n",
    "    no_nan = training_set[training_set['mode_confirm'].notna()].copy()  \n",
    "\n",
    "    no_nan['EI_friendly_mode'] = no_nan.mode_confirm.map(MODE_MAPPING_DICT)\n",
    "\n",
    "    # for some reason EI friendly mode still ends up with nans, so I drop them again.\n",
    "    no_nan = no_nan[no_nan['EI_friendly_mode'].notna()].copy()\n",
    "    no_nan['EI'] = no_nan.EI_friendly_mode.map(energy_dict)\n",
    "\n",
    "    EI_length_cov_matrix = np.cov(no_nan[['EI','distance_miles']].transpose())\n",
    "    EI_length_cov = EI_length_cov_matrix[0][1]\n",
    "\n",
    "    mixed_var_covar_EI_length = get_EC.get_mixed_variance_covariance_term_for_nonlinear_variance_propagation(no_nan['EI'],no_nan['distance_miles'])\n",
    "    mixed_var_covar_length_EI = get_EC.get_mixed_variance_covariance_term_for_nonlinear_variance_propagation(no_nan['distance_miles'],no_nan['EI'])\n",
    "    \n",
    "    test_energy_consumption_df = get_EC.compute_all_EC_values(test_set,unit_dist_MCS_df,energy_dict,Bayesian_android_EI_moments_df,Bayesian_ios_EI_moments_df, \n",
    "                                                            EI_length_cov, mixed_var_covar_EI_length, mixed_var_covar_length_EI,  print_info = False)\n",
    "\n",
    "    expected, predicted, actual = sum(test_energy_consumption_df['expected']), sum(test_energy_consumption_df['predicted']), sum(test_energy_consumption_df['user_labeled'])\n",
    "    sd = np.sqrt(test_energy_consumption_df.confusion_var.sum())\n",
    "    signed_error = expected - actual\n",
    "    error_over_sd = abs(signed_error/sd)\n",
    "\n",
    "    # k here is number of standard deviations.\n",
    "    k = 2\n",
    "    # count the number of times that the error magnitude is less than k times the standard deviation\n",
    "    within_2_sd_proportion = sum(k*test_energy_consumption_df['confusion_sd'] > abs(test_energy_consumption_df['error_for_confusion']))/len(test_energy_consumption_df)\n",
    "    percent_error = hf.relative_error(expected,actual)*100\n",
    "\n",
    "    results_map = {'trip_level_within_2_sd_proportion': within_2_sd_proportion, 'total_expected_EC': expected, \n",
    "                'total_user_labeled_EC': actual, 'percent_error': percent_error, 'signed_error': signed_error, \n",
    "                'aggregate_sd': sd, 'error_over_sd': error_over_sd}\n",
    "    fold_results = fold_results.append(results_map, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percent of the time that the error is above two standard deviations: {sum(fold_results.error_over_sd > 2)/len(fold_results)}\")\n",
    "print(f\"Maximum error relative to standard deviation: {max(fold_results.error_over_sd):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_EC.get_totals_and_errors(program_df, include_autocovariance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What how many standard deviations are in the error for each program if we include covariance between EI and length?\n",
    "n_standard_devs = []\n",
    "program_size = []\n",
    "\n",
    "for program in energy_consumption_df.program.unique():\n",
    "    program_df = energy_consumption_df[energy_consumption_df.program == program]\n",
    "\n",
    "    print(f\"program: {program}\")\n",
    "    # TODO: change this so that only the autocov for each user is used?\n",
    "    n_standard_devs.append(get_EC.get_totals_and_errors(program_df, include_autocovariance = True)['error_over_sd'])\n",
    "\n",
    "    program_size.append(len(program_df))\n",
    "\n",
    "    print(f\"{program}, {n_standard_devs[-1]:.2f}, {len(program_df)}\")\n",
    "plt.scatter(program_size,n_standard_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit(program_size,n_standard_devs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the error change as we increase the number of trips? \n",
    "# It looks like the error relative to the standard deviation increases.\n",
    "# I think we can safely say that trips between different users will not be strongly correlated.\n",
    "\n",
    "n_standard_devs = []\n",
    "n_trips_by_user = []\n",
    "percent_error = []\n",
    "\n",
    "no_sensed_proportion = []\n",
    "walking_proportion = []\n",
    "\n",
    "for u in energy_consumption_df.user_id.unique():\n",
    "    \n",
    "    user_df = energy_consumption_df[energy_consumption_df.user_id == u]\n",
    "\n",
    "    totals_and_errors = get_EC.get_totals_and_errors(user_df, include_autocovariance= True)\n",
    "    n_standard_devs.append(totals_and_errors['error_over_sd'])\n",
    "\n",
    "    if totals_and_errors['autocov_sum'] < 0: \n",
    "        print(f\"autocov sum, n_trips, error_over_sd: {totals_and_errors['autocov_sum']:.2f}, {len(user_df)}, {totals_and_errors['error_over_sd']:.3f}\")\n",
    "    n_trips_by_user.append(len(user_df))\n",
    "    percent_error.append(totals_and_errors[\"percent_error_for_expected\"])\n",
    "\n",
    "    primary_mode_proportion = user_df.groupby('primary_mode').sum().distance/user_df.distance.sum()\n",
    "    no_sensed_proportion.append(primary_mode_proportion['no_sensed'] if 'no_sensed' in primary_mode_proportion else 0)\n",
    "    walking_proportion.append(primary_mode_proportion['walking'] if 'walking' in primary_mode_proportion else 0)\n",
    "\n",
    "    if totals_and_errors['error_over_sd'] > 15:\n",
    "        large_error_user_df = user_df.copy()\n",
    "        large_error = totals_and_errors['error_over_sd']\n",
    "\n",
    "plt.scatter(n_trips_by_user,n_standard_devs)\n",
    "plt.xlabel(\"Number of trips for a user\")\n",
    "plt.ylabel(\"Number of standard deviations from truth\")\n",
    "plt.title(\"Energy consumption error relative to estimated standard deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_standard_devs, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(walking_proportion,n_standard_devs)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does error over sd vary with no sensed and walking?\n",
    "user_sd_info = pd.DataFrame({\"no_sensed_proportion\":no_sensed_proportion, \"walking_proportion\":walking_proportion, \"n_trips\":n_trips_by_user, \"n_standard_devs\":n_standard_devs})\n",
    "enough_trips = user_sd_info.query('n_trips > 50').copy()\n",
    "plt.scatter(enough_trips['no_sensed_proportion'],enough_trips['n_standard_devs'])\n",
    "plt.scatter(enough_trips['walking_proportion'],enough_trips['n_standard_devs'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enough_trips.hist(\"no_sensed_proportion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "LR = linear_model.LinearRegression()\n",
    "lr_fit = LR.fit(enough_trips[['no_sensed_proportion','walking_proportion']],enough_trips['n_standard_devs'])\n",
    "# to do one at a time: LR.fit(np.array(enough_trips['no_sensed_proportion']).reshape(-1, 1),enough_trips['n_standard_devs']).coef_\n",
    "\n",
    "lr_fit.coef_,lr_fit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(np.array(user_sd_info['n_trips']).reshape(-1, 1),user_sd_info['n_standard_devs']).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate n_sd_no_auto_cov_no_nonlinear, I ran compute_all_EC_values without the mixed_var_covar terms,\n",
    "# and I ran get_totals_and_errors with include_autocovar = False.\n",
    "before_after_n_sd = pd.DataFrame({\"n_sd_no_auto_cov_no_nonlinear\": n_standard_devs, \"n_sd_with_auto_cov_and_nonlinear\": user_sd_info['n_standard_devs']})\n",
    "before_after_n_sd.plot()#.scatter(x = \"n_sd_no_auto_cov_no_nonlinear\",y = \"n_sd_with_auto_cov_and_nonlinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the modes used by a user with a large error over sd.\n",
    "large_error_user_df.groupby('mode_confirm').sum()[['error_for_confusion', 'distance_miles']]\n",
    "\n",
    "# up next: look at the shared rides for this user. why is shared ride error negative?. Do the mode distance prediction thing.\n",
    "# Looks like a large percent of shared ride trips (and for other modes) for this user was no sensed and walk.\n",
    "#user label: shared_ride\n",
    "#    primary_mode\n",
    "#    car          0.044047\n",
    "#    no_sensed    0.655563\n",
    "#    walking      0.300390\n",
    "\n",
    "# look at percent no sensed for all users?\n",
    "large_error_user_df.primary_mode.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction_percentages(df):\n",
    "    for mode in ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike']:\n",
    "        #n_user_labels = all_trip_modes['mode_confirm'].count(mode)\n",
    "        mode_df = df[df['mode_confirm'] == mode]\n",
    "        section_mode_distance_dict_given_user_label = {}\n",
    "        for i,ct in mode_df.iterrows():\n",
    "            section_modes = ct['section_modes']\n",
    "\n",
    "        print(mode)\n",
    "        #print(mode_df.primary_mode.value_counts(normalize=True)) # prediction percentages by mode count\n",
    "\n",
    "        print(mode_df.groupby('primary_mode').sum().distance/mode_df.distance.sum()) # prediction percentages by distance\n",
    "\n",
    "print_prediction_percentages(user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.query('mode_confirm == \"shared_ride\"').primary_mode.hist()\n",
    "large_error_user_df.query('mode_confirm == \"shared_ride\"').primary_mode.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ride_large_user_error_df = large_error_user_df[large_error_user_df['mode_confirm'] == 'shared_ride']\n",
    "shared_ride_large_user_error_df.primary_mode.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_EC.get_totals_and_errors(large_error_user_df,include_autocovariance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_for_user = hf.get_ratios_for_dataset(large_error_user_df)\n",
    "r_for_dataset = ratios_for_user['r']\n",
    "percent_error_expected = hf.relative_error(sum(large_error_user_df['expected']),sum(large_error_user_df['user_labeled']))*100\n",
    "percent_error_predicted = hf.relative_error(sum(large_error_user_df['predicted']),sum(large_error_user_df['user_labeled']))*100\n",
    "mean_EC_all_user_labeled = sum(large_error_user_df['user_labeled'])\n",
    "output_path = \"/Users/mallen2/OpenPATH_Data/Sensing_sensitivity_analysis/\"+\"vail\"+\"_\"+\"mode_error_share\"+\"/\" # might not actually be a vail user\n",
    "hf.plot_error_by_primary_mode(large_error_user_df,'large_error_user', r_for_dataset, r, percent_error_expected,percent_error_predicted, mean_EC_all_user_labeled, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(n_standard_devs) # also == the number of users\n",
    "below_1 = sum(np.array(n_standard_devs) < 1)/n_samples\n",
    "below_2 = sum(np.array(n_standard_devs) < 2)/n_samples\n",
    "below_3 = sum(np.array(n_standard_devs) < 3)/n_samples\n",
    "below_7 = sum(np.array(n_standard_devs) < 7)/n_samples\n",
    "\n",
    "print(f\"Proportion within:\\n1 sd: {below_1:.4f}\\n2 sd: {below_2:.4f}\\n3 sd: {below_3:.4f}\\n7 sd: {below_7:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percent of primary mode predictions is correct?\n",
    "\n",
    "main_mode_confirms = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle', 'not_a_trip']\n",
    "main_modes_df = expanded_labeled_trips[expanded_labeled_trips.mode_confirm.isin(main_mode_confirms)].copy()\n",
    "main_modes_df = main_modes_df[main_modes_df.mode_confirm.notna()]\n",
    "\n",
    "match_count = 0\n",
    "for _,ct in main_modes_df.iterrows():\n",
    "    if (ct['primary_mode'] == 'car') and (ct['mode_confirm'] in ['shared_ride', 'taxi']):\n",
    "        match_count += 1\n",
    "    elif (ct['primary_mode'] == 'bicycling') and (ct['mode_confirm'] == 'pilot_ebike'):\n",
    "        match_count += 1\n",
    "    elif (ct['primary_mode'] == 'bus') and (ct['mode_confirm'] == 'free_shuttle'):\n",
    "        match_count += 1\n",
    "    elif MODE_MAPPING_DICT[ct['primary_mode']] == MODE_MAPPING_DICT[ct['mode_confirm']]:\n",
    "        match_count += 1\n",
    "\n",
    "# The version below doesn't count a car prediction as correct for shared ride.\n",
    "#sum(main_modes_df.mode_confirm.map(MODE_MAPPING_DICT)== main_modes_df.primary_mode.map(MODE_MAPPING_DICT))/len(main_modes_df)\n",
    "\n",
    "print(match_count/len(main_modes_df)*100)  # 65.75% if we exclude not_a_trip, 63.50% if we include not_a_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What fraction of the distance are we correctly predicting?\n",
    "\n",
    "# Note: MODE_MAPPING_DICT[\"no_sensed\"] == MODE_MAPPING_DICT[\"not_a_trip\"]   # both give 'Not a Trip'\n",
    "\n",
    "match_distance = 0\n",
    "for _,ct in main_modes_df.iterrows():\n",
    "    if len(ct['section_modes']) == 0:\n",
    "        print(f\"No sections sensed for a {ct['mode_confirm']} trip.\")\n",
    "    for i,s in enumerate(ct['section_modes']):\n",
    "        if (s == 'car') and (ct['mode_confirm'] in ['shared_ride', 'taxi']):\n",
    "            match_distance += ct['section_distances'][i]\n",
    "        elif (s == 'bicycling') and (ct['mode_confirm'] == 'pilot_ebike'):\n",
    "            match_distance += ct['section_distances'][i]\n",
    "        elif (s == 'bus') and (ct['mode_confirm'] == 'free_shuttle'):\n",
    "            match_count += 1\n",
    "        elif MODE_MAPPING_DICT[s] == MODE_MAPPING_DICT[ct['mode_confirm']]:\n",
    "            match_distance += ct['section_distances'][i]\n",
    "\n",
    "\n",
    "print(100*match_distance/main_modes_df.distance.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the same plot but this time select random samples of trips rather than all trips from the same user.\n",
    "# What do these show? They show that the relationship between number of standard deviations and the number of trips becomes less prominent when trips sets are not split by user.\n",
    "# This suggests that there is more dependence between trip energy consumptions for the same user than for trips taken by different users.\n",
    "def plot_n_trips_vs_fraction_of_error(energy_consumption_df, random_state_for_sampling):\n",
    "\n",
    "    n_standard_devs = []\n",
    "    n_trips_by_user = []\n",
    "    percent_error = []\n",
    "\n",
    "    for u in energy_consumption_df.user_id.unique():\n",
    "        n_trips = len(energy_consumption_df[energy_consumption_df.user_id == u])\n",
    "        sub_df = energy_consumption_df.sample(n_trips, random_state=random_state_for_sampling)\n",
    "        totals_and_errors = get_EC.get_totals_and_errors(sub_df, include_autocovariance=True)\n",
    "        n_standard_devs.append(totals_and_errors['error_over_sd'])\n",
    "        n_trips_by_user.append(n_trips)\n",
    "        percent_error.append(totals_and_errors[\"percent_error_for_expected\"])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(n_trips_by_user,n_standard_devs)\n",
    "    plt.xlabel(\"Number of trips in random set of trips\")\n",
    "    plt.ylabel(\"Number of standard deviations from truth\")\n",
    "    plt.title(f\"Energy consumption error relative to estimated standard deviation, random_state = {random_state_for_sampling}\")\n",
    "\n",
    "for j in range(1,5):\n",
    "    plot_n_trips_vs_fraction_of_error(energy_consumption_df,random_state_for_sampling=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read up about autocorrelation\n",
    "\n",
    "def acf(x, length=20):  # https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation\n",
    "    return np.array([1]+[np.corrcoef(x[:-i], x[i:])[0,1]  \\\n",
    "        for i in range(1, length)])\n",
    "\n",
    "for u in energy_consumption_df.user_id.unique()[0:6]:\n",
    "    \n",
    "    user_df = energy_consumption_df[energy_consumption_df.user_id == u]\n",
    "    user_df = user_df.sort_values(by='end_ts', ascending=True)\n",
    "\n",
    "    total_labeled, total_expected = sum(user_df.user_labeled), sum(user_df.expected)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(20,4)\n",
    "    plt.plot(user_df.end_ts,user_df.user_labeled)\n",
    "    plt.plot(user_df.end_ts,user_df.expected)\n",
    "    plt.legend([\"user labeled EC\", \"expected EC\"])\n",
    "    plt.ylabel(\"Trip energy consumption (kWH)\")\n",
    "    plt.xlabel(\"Trip end timestamp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A histogram of trip energy consumption.\n",
    "energy_consumption_df.user_labeled.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the autocovariance at a few lags. Plots of info in autocov_df come after the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocov_df = pd.DataFrame()\n",
    "for u in energy_consumption_df.user_id.unique():\n",
    "    \n",
    "    user_df = energy_consumption_df[energy_consumption_df.user_id == u]\n",
    "    user_df = user_df.sort_values(by='end_ts', ascending=True)\n",
    "    if len(user_df)<2: \n",
    "        print(f\"Skipping a user with {len(user_df)} trips.\") \n",
    "        continue\n",
    "    labeled_autocov_1, expected_autocov_1 = get_EC.lagged_auto_cov(user_df.user_labeled,1), get_EC.lagged_auto_cov(user_df.expected,1)\n",
    "    labeled_autocov_2, expected_autocov_2 = get_EC.lagged_auto_cov(user_df.user_labeled,2), get_EC.lagged_auto_cov(user_df.expected,2)\n",
    "    labeled_autocov_10, expected_autocov_10 = get_EC.lagged_auto_cov(user_df.user_labeled,10), get_EC.lagged_auto_cov(user_df.expected,10)\n",
    "\n",
    "    autocov_df = autocov_df.append({ \"user_id\": u,\n",
    "                                    \"n_trips\": len(user_df),\n",
    "                                    \"labeled_EC_autocov_lag_1\": labeled_autocov_1, \n",
    "                                    \"labeled_EC_autocov_lag_2\":labeled_autocov_2,\n",
    "                                    \"expected_EC_autocov_lag_1\": expected_autocov_1,\n",
    "                                    \"expected_EC_autocov_lag_2\": expected_autocov_2,\n",
    "                                    \"expected_EC_autocov_lag_10\": expected_autocov_10,\n",
    "                                    \"labeled_EC_autocov_lag_10\": labeled_autocov_10\n",
    "                                    }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(autocov_df.labeled_EC_autocov_lag_1,autocov_df.expected_EC_autocov_lag_1)\n",
    "\n",
    "# with more recorded trips, our autocov estimate gets closer to the truth.\n",
    "plt.figure()\n",
    "plt.scatter(autocov_df.n_trips, autocov_df.labeled_EC_autocov_lag_1 - autocov_df.expected_EC_autocov_lag_1)\n",
    "plt.xlabel(\"Number of trips\")\n",
    "plt.ylabel(\"Difference between expected EC autocov and user labeled EC autocov at lag = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocov_df.expected_EC_autocov_lag_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocov_df.expected_EC_autocov_lag_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocov_df[abs(autocov_df.expected_EC_autocov_lag_1) > 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what the trips are like for users with 5000% error. \n",
    "# Answer: those users have very few trips.\n",
    "plt.scatter(percent_error,n_trips_by_user) \n",
    "plt.xlabel(\"percent error for expected for each user\")\n",
    "plt.ylabel(\"Number of trips associated with that user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = np.sqrt(energy_consumption_df.confusion_var.sum())\n",
    "print(sd)\n",
    "print((expected - actual)/sd)\n",
    "hf.relative_error(expected,actual)*100, hf.relative_error(predicted,actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobilityNet estimate of P(predicted| actual)\n",
    "collapsed_confusion_matrix = ios_confusion.copy()\n",
    "prior_probs = [1/len(collapsed_confusion_matrix.index)]* len(collapsed_confusion_matrix.index) # later try p_car = 0.4, everthing else is (1-0.4)/(n_non_car)\n",
    "\n",
    "p_predicted_given_actual = collapsed_confusion_matrix.divide(collapsed_confusion_matrix.sum(axis=1), axis='rows')\n",
    "\n",
    "p_predicted_given_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_handling.get_Bayesian_conditional_EI_expectation_and_variance(android_confusion,energy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of predictions given user labeled mode\n",
    "May want to look at primary mode normalized by distance rather than value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trip_modes = expanded_labeled_trips[['mode_confirm','section_modes','primary_mode','distance']].copy()\n",
    "\n",
    "#for i,ct in all_trip_modes.iterrows():\n",
    "\n",
    "for mode in ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike']:\n",
    "    #n_user_labels = all_trip_modes['mode_confirm'].count(mode)\n",
    "    mode_df = all_trip_modes[all_trip_modes['mode_confirm'] == mode]\n",
    "    section_mode_distance_dict_given_user_label = {}\n",
    "    for i,ct in mode_df.iterrows():\n",
    "        section_modes = ct['section_modes']\n",
    "\n",
    "    print(mode)\n",
    "    #print(mode_df.primary_mode.value_counts(normalize=True)) # prediction percentages by mode count\n",
    "\n",
    "    print(mode_df.groupby('primary_mode').sum().distance/mode_df.distance.sum()) # prediction percentages by distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors for drove alone and shared ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()\n",
    "drove_alone_4c_df = program_df[program_df['mode_confirm'] == 'drove_alone']\n",
    "drove_alone_outliers = hf.get_outliers(drove_alone_4c_df,'error_for_confusion',100,15)[['distance','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "#drove_alone_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ride_4c_df = program_df[program_df['mode_confirm'] == 'shared_ride']\n",
    "shared_ride_outliers_low = hf.get_outliers(shared_ride_4c_df,'error_for_confusion',100,15)[['distance','distance_miles','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "shared_ride_outliers_high = hf.get_outliers(shared_ride_4c_df,'error_for_confusion',85,0)[['distance','distance_miles','mode_confirm','section_modes','section_distances','primary_mode','primary_length','error_for_confusion','error_for_prediction','expected','predicted', 'user_labeled','os']]\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "fig.set_figwidth(15)\n",
    "shared_ride_outliers_high.primary_mode.hist(ax = axs[0])\n",
    "shared_ride_outliers_low.primary_mode.hist(ax = axs[1])\n",
    "\n",
    "axs[0].set_title(\"4c shared ride overestimates primary modes (above 85th percentile)\")\n",
    "axs[1].set_title(\"4c shared ride underestimates primary modes(below 15th percentile)\")\n",
    "\n",
    "# most of the overestimates are car. (blue)\n",
    "# most of the unerestimates are walking, bicycling, and no sensed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ride_outliers_high.distance_miles.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drove_alone_outliers.primary_mode.hist()\n",
    "plt.title(\"4c drove alone outlier primary modes (below the 15th percentile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convenction below: <user label>_<primary mode>\n",
    "drove_alone_car = drove_alone_4c_df[drove_alone_4c_df.primary_mode == 'car']\n",
    "shared_ride_car = shared_ride_4c_df[shared_ride_4c_df.primary_mode == 'car']\n",
    "\n",
    "EI_used_for_android_sensed_car = 1.189540\n",
    "EI_used_for_android_walking = 0.010464\n",
    "EI_for_drove_alone = 1.51517707\n",
    "EI_for_shared_ride = 0.757588535\n",
    "drove_alone_car_distance = drove_alone_car.distance.sum()*METERS_TO_MILES\n",
    "shared_ride_car_distance = shared_ride_car.distance.sum()*METERS_TO_MILES\n",
    "\n",
    "# the outliers below 15% account for -2390 kWH\n",
    "drove_alone_outlier_error = drove_alone_outliers.error_for_confusion.sum()\n",
    "shared_ride_outliers_high_error = shared_ride_outliers_high.error_for_confusion.sum()\n",
    "shared_ride_outliers_low_error = shared_ride_outliers_low.error_for_confusion.sum()\n",
    "\n",
    "# the drove alone trips in 4c where the primary mode is car account for -1754 kWH of error.\n",
    "print(f\"Errors for drove alone and shared ride when we predict car: {drove_alone_car.error_for_confusion.sum():.2f}, {shared_ride_car.error_for_confusion.sum():.2f}\")\n",
    "print(f\"Drove alone outlier errors sum: {drove_alone_outlier_error:.2f}\")\n",
    "print(f\"Shared ride outlier error for upper outliers, lower outliers: {shared_ride_outliers_high_error:.2f}, {shared_ride_outliers_low_error:.2f}\")\n",
    "\n",
    "print(\"\\nMost of the outlier error for drove alone is from walking.\")\n",
    "print(f\"Difference between sensed walking and drove alone EI: {EI_used_for_android_walking - EI_for_drove_alone:.4f}\")\n",
    "\n",
    "print(\"\\nMost of the overestimation outlier error for shared ride is from sensed car.\")\n",
    "print(f\"Difference between sensed car and shared ride EI: {EI_used_for_android_sensed_car - EI_for_shared_ride:.4f}\")\n",
    "\n",
    "print(\"\\nMost of the underestimation outlier error for shared ride is from no_sensed and walking.\")\n",
    "print(f\"Difference between no_sensed and shared ride EI: {android_EI_moments_df['mean(EI)']['no_sensed'] - EI_for_shared_ride:.4f}\")\n",
    "print(f\"Difference between sensed walking and shared ride EI: {EI_used_for_android_walking - EI_for_shared_ride:.4f}\")\n",
    "print(\"In either case, when we mispredict drove alone, we are guaranteed to have a higher error than for a similar shared ride trip.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy consumption estimates by user labeled mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.plot_energy_consumption_by_mode(energy_consumption_df, program_name= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error magnitudes compared to standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many standard deviations does it take to reach the size of the error?\n",
    "main_mode_confirms = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle']\n",
    "energy_consumption_df['n_standard_devs'] = energy_consumption_df['error_for_confusion']/energy_consumption_df['confusion_sd']\n",
    "\n",
    "# get standard deviation outliers?\n",
    "energy_consumption_df.n_standard_devs.hist(bins=100)\n",
    "\n",
    "pc_df = energy_consumption_df[energy_consumption_df['program']=='pc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_errors = energy_consumption_df[abs(energy_consumption_df.n_standard_devs) > 2]\n",
    "high_errors.groupby('mode_confirm').sum().loc[main_mode_confirms].distance_miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df[energy_consumption_df.mode_confirm== 'shared_ride'].n_standard_devs.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df[energy_consumption_df.mode_confirm== 'pilot_ebike'].n_standard_devs.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.n_standard_devs.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_by_user_mode = energy_consumption_df.groupby(\"mode_confirm\").sum().loc[main_mode_confirms][['confusion_var']]\n",
    "variances_by_user_mode['sd'] = np.sqrt(variances_by_user_mode)\n",
    "variances_by_user_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode vs distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r energy_consumption_df\n",
    "'not_a_trip' in energy_consumption_df.mode_confirm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the covariance between energy intensity and trip length.\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "expanded_labeled_trips['EI_friendly_mode'] = expanded_labeled_trips.mode_confirm.map(MODE_MAPPING_DICT)\n",
    "expanded_labeled_trips['EI'] = expanded_labeled_trips.EI_friendly_mode.map(energy_dict)\n",
    "no_nan = expanded_labeled_trips[expanded_labeled_trips['mode_confirm'].notna()]\n",
    "np.cov(no_nan[['EI','distance_miles']].transpose())  # = 1105.462 for all CEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1742**2 + 54953*1105)*2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan[['EI','distance_miles']].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.EI_friendly_mode.map(energy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips['EI_friendly_mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.mode_confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make boxplots of distance and user labeled mode.\n",
    "expanded_labeled_trips['distance_miles'] = expanded_labeled_trips.distance*METERS_TO_MILES\n",
    "\n",
    "main_mode_confirms = ['drove_alone','shared_ride','walk','pilot_ebike','bus','bike','train','taxi','free_shuttle', 'not_a_trip']\n",
    "main_modes_only = expanded_labeled_trips[expanded_labeled_trips.mode_confirm.isin(main_mode_confirms)].copy()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "ax.set_ylabel(\"distance in miles\")\n",
    "ax.set_ylim([0,50])  # keep in mind that ceo has plenty of outliers above 50 and even above 300 miles\n",
    "main_modes_only.boxplot(column='distance_miles', by='mode_confirm', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in main_mode_confirms:\n",
    "    mode_df = expanded_labeled_trips[expanded_labeled_trips.mode_confirm == mode]\n",
    "    print(f\"{mode}: {mode_df.distance_miles.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.distance.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the energy consumption percent error as a function of dataset characteristics\n",
    "Make sure you've calculated program proportions and energy consumption for the full dataset first.\n",
    "Before analysis, keep track of whether you dropped not a trips in the \"helper_functions.drop_unwanted_trips()\" call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.05)\n",
    "linreg = linear_model.LinearRegression()\n",
    "ridge = linear_model.Ridge(alpha= 0.05)\n",
    "\n",
    "# splitting without shuffling leads to some larger car to other ratios\n",
    "kf = KFold(n_splits=100, shuffle=True, random_state=2)  # some splits might not have any ebike\n",
    "fold_proportions_and_errors = pd.DataFrame(columns=['r', 'drove_alone_distance', 'shared_ride_distance','car_proportion', \n",
    "                                        'ebike_proportion', 'walk_proportion', 'drove_alone_proportion', 'shared_ride_proportion', 'car_to_other',\n",
    "                                        'percent_error','error'])\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(energy_consumption_df):\n",
    "    # Calculate ratios\n",
    "    # Calculate EC\n",
    "    # Append to dataframe\n",
    "    df_subset = energy_consumption_df.iloc[test_index]\n",
    "\n",
    "    ratios = hf.get_ratios_for_dataset(df_subset)\n",
    "\n",
    "    user_labeled = df_subset.user_labeled.sum()\n",
    "    total_error = df_subset.error_for_confusion.sum()\n",
    "    percent_error = 100*total_error/user_labeled\n",
    "\n",
    "    ratios.update({'error': total_error, 'percent_error': percent_error})\n",
    "\n",
    "    fold_proportions_and_errors = fold_proportions_and_errors.append(ratios, ignore_index=True)\n",
    "\n",
    "features = ['r','non_moto_to_moto','car_to_other', 'walk_proportion', 'drove_alone_proportion']\n",
    "X = fold_proportions_and_errors[features]\n",
    "y = fold_proportions_and_errors['percent_error']\n",
    "\n",
    "lin_reg_fit = linreg.fit(X,y)\n",
    "print(\"Linear regression model coefficients:\")\n",
    "print({label:coef for label, coef in zip(features,lin_reg_fit.coef_)})\n",
    "\n",
    "ridge_fit = ridge.fit(X,y)\n",
    "print(\"Ridge regression model coefficients:\")\n",
    "print({label:coef for label, coef in zip(features,ridge_fit.coef_)})\n",
    "\n",
    "lasso_fit = lasso.fit(X,y)\n",
    "print(\"LASSO model coefficients:\")\n",
    "print({label:coef for label, coef in zip(features,lasso_fit.coef_)})\n",
    "\n",
    "features_of_interest = ['r','non_moto_to_moto','car_to_other']\n",
    "n_features = len(features_of_interest)\n",
    "fig, axs = plt.subplots(nrows=n_features,ncols=1)\n",
    "fig.set_figheight(5*n_features)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "j = 0\n",
    "for feature in features_of_interest:\n",
    "    axs[j].scatter(fold_proportions_and_errors[feature],fold_proportions_and_errors['percent_error'])\n",
    "    axs[j].set_xlabel(feature)\n",
    "    axs[j].set_ylabel(\"Percent error for expected\")\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the predicted values and actual values for the non cross validated models produced above.\n",
    "features_of_interest = ['r','non_moto_to_moto','car_to_other']\n",
    "program_features = program_proportions[features]\n",
    "\n",
    "# Calculate percent errors for each program.\n",
    "program_percent_error_map = {}\n",
    "for program in energy_consumption_df['program'].unique():\n",
    "    program_df = energy_consumption_df[energy_consumption_df['program'] == program].copy()\n",
    "    percent_error_expected = hf.relative_error(sum(program_df['expected']),sum(program_df['user_labeled']))*100\n",
    "    program_percent_error_map[program] = percent_error_expected\n",
    "program_percent_error_map['all'] = hf.relative_error(sum(energy_consumption_df['expected']),sum(energy_consumption_df['user_labeled']))*100\n",
    "\n",
    "# Calculate the predictions for each program.\n",
    "ridge_predictions = ridge_fit.predict(program_features)\n",
    "lasso_predictions = lasso_fit.predict(program_features)\n",
    "LR_predictions = lin_reg_fit.predict(program_features)\n",
    "\n",
    "program_percent_error_list = [program_percent_error_map[x] for x in program_features.index]\n",
    "\n",
    "error_model_df = pd.DataFrame({\"program\": program_features.index, \"linear regression\": LR_predictions, \"ridge\": ridge_predictions, \"LASSO\": lasso_predictions, \n",
    "            \"observed percent error\": program_percent_error_list,\n",
    "            \"linreg residuals\": program_percent_error_list - LR_predictions,\n",
    "            \"ridge residuals\": program_percent_error_list - ridge_predictions,\n",
    "            \"lasso residuals\": program_percent_error_list - lasso_predictions})\n",
    "print(error_model_df.round(3).to_markdown()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals, y_vals = fold_proportions_and_errors['non_moto_to_moto'],fold_proportions_and_errors['percent_error']\n",
    "\n",
    "a, b = np.polyfit(x_vals, y_vals, 1)\n",
    "\n",
    "plt.scatter(x_vals, y_vals)\n",
    "\n",
    "plt.plot(x_vals, a*x_vals+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the naturalistic splits validation.\n",
    "def build_percent_error_models(training_set_df, n_splits, features):\n",
    "    # The test set in each KFold.split is the fold of interest.\n",
    "    kf = KFold(n_splits, shuffle=True, random_state=2) \n",
    "\n",
    "    # This dataframe will store the proportions we calculate for each split of the training dataset.\n",
    "    fold_proportions_and_errors = pd.DataFrame(columns=['r', 'drove_alone_distance', 'shared_ride_distance','car_proportion', \n",
    "                                        'ebike_proportion', 'walk_proportion', 'drove_alone_proportion', 'shared_ride_proportion', 'car_to_other',\n",
    "                                        'percent_error','error'])\n",
    "\n",
    "    for _, test_index in kf.split(training_set_df):\n",
    "        # Calculate ratios.\n",
    "        # Calculate EC percent error.\n",
    "        # Append to dataframe\n",
    "        df_subset = energy_consumption_df.iloc[test_index]\n",
    "\n",
    "        ratios = hf.get_ratios_for_dataset(df_subset)\n",
    "\n",
    "        user_labeled = df_subset.user_labeled.sum()\n",
    "        total_error = df_subset.error_for_confusion.sum()\n",
    "        percent_error = 100*total_error/user_labeled\n",
    "\n",
    "        ratios.update({'error': total_error, 'percent_error': percent_error})\n",
    "\n",
    "        fold_proportions_and_errors = fold_proportions_and_errors.append(ratios, ignore_index=True)\n",
    "\n",
    "    X = fold_proportions_and_errors[features]\n",
    "    y = fold_proportions_and_errors['percent_error']\n",
    "\n",
    "    lin_reg_fit = linreg.fit(X,y)\n",
    "    print(\"Linear regression model coefficients:\")\n",
    "    print({label:coef for label, coef in zip(features,lin_reg_fit.coef_)})\n",
    "\n",
    "    ridge_fit = ridge.fit(X,y)\n",
    "    print(\"Ridge regression model coefficients:\")\n",
    "    print({label:coef for label, coef in zip(features,ridge_fit.coef_)})\n",
    "\n",
    "    lasso_fit = lasso.fit(X,y)\n",
    "    print(\"LASSO model coefficients:\")\n",
    "    print({label:coef for label, coef in zip(features,lasso_fit.coef_)})\n",
    "\n",
    "    return {\"LR\":lin_reg_fit, \"Ridge\": ridge_fit, \"LASSO\": lasso_fit}\n",
    "\n",
    "#########\n",
    "features_of_interest = ['r','non_moto_to_moto','car_to_other']\n",
    "program_features = program_proportions[features_of_interest]\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.05)\n",
    "linreg = linear_model.LinearRegression()\n",
    "ridge = linear_model.Ridge(alpha= 0.05)\n",
    "\n",
    "model_predictions_df = pd.DataFrame(columns=['program','LR ppe','Ridge ppe', 'LASSO ppe'])#, 'observed percent error'])\n",
    "\n",
    "for program in energy_consumption_df.program.unique():\n",
    "\n",
    "    # The training set is all data excluding the current program. \n",
    "    # I calculated relevant info from the program/test set in the cell that generates program_proportions. \n",
    "    training_set = energy_consumption_df[energy_consumption_df.program != program].copy()\n",
    "\n",
    "    print(program)\n",
    "    error_models = build_percent_error_models(training_set, n_splits=100, features= features_of_interest)\n",
    "\n",
    "    # Find the appropriate index to look for within the model predicted values\n",
    "    program_index = list(program_features.index).index(program)\n",
    "\n",
    "    print(error_models[\"LR\"].predict(program_features)[program_index])\n",
    "\n",
    "    # To predict for 1 program only, could use np.dot(program_features.loc[program],error_models[\"LR\"].coef_) + error_models[\"LR\"].intercept_\n",
    "    \n",
    "    # Display the predictions\n",
    "    model_predictions_df = model_predictions_df.append(\n",
    "        {   \"program\": program,\n",
    "            \"LR ppe\": error_models[\"LR\"].predict(program_features)[program_index],  # need the prediction where the program == program,\n",
    "            \"Ridge ppe\": error_models[\"Ridge\"].predict(program_features)[program_index],\n",
    "            \"LASSO ppe\": error_models[\"LASSO\"].predict(program_features)[program_index]\n",
    "        },\n",
    "          ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model predictions for each program after training on the rest of the data.\n",
    "\n",
    "program_percent_error_map = {}\n",
    "for program in energy_consumption_df['program'].unique():\n",
    "    program_df = energy_consumption_df[energy_consumption_df['program'] == program].copy()\n",
    "    percent_error_expected = hf.relative_error(sum(program_df['expected']),sum(program_df['user_labeled']))*100\n",
    "    program_percent_error_map[program] = percent_error_expected\n",
    "program_percent_error_map['all'] = hf.relative_error(sum(energy_consumption_df['expected']),sum(energy_consumption_df['user_labeled']))*100\n",
    "\n",
    "model_predictions_df['observed percent error'] = model_predictions_df.program.map(program_percent_error_map)\n",
    "model_predictions_df[\"linreg residuals\"] =  model_predictions_df['observed percent error'] - model_predictions_df['LR ppe']\n",
    "model_predictions_df[\"ridge residuals\"] =  model_predictions_df['observed percent error'] - model_predictions_df['Ridge ppe']\n",
    "model_predictions_df[\"LASSO residuals\"] =  model_predictions_df['observed percent error'] - model_predictions_df['LASSO ppe']\n",
    "\n",
    "print(model_predictions_df.round(3).to_markdown()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_percent_error_map = {}\n",
    "for program in energy_consumption_df['program'].unique():\n",
    "    program_df = energy_consumption_df[energy_consumption_df['program'] == program].copy()\n",
    "    percent_error_expected = hf.relative_error(sum(program_df['expected']),sum(program_df['user_labeled']))*100\n",
    "    program_percent_error_map[program] = percent_error_expected\n",
    "program_percent_error_map['all'] = hf.relative_error(sum(energy_consumption_df['expected']),sum(energy_consumption_df['user_labeled']))*100\n",
    "\n",
    "program_percent_error_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot energy consumption by user labeled mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()\n",
    "\n",
    "hf.plot_energy_consumption_by_mode(program_df,'4c')\n",
    "hf.plot_energy_consumption_by_mode(energy_consumption_df,'all CEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = energy_consumption_df[energy_consumption_df['program'] == '4c'].copy()\n",
    "mode_df = program_df[program_df['mode_confirm'] == 'drove_alone']\n",
    "mode_df.error_for_confusion.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_df = program_df[program_df['mode_confirm'] == 'shared_ride']\n",
    "mode_df.error_for_confusion.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_by_primary_mode(df,chosen_program, r_for_dataset, r, percent_error_expected,percent_error_predicted, mean_EC_all_user_labeled, output_path):\n",
    "   # Plot error totals by mode:\n",
    "    mode_expected_errors = {}\n",
    "    mode_predicted_errors = {}\n",
    "\n",
    "    for mode in df.primary_mode.unique():\n",
    "        if type(mode) == float: continue\n",
    "        user_labeled_total = sum(df[df.primary_mode == mode]['user_labeled'])\n",
    "        error_for_expected = sum(df[df.primary_mode == mode]['expected']) - user_labeled_total\n",
    "        error_for_predicted = sum(df[df.primary_mode == mode]['predicted']) - user_labeled_total\n",
    "\n",
    "        mode_expected_errors[mode] = error_for_expected\n",
    "        mode_predicted_errors[mode] = error_for_predicted\n",
    "\n",
    "    mode_expected_errors['Total'] = sum(mode_expected_errors.values())\n",
    "    mode_predicted_errors['Total'] = sum(mode_predicted_errors.values())\n",
    "    all_modes = list(mode_expected_errors.keys())\n",
    "\n",
    "    fig,axs = plt.subplots(1,2)\n",
    "    fig.set_figwidth(15)\n",
    "    fig.set_figheight(8)\n",
    "\n",
    "    title = f\"Total energy consumption errors by mode for {chosen_program}. Dataset r = {r_for_dataset:.2f}, used r = {r:.2f}, percent errors: expected: {percent_error_expected:.2f} predicted: {percent_error_predicted:.2f}\\\n",
    "    \\nuser labeled EC: {mean_EC_all_user_labeled:.2f}\"\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    axs[0].grid(axis='x')\n",
    "    axs[1].grid(axis='x')\n",
    "\n",
    "    axs[0].barh(all_modes,[mode_expected_errors[x] for x in all_modes],height=0.5)\n",
    "    axs[0].set_title(\"Confusion based error share by primary mode\")\n",
    "    axs[1].barh(all_modes,[mode_predicted_errors[x] for x in all_modes],height=0.5)\n",
    "    axs[1].set_title(\"Prediction error share by primary mode\")\n",
    "\n",
    "    #fig_file = output_path+chosen_program+\"_EC_mode_total_errors_\"+which_car_precision+ \"_for_car_precision_info\"+ \"_r_from_\"+which_r+ \"_\" +remove_outliers + \"_remove_outliers\"+\".png\"\n",
    "\n",
    "    fig_file = output_path+chosen_program+\"_EC_primary_mode_total_errors_\"+\"Mobilitynet_precision\"+\"r_from_dataset\"+\"keep_outliers.png\"\n",
    "    fig.savefig(fig_file)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the error share by primary mode for each program\n",
    "for program in energy_consumption_df['program'].unique():\n",
    "    program_df = energy_consumption_df[energy_consumption_df['program'] == program].copy()\n",
    "    chosen_program = program\n",
    "    r_for_dataset = program_proportions.loc[program]['r']\n",
    "    percent_error_expected = hf.relative_error(sum(program_df['expected']),sum(program_df['user_labeled']))*100\n",
    "    percent_error_predicted = hf.relative_error(sum(program_df['predicted']),sum(program_df['user_labeled']))*100\n",
    "    mean_EC_all_user_labeled = sum(program_df['user_labeled'])\n",
    "    output_path = \"/Users/mallen2/OpenPATH_Data/Sensing_sensitivity_analysis/\"+chosen_program+\"_\"+\"mode_error_share\"+\"/\"\n",
    "    plot_error_by_primary_mode(program_df,chosen_program, r_for_dataset, r, percent_error_expected,percent_error_predicted, mean_EC_all_user_labeled, output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the primary mode error plot for the full dataset.\n",
    "program_df = energy_consumption_df.copy()\n",
    "chosen_program = 'all'\n",
    "r_for_dataset = program_proportions.loc[chosen_program]['r']\n",
    "percent_error_expected = hf.relative_error(sum(program_df['expected']),sum(program_df['user_labeled']))*100\n",
    "percent_error_predicted = hf.relative_error(sum(program_df['predicted']),sum(program_df['user_labeled']))*100\n",
    "mean_EC_all_user_labeled = sum(program_df['user_labeled'])\n",
    "output_path = \"/Users/mallen2/OpenPATH_Data/Sensing_sensitivity_analysis/\"+chosen_program+\"_\"+\"mode_error_share\"+\"/\"\n",
    "plot_error_by_primary_mode(program_df,chosen_program, r_for_dataset, r, percent_error_expected,percent_error_predicted, mean_EC_all_user_labeled, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) get set of trips for which user mode = drove alone, primary mode = car for 4c\n",
    "# 2) calculate error.\n",
    "# 3) compare with the full error for user mode = drove alone.\n",
    "program_df = expanded_labeled_trips[expanded_labeled_trips['program'] == '4c'].copy()\n",
    "program_df = program_df.drop(\n",
    "    program_df[program_df.mode_confirm == 'air'].index\n",
    "    )\n",
    "\n",
    "EC_4c = get_EC.compute_all_EC_values(program_df,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)\n",
    "\n",
    "for mode in ['shared_ride','drove_alone']:\n",
    "    mode_df = EC_4c[EC_4c.mode_confirm == mode].copy()\n",
    "\n",
    "    # Get the total error for all the trips for which we predicted car and the actual mode was <mode>\n",
    "    error_for_expected = sum(mode_df[mode_df.primary_mode == 'car']['error_for_confusion'])\n",
    "    print(mode,error_for_expected)\n",
    "\n",
    "    # this implies that the large difference in error magnitude for 4c between shared ride and drove alone is not from load factor.\n",
    "    # shared_ride 1491.5667796053235\n",
    "    # drove_alone -1924.5901433665767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips.mode_confirm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double checking that I calculated the energy consumption error for pc correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df here is from expanded_labeled_trips.pickle, generated by place_all_trips_in_pkl.py\n",
    "pc_trips = df[df['program'] == 'pc'].copy()\n",
    "r = 1\n",
    "car_EI_load_divider = (r+1)/(r+0.5)  # aka Michael's definition of load factor.\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_EI_load_divider})\n",
    "pc_test_sample = pc_trips.sample(n = 5, random_state= np.random.RandomState(1))[['_id','distance','mode_confirm','section_modes','section_distances','os']]\n",
    "\n",
    "# Get the confusion matrices and then the EI moments from those.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "\n",
    "# Test to see if you calculated expected EC error correctly.\n",
    "pc_test_sample['EI'] = [energy_dict[MODE_MAPPING_DICT[mode]] for mode in pc_test_sample['mode_confirm']]\n",
    "pc_test_sample['unit_length_mean'] = [unit_dist_MCS_df[os][\"mean\"] for os in pc_test_sample['os']]\n",
    "#var_for_unit_L = unit_dist_MCS_df[os][\"var\"]\n",
    "confusion_EC_list = []\n",
    "for _,ct in pc_test_sample.iterrows():\n",
    "    os = ct['os']\n",
    "    modes = ct['section_modes']\n",
    "    EC = 0\n",
    "    # add each section EC to the EC for the trip.\n",
    "    for i,mode in enumerate(modes):\n",
    "        if os == \"android\":\n",
    "            mean_EI = android_EI_moments_df[\"mean(EI)\"][mode]\n",
    "            var_EI = android_EI_moments_df[\"variance(EI)\"][mode]  # variance given the inferred mode is <mode>\n",
    "        elif os == \"ios\":\n",
    "            mean_EI = ios_EI_moments_df[\"mean(EI)\"][mode]\n",
    "            var_EI = ios_EI_moments_df[\"variance(EI)\"][mode]\n",
    "        \n",
    "        EC += mean_EI*ct['unit_length_mean']*ct['section_distances'][i]*METERS_TO_MILES\n",
    "    \n",
    "    confusion_EC_list.append(EC)\n",
    "\n",
    "\n",
    "pc_test_sample['confusion_EC'] = confusion_EC_list\n",
    "\n",
    "pc_test_sample['user_EC'] = pc_test_sample['EI']*pc_test_sample['unit_length_mean']*pc_test_sample['distance']*METERS_TO_MILES\n",
    "\n",
    "total_expected, total_user_labeled = pc_test_sample['confusion_EC'].sum(), pc_test_sample['user_EC'].sum()\n",
    "\n",
    "print(f\"expected, user labeled, percent error: {total_expected, total_user_labeled, 100*hf.relative_error(total_expected,total_user_labeled)}\")\n",
    "\n",
    "# expected, user labeled, percent error: (25.386297055076234, 21.601249126657052, 17.52235672217788)\n",
    "\n",
    "all_EC = get_EC.compute_all_EC_values(pc_test_sample,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)\n",
    "assert sum(all_EC['confusion_EC']) == total_expected\n",
    "assert sum(all_EC['user_EC']) == total_user_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Writes a docker exec command to mongodump a list of object ids for the selected collection'''\n",
    "def write_mongodump_command(text_file_name, db_name, collection, object_id_list, dump_name):\n",
    "    query_file = open(f\"{text_file_name}\",\"w\")\n",
    "    query_file.write(f\"docker exec {db_name} sh -c 'mongodump --archive --db=Stage_database --collection={collection} --query=\\\"\")\n",
    "    query_file.write(\"{\\\\\\\"_id\\\\\\\":{\\\\\\\"\\\\$in\\\\\\\":[\") \n",
    "\n",
    "    # when printed to the file, the query should look like this with an oid entry for each object_id_list element:\n",
    "    #query=\"{\\\"_id\\\": {\\\"\\$in\\\": [{\\\"\\$oid\\\":\\\"<objectId>\\\"}]} }\"' > db_testing.dump\n",
    "\n",
    "    for k in range(0,len(object_id_list)):\n",
    "        if k != len(object_id_list)-1:\n",
    "            query_file.write(f\"{{\\\\\\\"\\\\$oid\\\\\\\":\\\\\\\"{str(object_id_list[k])}\\\\\\\"}},\")\n",
    "        else:\n",
    "            query_file.write(f\"{{\\\\\\\"\\\\$oid\\\\\\\":\\\\\\\"{str(object_id_list[k])}\\\\\\\"}} ] }} }}\\\"\\' > {dump_name}\")\n",
    "    query_file.close()\n",
    "write_mongodump_command('pc_trip_query.txt', 'all-ceo-db', 'Stage_analysis_timeseries', list(pc_test_sample['_id']), 'pc_test_trips.dump')\n",
    "\n",
    "# I would also need to dump the stage uuids into my test database\n",
    "# #docker exec all-ceo-db sh -c 'mongodump --archive --db=Stage_database --collection=Stage_uuids --query=\"{}\"'  > pc_Stage_uuids.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the percent error for car trips only.\n",
    "only_car_trips = df[df['mode_confirm'].isin(['drove_alone','shared_ride'])].copy()\n",
    "only_car_trips = hf.drop_unwanted_trips(only_car_trips) # double check whether you want to include not a trips.\n",
    "\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "# The following values were found by running sensing sensitivity analysis.py for each program and recording the percent error, \n",
    "# as seen in the github issue \"Estimate mean and variance of energy consumption\"\n",
    "r_value_map = {\"vail\": 0.833, \"pc\": 0.730, \"fc\": 0.713, \"cc\": 0.591, \"4c\": 0.513, \"sc\": 0.566, \"stage\": 0.667}\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(android_confusion,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(ios_confusion,energy_dict)\n",
    "\n",
    "percent_error_only_car = pd.DataFrame(columns= ['program','percent_error_for_expected','r_value'])\n",
    "for program in only_car_trips['program'].unique(): # runs a while if you forget to specify unique\n",
    "    program_df = only_car_trips[only_car_trips['program'] == program]\n",
    "    df_with_EC = get_EC.compute_all_EC_values(program_df,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)\n",
    "\n",
    "    error_and_actual = df_with_EC.sum()[['error_for_confusion','user_labeled']]\n",
    "\n",
    "    percent_error_only_car = percent_error_only_car.append({\"program\":program, 'percent_error_for_expected': error_and_actual['error_for_confusion']/error_and_actual['user_labeled'],\n",
    "                                \"r_value\": r_value_map[program]}, ignore_index=True)\n",
    "\n",
    "    #   'user_labeled', 'confusion_var', 'user_var']]\n",
    "    #program_EC_map.loc[program] = df_with_EC.sum()[['error_for_confusion', 'error_for_prediction', 'expected', 'predicted',\n",
    "    #   'user_labeled', 'confusion_var', 'user_var']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find percent of distance in ebike, after dropping not a trip.\n",
    "no_not_a_trips = drop_unwanted_trips(df)\n",
    "program_ebike_percent_map = {}\n",
    "for program in no_not_a_trips['program'].unique():\n",
    "    program_df = no_not_a_trips[no_not_a_trips['program'] == program]\n",
    "    # get the ebike ratio\n",
    "    ebike_distance = program_df.groupby('mode_confirm').sum()['distance']['pilot_ebike']\n",
    "    total_distance = program_df.groupby('mode_confirm').sum()['distance'].sum()\n",
    "\n",
    "    # store it for that program\n",
    "    program_ebike_percent_map[program] = ebike_distance/total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percent error vs r and ebike ratio\n",
    "# The following values were found by running sensing sensitivity analysis.py for each program and recording the percent error, \n",
    "# as seen in the github issue \"Estimate mean and variance of energy consumption\"\n",
    "percent_error_for_expected_map_with_not_a_trip = {\"vail\": -12.86, \"pc\": 21.7, \"fc\": 11.77, \"cc\": 5.25, \"4c\": -6.92, \"sc\": 13.21, \"stage\": -1.13}\n",
    "r_value_map = {\"vail\": 0.833, \"pc\": 0.730, \"fc\": 0.713, \"cc\": 0.591, \"4c\": 0.513, \"sc\": 0.566, \"stage\": 0.667}\n",
    "percent_error_for_expected_map_without_not_a_trip = {\"vail\": -15.99, \"pc\": 11.14, \"fc\": 2.47, \"cc\": 4.22, \"4c\": -7.55, \"sc\": 12.29, \"stage\": -1.66}\n",
    "\n",
    "\n",
    "ebike_list = [program_ebike_percent_map[program] for program in no_not_a_trips['program'].unique()]\n",
    "r_list = [r_value_map[program] for program in no_not_a_trips['program'].unique()]\n",
    "percent_error_list = [percent_error_for_expected_map_without_not_a_trip[program] for program in no_not_a_trips['program'].unique()]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(ebike_list,r_list,percent_error_list)\n",
    "ax.set_xlabel(\"ratio of ebike distance to total distance\")\n",
    "ax.set_ylabel(\"r value\")\n",
    "ax.set_zlabel(\"percent error for expected\")\n",
    "\n",
    "ax.annotate()\n",
    "\n",
    "\n",
    "#plt.zlabel(\"percent error for expected energy consumption, after dropping not a trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## (With only car trips) Plot r value vs percent error for each program.\n",
    "\n",
    "plt.scatter(percent_error_only_car['r_value'], percent_error_only_car['percent_error_for_expected'])\n",
    "plt.xlabel(\"ratio of drove alone distance to shared ride distance\")\n",
    "plt.ylabel(\"percent error for expected energy consumption, with only car trips\")\n",
    "\n",
    "for _,p in percent_error_only_car.iterrows():\n",
    "    plt.annotate(s = p['program'], xy = (p['r_value'] + 0.01,p['percent_error_for_expected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Plot r value vs percent error for each program.\n",
    "# Also plot distance in shared ride vs percent error for each program dataset.\n",
    "shared_ride_trips = expanded_labeled_trips[expanded_labeled_trips['mode_confirm'] == 'shared_ride'].copy()\n",
    "program_shared_rides = shared_ride_trips.groupby('program').sum()\n",
    "\n",
    "# The following values were found by running sensing sensitivity analysis.py for each program and recording the percent error, \n",
    "# as seen in the github issue \"Estimate mean and variance of energy consumption\"\n",
    "percent_error_for_expected_map_with_not_a_trip = {\"vail\": -12.86, \"pc\": 21.7, \"fc\": 11.77, \"cc\": 5.25, \"4c\": -6.92, \"sc\": 13.21, \"stage\": -1.13}\n",
    "r_value_map = {\"vail\": 0.833, \"pc\": 0.730, \"fc\": 0.713, \"cc\": 0.591, \"4c\": 0.513, \"sc\": 0.566, \"stage\": 0.667}\n",
    "percent_error_for_expected_map_without_not_a_trip = {\"vail\": -15.99, \"pc\": 11.14, \"fc\": 2.47, \"cc\": 4.22, \"4c\": -7.55, \"sc\": 12.29, \"stage\": -1.66}\n",
    "\n",
    "\n",
    "# \n",
    "program_shared_rides['percent_error_for_expected_without_not_a_trip'] = program_shared_rides.index.map(percent_error_for_expected_map_without_not_a_trip)\n",
    "program_shared_rides['r_value'] = program_shared_rides.index.map(r_value_map)\n",
    "\n",
    "plt.scatter(program_shared_rides['r_value'], program_shared_rides['percent_error_for_expected_without_not_a_trip'])\n",
    "plt.xlabel(\"ratio of drove alone distance to shared ride distance\")\n",
    "plt.ylabel(\"percent error for expected energy consumption, after dropping not a trip\")\n",
    "\n",
    "for _,p in program_shared_rides.iterrows():\n",
    "    plt.annotate(s = p.name, xy = (p['r_value'] + 0.01,p['percent_error_for_expected_without_not_a_trip']-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''program_shared_rides['percent_error_for_expected'] = program_shared_rides.index.map(percent_error_for_expected_map_with_not_a_trip)\n",
    "program_shared_rides['r_value'] = program_shared_rides.index.map(r_value_map)\n",
    "\n",
    "plt.scatter(program_shared_rides['r_value'], program_shared_rides['percent_error_for_expected'])\n",
    "plt.xlabel(\"ratio of drove alone distance to shared ride distance\")\n",
    "plt.ylabel(\"percent error for expected energy consumption\")\n",
    "\n",
    "for _,p in program_shared_rides.iterrows():\n",
    "    plt.annotate(s = p.name, xy = (p['r_value'] + 0.01,p['percent_error_for_expected']-1))\n",
    "\n",
    "plt.scatter(program_shared_rides['distance'], program_shared_rides['percent_error_for_expected'])\n",
    "plt.xlabel(\"shared ride distance in dataset (m)\")\n",
    "plt.ylabel(\"percent error for expected energy consumption\")\n",
    "\n",
    "for _,p in program_shared_rides.iterrows():\n",
    "    plt.annotate(s = p.name, xy = (p['distance']+10**6,p['percent_error_for_expected']-1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add primary mode and length columns to expanded labeled trips\n",
    "primary_modes = []\n",
    "primary_lengths = []\n",
    "\n",
    "for i,ct in expanded_labeled_trips.iterrows():\n",
    "    # Get primary mode\n",
    "    if len(ct[\"section_distances\"]) == 0: # for data up to 5-9-2022, there are 63 stage trips with no sensed sections.\n",
    "        expanded_labeled_trips = expanded_labeled_trips.drop(index = i) \n",
    "        print(\"dropped\")\n",
    "        continue\n",
    "    longest_section = max(ct[\"section_distances\"])\n",
    "    primary_mode = ct[\"section_modes\"][ct[\"section_distances\"]==longest_section]\n",
    "\n",
    "    # in case there are ever tied longest sections.\n",
    "    # pick the most energy intensive mode.\n",
    "    if isinstance(primary_mode,list): \n",
    "        mini_energy_dict = {x:energy_dict[MODE_MAPPING_DICT[x]] for x in primary_mode}\n",
    "        primary_mode = max(mini_energy_dict, key=mini_energy_dict.get)\n",
    "\n",
    "    primary_modes.append(primary_mode)\n",
    "    primary_lengths.append(longest_section)\n",
    "\n",
    "expanded_labeled_trips['primary_mode'] = primary_modes\n",
    "expanded_labeled_trips['primary_length'] = primary_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "#################\n",
    "#################\n",
    "# I changed this cell to not use the dataset car precision and use a drove alone divider of 1 \n",
    "# so I could look at just drove alone/bike/bus/walk trips.\n",
    "\n",
    "# for each trip, predict energy consumption with either the expectation or the prediction. compare it to the actual energy consumption.\n",
    "\n",
    "#android_EI_moments_df = pd.read_csv(\"android_EI_moments_corrected_load.csv\").set_index(\"mode\")\n",
    "#ios_EI_moments_df = pd.read_csv(\"ios_EI_moments_corrected_load.csv\").set_index(\"mode\")\n",
    "\n",
    "print(\"Computing trip level energy consumptions\")\n",
    "new_car_precision = 0.83  # 0.739 for pc, 0.83 for vail.\n",
    "android_confusion = pd.read_csv(\"android_confusion.csv\").set_index('gt_mode')\n",
    "ios_confusion = pd.read_csv(\"ios_confusion.csv\").set_index('gt_mode')\n",
    "\n",
    "#new_android_cm = cm_handling.change_precision(android_confusion,'car',new_car_precision)\n",
    "#new_ios_cm = cm_handling.change_precision(ios_confusion,'car',new_car_precision)\n",
    "\n",
    "new_android_cm = android_confusion #cm_handling.drop_rows_and_columns(android_confusion,['Train','Pilot ebike','Scooter share'],['subway','train'])\n",
    "new_ios_cm = ios_confusion #cm_handling.drop_rows_and_columns(ios_confusion,['Train','Pilot ebike','Scooter share'],['subway','train'])\n",
    "\n",
    "r = 1  # 0.91 for vail, 0.71 for pc.\n",
    "car_load_factor = (r+1)/(r+0.5)\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "android_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(new_android_cm,energy_dict)\n",
    "ios_EI_moments_df = cm_handling.get_conditional_EI_expectation_and_variance(new_ios_cm,energy_dict)\n",
    "\n",
    "expected = []\n",
    "predicted = []\n",
    "user_labeled = []\n",
    "\n",
    "confusion_based_variance = []\n",
    "user_based_variance = []\n",
    "\n",
    "predicted_dict = {}\n",
    "expected_dict = {}\n",
    "\n",
    "expected_error_list = []\n",
    "prediction_error_list = []\n",
    "\n",
    "for i,ct in expanded_labeled_trips.iterrows():\n",
    "\n",
    "    # Calculate expected energy consumption\n",
    "    trip_expected, trip_confusion_based_variance = get_EC.get_expected_EC_for_one_trip(ct,unit_dist_MCS_df,android_EI_moments_df,ios_EI_moments_df)\n",
    "\n",
    "    # Calculate predicted energy consumption\n",
    "    trip_predicted = get_EC.get_predicted_EC_for_one_trip(ct,unit_dist_MCS_df,energy_dict)[0]\n",
    "    \n",
    "    # Calculate user labeled energy consumption\n",
    "    trip_user_labeled, trip_user_based_variance = get_EC.get_user_labeled_EC_for_one_trip(ct,unit_dist_MCS_df,energy_dict)\n",
    "\n",
    "    expected.append(trip_expected)\n",
    "    predicted.append(trip_predicted)\n",
    "    user_labeled.append(trip_user_labeled)\n",
    "\n",
    "    confusion_based_variance.append(trip_confusion_based_variance)\n",
    "    user_based_variance.append(trip_user_based_variance)\n",
    "\n",
    "    user_mode = ct['mode_confirm']\n",
    "    if user_mode not in predicted_dict: predicted_dict[user_mode] = []\n",
    "    if user_mode not in expected_dict: expected_dict[user_mode] = []\n",
    "\n",
    "    prediction_error = trip_predicted - trip_user_labeled\n",
    "    expected_error = trip_expected - trip_user_labeled\n",
    "\n",
    "    expected_error_list.append(expected_error)\n",
    "    prediction_error_list.append(prediction_error)\n",
    "\n",
    "    if abs(expected_error) < 100: \n",
    "\n",
    "        predicted_dict[user_mode].append(prediction_error)\n",
    "        expected_dict[user_mode].append(expected_error)\n",
    "    else:\n",
    "        print(f\"Large EC error: EC user labeled, EC expected: {trip_user_labeled, trip_expected}\")\n",
    "        print(f\"\\tTrip info: mode_confirm,sensed,distance (mi): {ct['mode_confirm'],ct['section_modes'],ct['distance']*METERS_TO_MILES}\")\n",
    "\n",
    "def relative_error(m,t):\n",
    "    return (m-t)/t\n",
    "total_expected = sum(expected)\n",
    "total_predicted = sum(predicted)\n",
    "total_user_labeled = sum(user_labeled)\n",
    "print(f\"Total EC: expected, predicted, user labeled {total_expected:.2f},{total_predicted:.2f},{total_user_labeled:.2f}\")\n",
    "print(f\"standard deviation for expected: {np.sqrt(sum(confusion_based_variance)):.2f}\")\n",
    "print(f\"Percent error: {relative_error(sum(expected),sum(user_labeled))*100:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt_with_errors = get_EC.compute_all_EC_values(expanded_labeled_trips,unit_dist_MCS_df,energy_dict,android_EI_moments_df,ios_EI_moments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the values to expanded_labeled_trips\n",
    "\n",
    "quantiles = [99.9,0.1]\n",
    "upper, lower = np.percentile(elt_with_errors['error_for_confusion'], quantiles)\n",
    "print(f\"{quantiles[0]} and {quantiles[1]} percentiles: {upper,lower}\")\n",
    "\n",
    "# | (elt_with_errors.errors_from_confusion > upper)\n",
    "xlow_outliers = elt_with_errors[(elt_with_errors.error_for_confusion < lower) | (elt_with_errors.error_for_confusion > upper)]\n",
    "xlow_outliers[['mode_confirm','distance','error_for_confusion','primary_mode','section_modes','section_distances']]\n",
    "#[[\"mode_confirm\",\"distance\",\"section_modes\",\"section_distances\",\"errors_from_confusion\",\"errors_from_prediction\",\"confusion_sd\"]]\n",
    "\n",
    "# Drop outliers below the 0.1 percentile.\n",
    "elt_with_errors_outliers_removed = elt_with_errors.drop(xlow_outliers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_by_mode(df,chosen_program):\n",
    "   # Plot error totals by mode:\n",
    "    mode_expected_errors = {}\n",
    "    mode_predicted_errors = {}\n",
    "\n",
    "    for mode in df.mode_confirm.unique():\n",
    "        if mode == 'combination_football game, dinner, drove friend home': continue\n",
    "\n",
    "        mode_expected_errors[mode] = df[df.mode_confirm == mode]['error_for_confusion'].sum()\n",
    "        mode_predicted_errors[mode] = df[df.mode_confirm == mode]['error_for_prediction'].sum()\n",
    "\n",
    "    mode_expected_errors['Total'] = sum(mode_expected_errors.values())\n",
    "    mode_predicted_errors['Total'] = sum(mode_expected_errors.values())\n",
    "    all_modes = list(mode_expected_errors.keys())\n",
    "\n",
    "    fig,axs = plt.subplots(1,2)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(int(len(all_modes)/4) + 1)\n",
    "    fig.suptitle(f\"Total energy consumption errors by mode for {chosen_program}\")\n",
    "\n",
    "    axs[0].grid(axis='x')\n",
    "    axs[1].grid(axis='x')\n",
    "\n",
    "    mode_expected_error_list = [mode_expected_errors[x] for x in all_modes]\n",
    "    mode_predicted_error_list = [mode_predicted_errors[x] for x in all_modes]\n",
    "    axs[0].barh(all_modes,mode_expected_error_list)\n",
    "\n",
    "    for i, v in enumerate(mode_expected_error_list):\n",
    "        axs[0].text(-np.sign(v)*500, i + 0.5, f\"{v:.2f}\", color='blue', fontweight='bold')\n",
    "\n",
    "    axs[0].set_title(\"Confusion based error share by mode\")\n",
    "    axs[1].barh(all_modes,mode_predicted_error_list)\n",
    "\n",
    "    for i, v in enumerate(mode_expected_error_list):\n",
    "        axs[1].text(-np.sign(v)*50, i, f\"{v:.2f}\", color='red', fontweight='bold')\n",
    "\n",
    "    axs[1].set_title(\"Prediction error share by mode\")\n",
    "\n",
    "plot_error_by_mode(elt_with_errors, 'vail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt_with_errors_outliers_removed['isfloat'] = elt_with_errors_outliers_removed['mode_confirm'].map(lambda x: type(x) == float)\n",
    "nan_mode_confirms = elt_with_errors_outliers_removed[elt_with_errors_outliers_removed.isfloat == True]\n",
    "df = nan_mode_confirms[['mode_confirm','section_modes','distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ct in elt_with_errors_outliers_removed.iterrows():\n",
    "    if type(ct['mode_confirm']) is float:\n",
    "        elt_with_errors_outliers_removed.at[i,'mode_confirm'] = 'nan'\n",
    "    if ct['mode_confirm'] == 'nan':\n",
    "        print(ct[['mode_confirm','section_modes','distance','expected']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and sd for all user labeled and for all sensed:\n",
    "mean_EC_all_sensing = sum(elt_with_errors_outliers_removed['expected'])\n",
    "mean_EC_all_user_labeled = sum(elt_with_errors_outliers_removed['user_labeled'])\n",
    "\n",
    "sd_sensed = np.sqrt(sum(elt_with_errors_outliers_removed['confusion_var']))\n",
    "sd_users = np.sqrt(sum(elt_with_errors_outliers_removed['user_var']))\n",
    "\n",
    "# Now calculate for various random splits of the data\n",
    "# 10^3 NMC takes 10 seconds on vail to create all 4 splits.\n",
    "proportion_sensed = [0.2,0.4,0.6,0.8]\n",
    "NMC = 100#**2#**3\n",
    "\n",
    "summary_df_map = {}\n",
    "for ps in proportion_sensed:\n",
    "    \n",
    "    mean_EC_agg = []\n",
    "    var_EC_agg = []\n",
    "    error_EC_agg = []\n",
    "    for j in range(0,NMC):\n",
    "        rand_state = np.random.RandomState(1+j)\n",
    "\n",
    "        # Split the labeled trips into a user labeled dataframe and a sensed dataframe\n",
    "        user_labeled,sensed  = skm.train_test_split(elt_with_errors_outliers_removed , \n",
    "                                                    test_size = ps, # sensed\n",
    "                                                    train_size = 1-ps,  # user_labeled\n",
    "                                                    random_state= rand_state)\n",
    "        mean_EC_sensed, var_EC_sensed = sum(sensed['expected']), sum(sensed['confusion_var'])\n",
    "        \n",
    "        mean_EC_user_labeled, var_EC_user_labeled = sum(user_labeled['user_labeled']), sum(user_labeled['user_var'])\n",
    "\n",
    "        # Get the total mean and variance for the current iteration and add it to a list.\n",
    "        current_aggregate_EC = mean_EC_sensed + mean_EC_user_labeled\n",
    "        mean_EC_agg.append(current_aggregate_EC)\n",
    "        var_EC_agg.append(var_EC_sensed + var_EC_user_labeled)\n",
    "        error_EC_agg.append(current_aggregate_EC - mean_EC_all_user_labeled)\n",
    "\n",
    "        sd_EC_agg = np.sqrt(np.array(var_EC_agg))\n",
    "\n",
    "    summary_df_map[ps] = pd.DataFrame({\"mean\": mean_EC_agg, \"sd\": sd_EC_agg, 'error': error_EC_agg})\n",
    " \n",
    "        # prop var sensed\n",
    "        # prop var user labeled\n",
    "average_summaries = {}\n",
    "for ps in proportion_sensed:\n",
    "    average_across_splits_mean = np.mean(summary_df_map[ps][\"mean\"])\n",
    "    average_across_splits_sd = np.mean(summary_df_map[ps][\"sd\"])\n",
    "    average_summaries[ps] = {\"mean\": average_across_splits_mean, \"sd\": average_across_splits_sd}\n",
    "\n",
    "def get_interval(mean,sd):\n",
    "    return [mean -sd, mean,mean + sd]\n",
    "\n",
    "interval_sensed_vail = get_interval(mean_EC_all_sensing,sd_sensed)\n",
    "interval_users_vail = get_interval(mean_EC_all_user_labeled,sd_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "fig.set_figheight(6)\n",
    "\n",
    "print(f\"Prop = {0}: mean, sd: {mean_EC_all_user_labeled,sd_users}\")\n",
    "\n",
    "ax.plot([0]*3,interval_users_vail,'bo') \n",
    "j = 1\n",
    "for ps in proportion_sensed:\n",
    "    summary = average_summaries[ps]\n",
    "\n",
    "    print(f\"Prop = {ps}: mean, sd: {summary['mean'] ,summary['sd']}\")\n",
    "    x = [ps]*3\n",
    "    y = get_interval(summary[\"mean\"],summary[\"sd\"])\n",
    "    ax.plot(x,y,'bo')\n",
    "    j+=1\n",
    "\n",
    "print(f\"Prop = {1}: mean, sd: {mean_EC_all_sensing,sd_sensed}\")\n",
    "ax.plot([1]*3,interval_sensed_vail,'bo')\n",
    "ax.set_ylim([7000,11000])#([7000,11000]) [40000,70000]\n",
    "ax.set_xlabel(\"Proportion of trips using sensing as opposed to user labels\")\n",
    "ax.set_ylabel(\"Energy consumption (kWH)\")\n",
    "\n",
    "fig.suptitle(\"PC energy consumption mean +- 1 sd as percent of sensed trips increases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often is the magnitude of the aggregate error less than z standard deviations?\n",
    "z = 2\n",
    "for ps in proportion_sensed:\n",
    "    ps0x = summary_df_map[ps]   # proportion sensed = 0.x\n",
    "    print(f\"proportion sensed = {ps}: {sum(z*ps0x['sd'] > abs(ps0x['error']))/len(ps0x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt_with_errors.error_for_confusion.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [90,5]\n",
    "upper, lower = np.percentile(expected_error_list, quantiles)\n",
    "print(f\"{quantiles[0]} and {quantiles[1]} percentiles: {upper,lower}\")\n",
    "\n",
    "# | (elt_with_errors.errors_from_confusion > upper)\n",
    "low_outliers = elt_with_errors[(elt_with_errors.error_for_confusion < lower)]\n",
    "# [[\"mode_confirm\",\"distance\",\"section_modes\",\"section_distances\",\"errors_from_confusion\"]]\n",
    "\n",
    "low_outliers.mode_confirm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall errors when we have no outliers.\n",
    "remove_low = elt_with_errors.drop(xlow_outliers.index)\n",
    "summary = remove_low.sum()[['expected','predicted','user_labeled','confusion_sd']]\n",
    "percent_error = (summary['expected'] - summary['user_labeled'])/summary['user_labeled']\n",
    "\n",
    "totals = remove_low.sum()[['expected','predicted','user_labeled']]\n",
    "\n",
    "print(totals)\n",
    "print(\"\\nDifferences (look at the \\\"user_labeled\\\" value and compare with sd):\")\n",
    "print(totals.diff())\n",
    "print(f\"sd: {np.sqrt(sum(remove_low['confusion_sd']**2))}\")\n",
    "print(f\"percent error between expected and user labeled: {percent_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_grouped_values = remove_low.groupby('mode_confirm').sum()\n",
    "drove_alone = mode_grouped_values.loc['drove_alone'][['expected','predicted','user_labeled','error_for_prediction','error_for_confusion']]\n",
    "shared_ride = mode_grouped_values.loc['shared_ride'][['expected','predicted','user_labeled','error_for_prediction','error_for_confusion']]\n",
    "print('Drove alone:')\n",
    "print(drove_alone)\n",
    "print('\\n')\n",
    "print('Shared ride:')\n",
    "print(shared_ride)\n",
    "print('\\nSum:')\n",
    "print(drove_alone + shared_ride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low[['mode_confirm','section_modes','expected','predicted','user_labeled','error_for_prediction','error_for_confusion','confusion_sd','os','distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC errors\n",
    "program = 'vail'\n",
    "def plot_error_hists_by_mode(df):\n",
    "    n_plots = len(df.mode_confirm.unique())\n",
    "    fig,axs = plt.subplots(n_plots,2)\n",
    "    fig.set_figwidth(15)\n",
    "    fig.set_figheight(4*n_plots)\n",
    "    fig.suptitle(f\"{program}\")\n",
    "    i = 0\n",
    "\n",
    "    for mode in df.mode_confirm.unique():\n",
    "        if mode == 'combination_football game, dinner, drove friend home': continue\n",
    "\n",
    "        mode_expected_error = df[df.mode_confirm == mode]['error_for_confusion']\n",
    "        mode_prediction_error = df[df.mode_confirm == mode]['error_for_prediction']\n",
    "\n",
    "\n",
    "        if type(mode) == float: mode = 'nan'\n",
    "        axs[i,0].hist(mode_expected_error,bins=30)\n",
    "        axs[i,0].set_xlabel(mode + ' EC confusion based error')\n",
    "\n",
    "        axs[i,1].hist(mode_prediction_error,bins=30)\n",
    "        axs[i,1].set_xlabel(mode + ' EC prediction based error')\n",
    "        i+=1\n",
    "\n",
    "plot_error_hists_by_mode(remove_low);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low.mode_confirm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(remove_low['error_for_confusion'],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = []\n",
    "for _,ct in remove_low.iterrows():\n",
    "    u = ecwu.User(ct.user_id)\n",
    "    os.append(u.getProfile()[\"curr_platform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low['os'] = os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_EC_increase_if_primary_car = 0\n",
    "distance_sum = 0\n",
    "\n",
    "primary_mode_EC = 0\n",
    "for _,ct in remove_low.iterrows():\n",
    "\n",
    "    # Look only at the trips where primary mode was car and mode confirm was drove alone.\n",
    "    # ignore the two outlier drove alone trips below the 0.1 percentile.\n",
    "    if  (ct['primary_mode'] == 'car') & (ct['mode_confirm']=='drove_alone'):\n",
    "        # Get operating system\n",
    "        u = ecwu.User(ct.user_id)\n",
    "        os = u.getProfile()[\"curr_platform\"]\n",
    "\n",
    "        # Get OS specific trip length info.\n",
    "        mean_for_unit_L = unit_dist_MCS_df[os][\"mean\"]\n",
    "\n",
    "        section_modes = ct[\"section_modes\"]\n",
    "        n_sections = len(section_modes)\n",
    "        sections_lengths = np.array(ct[\"section_distances\"])*METERS_TO_MILES   # 1 meter = 0.000621371 miles\n",
    "\n",
    "        mean_L = sections_lengths*mean_for_unit_L\n",
    "            \n",
    "        non_car_dist = 0\n",
    "        for s in range(0,n_sections):\n",
    "            # EI mean and variance.\n",
    "\n",
    "            # Add up the non car section energy consumptions as if they were car.\n",
    "            if section_modes[s]== 'car': continue\n",
    "            non_car_dist += mean_L[s]\n",
    "\n",
    "        distance_sum += non_car_dist\n",
    "\n",
    "        mean_EI, var_EI = get_EC.get_EI_moments_for_trip('car',os,android_EI_moments_df,ios_EI_moments_df)\n",
    "        # Propagate variance for the trip\n",
    "        mean_EC = non_car_dist*mean_EI\n",
    "\n",
    "        primary_mode_EC += sum(mean_L)*mean_EI\n",
    "\n",
    "        # Add to total - follows from assumed independence of section errors.\n",
    "        mean_EC_increase_if_primary_car += mean_EC\n",
    "\n",
    "    \n",
    "\n",
    "mean_EC_increase_if_primary_car, primary_mode_EC, distance_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_car = remove_low[remove_low['primary_mode'] == 'car']\n",
    "primary_car_drove_alone = remove_low[remove_low['mode_confirm'] == 'drove_alone']\n",
    "\n",
    "primary_car_drove_alone.groupby(primary_car_drove_alone.os).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low['mode_confirm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt_with_errors.mode_confirm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the distance in each mode.\n",
    "mode_distance_df = remove_low[['mode_confirm','distance']].groupby(\"mode_confirm\").sum()\n",
    "mode_distance_df.loc['car'] + mode_distance_df.loc['drove_alone'] - mode_distance_df.loc[\"shared_ride\"]\n",
    "\n",
    "# More distance in shared ride than in drove alone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load factor estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find how our estimate changes when we have a different assumed ratio of drove alone to shared ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1 # drove_alone_load_factor\n",
    "y = 2 # shared_ride_load_factor\n",
    "r = 0.91\n",
    "\n",
    "# VMT\n",
    "v_miles_in_drove_alone = drove_alone_dist*METERS_TO_MILES*1.04 #9000 #   # drove alone mean distance in miles.  \n",
    "v_miles_in_shared_ride = shared_ride_dist*METERS_TO_MILES*1.04 #11000 #   # shared ride mean distance in miles.   # 100 -> off by 20, 1000 -> off by 200\n",
    "avg = (x+y)/2#(r+1)/(r+0.5)#(x+y)/2\n",
    "\n",
    "drove_alone_EI = 1.51517707\n",
    "shared_ride_EI = 0.757588535\n",
    "\n",
    "no_average = 1/x*drove_alone_EI*v_miles_in_drove_alone + 1/y*drove_alone_EI*v_miles_in_shared_ride\n",
    "with_average = 1/avg*drove_alone_EI*v_miles_in_drove_alone + 1/avg*drove_alone_EI*v_miles_in_shared_ride\n",
    "\n",
    "\n",
    "# without average means that we use the correct energy intensity of each mode. For \"with average\", we use the average value for both.\n",
    "print(f\"drove_alone without average, with average: {1/x*drove_alone_EI*v_miles_in_drove_alone,1/avg*drove_alone_EI*v_miles_in_drove_alone}\")   # with avg underestimates\n",
    "print(f\"shared_ride without average, with average: {1/y*drove_alone_EI*v_miles_in_shared_ride,1/avg*drove_alone_EI*v_miles_in_shared_ride}\")   # with avg overestimates\n",
    "print(no_average-with_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the precision for car based on user labels in the current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look at what the car primary mode trips are like.\n",
    "sensed_mode_dict = {}\n",
    "car_user_sensing_match = 0\n",
    "\n",
    "car_walking_cases = []\n",
    "car_trip_n_sections = []\n",
    "car_biking_cases = []\n",
    "\n",
    "walks = []\n",
    "cars = 0\n",
    "\n",
    "multi_section_cars = []\n",
    "\n",
    "# get all cases where car is not the only section.\n",
    "\n",
    "for _,ct in expanded_labeled_trips.iterrows():\n",
    "    longest_section = max(ct[\"section_distances\"])\n",
    "    primary_mode = ct[\"section_modes\"][ct[\"section_distances\"]==longest_section]\n",
    "\n",
    "    # in case there are ever tied longest sections.\n",
    "    # pick the most energy intensive mode.\n",
    "    if isinstance(primary_mode,list): \n",
    "        mini_energy_dict = {x:energy_dict[MODE_MAPPING_DICT[x]] for x in primary_mode}\n",
    "        primary_mode = max(mini_energy_dict, key=mini_energy_dict.get)\n",
    "\n",
    "    if primary_mode == 'car': cars += 1\n",
    "\n",
    "    if primary_mode == \"car\" and ct[\"mode_confirm\"] in [\"drove_alone\",\"shared_ride\",\"car\"]:\n",
    "\n",
    "        modes = ct[\"section_modes\"]\n",
    "        dists = ct[\"section_distances\"]\n",
    "\n",
    "        if len(modes) > 1:\n",
    "            multi_section_cars.append(ct)\n",
    "\n",
    "        if ct[\"section_modes\"] == ['car', 'walking']:\n",
    "            car_walking_cases.append(ct[\"section_distances\"])\n",
    "        if ct[\"section_modes\"] == ['car', 'bicycling']:\n",
    "            car_biking_cases.append(ct[\"section_distances\"])\n",
    "        elif ['car','walking'] in ct[\"section_modes\"]:\n",
    "            print(ct[\"section_modes\"])\n",
    "\n",
    "        #print(ct[\"section_modes\"])\n",
    "        #print(ct[\"section_distances\"])\n",
    "        car_user_sensing_match +=1\n",
    "\n",
    "        car_trip_n_sections.append(len(ct[\"section_distances\"]))\n",
    "\n",
    "\n",
    "    if primary_mode not in sensed_mode_dict: sensed_mode_dict[primary_mode] = 1\n",
    "    sensed_mode_dict[primary_mode] +=1\n",
    "\n",
    "# Calculate precision for car.\n",
    "car_precision = car_user_sensing_match/cars  #P(userlabel = car| predict car) = P(predict and ground truth car)/P(predict car)\n",
    "print(car_precision)   # 83% for vail, 73.9% for pueblo county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate car precision for this dataset.\n",
    "car_user_sensing_match = 0\n",
    "primary_cars = 0\n",
    "\n",
    "for _,ct in expanded_labeled_trips.iterrows():\n",
    "    longest_section = max(ct[\"section_distances\"])\n",
    "    primary_mode = ct[\"section_modes\"][ct[\"section_distances\"]==longest_section]\n",
    "\n",
    "    # in case there are ever tied longest sections.\n",
    "    # pick the most energy intensive mode.\n",
    "    if isinstance(primary_mode,list): \n",
    "        mini_energy_dict = {x:energy_dict[MODE_MAPPING_DICT[x]] for x in primary_mode}\n",
    "        primary_mode = max(mini_energy_dict, key=mini_energy_dict.get)\n",
    "\n",
    "    if primary_mode == 'car': primary_cars += 1\n",
    "\n",
    "    if primary_mode == \"car\" and ct[\"mode_confirm\"] in [\"drove_alone\",\"shared_ride\",\"car\"]:\n",
    "        car_user_sensing_match +=1\n",
    "\n",
    "# Calculate precision for car.\n",
    "car_precision = car_user_sensing_match/primary_cars  #P(userlabel = car| predict car) = P(predict and ground truth car)/P(predict car)\n",
    "print(car_precision)   # 83% for vail, 73.9% for pueblo county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label_to_sensing_map = {\n",
    "    'drove_alone': 'car',\n",
    "    'shared_ride': 'car',\n",
    "    'pilot_ebike': 'bicycling',\n",
    "    'walk': 'walking',\n",
    "    'bus': 'bus',\n",
    "    'not_a_trip': 'no_sensed',\n",
    "    'car': 'car',\n",
    "    'taxi': 'car',\n",
    "    'bike': 'bicycling',\n",
    "    'train': 'train',\n",
    "    'subway': 'subway',\n",
    "    'air': 'air_or_hsr'\n",
    "}\n",
    "\n",
    "gis_sensed_modes = {0 : 'no_sensed',    # UNKNOWN  #NOTE: this is important info to mention.\n",
    "        1 : 'walking',    # WALKING\n",
    "        2 : 'bicycling',    # BICYCLING\n",
    "        3 : 'bus',        # BUS\n",
    "        4 : 'train',      # TRAIN\n",
    "        5 : 'car',        # CAR\n",
    "        6 : 'air_or_hsr', # AIR_OR_HSR\n",
    "        7 : 'subway',      # SUBWAY\n",
    "        8 : 'train',      # TRAM\n",
    "        9 : 'train',      # LIGHT_RAIL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find the confusion matrix for the current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklearn_metrics\n",
    "\n",
    "confusion_ready = expanded_labeled_trips.dropna()\n",
    "user_labels = confusion_ready['mode_confirm']\n",
    "sensed_labels = confusion_ready['primary_mode']\n",
    "cm_user_v_sensed = sklearn_metrics.confusion_matrix(user_labels,sensed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_user_v_sensed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_types = [type(x) for x in expanded_labeled_trips['mode_confirm']]\n",
    "type(confusion_ready['mode_confirm'].iloc[mc_types.index(float)])\n",
    "\n",
    "# so mode confirm has an nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensed_user = expanded_labeled_trips[['primary_mode','mode_confirm']]\n",
    "sensed_user[sensed_user['mode_confirm']== 'electric_vehicle']  # sensed as walking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_labeled_trips['mode_confirm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_diffs = []\n",
    "# Verify that section sums are equal to trip lengths.\n",
    "for _,ct in expanded_labeled_trips.iterrows():\n",
    "    section_sum = sum(ct[\"section_distances\"])\n",
    "    trip_length = ct[\"distance\"]\n",
    "\n",
    "    length_diffs.append(trip_length-section_sum)\n",
    "    #np.testing.assert_approx_equal(section_sum,ct['distance'],5)\n",
    "plt.hist(length_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_mode = [\"walking\",\"car\"]\n",
    "mini_energy_dict = {x:energy_dict[MODE_MAPPING_DICT[x]] for x in primary_mode}\n",
    "primary_mode = max(mini_energy_dict, key=mini_energy_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_sum = 0\n",
    "for trip in car_walking_cases:\n",
    "    print(trip)\n",
    "    walk_sum += trip[1]\n",
    "# This is the increase in EC if we count walk sections for primary car trips as car.\n",
    "walk_sum*1.13*1.04*METERS_TO_MILES - walk_sum*0.01*1.04*METERS_TO_MILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell: \n",
    "# The primary section is the only section used.\n",
    "# I ignore shared rides.\n",
    "# Car load factor to create the EI moments dataframe: 1\n",
    "# Car precision is increased stepwise by 0.1, with bus taking the rest of the labels. (see store_errors.ipynb).\n",
    "# In this analysis, the adjusted car precision is the same for both ios and android.\n",
    "\n",
    "# drop shared rides.\n",
    "elt = expanded_labeled_trips.copy()\n",
    "no_shared_rides = elt.drop(elt[elt.mode_confirm == \"shared_ride\"].index)\n",
    "\n",
    "prediction_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, # these do not get used when we only use the prediction.\n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=True,\n",
    "        only_primary_section=True)\n",
    "\n",
    "for j in range(0,4):\n",
    "    print(f\"car precision: {0.45+ 0.1*(j+1)}\")\n",
    "    precision_adj_android_EI_moments_df = pd.read_csv(\"android_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "    precision_adj_ios_EI_moments_df = pd.read_csv(\"ios_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "\n",
    "    # Looking only at the primary section EC consumption and applying the user or sensed label to it.\n",
    "    confusion_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "            precision_adj_android_EI_moments_df, \n",
    "            precision_adj_ios_EI_moments_df, \n",
    "            gis_sensed_modes,energy_dict,\n",
    "            using_predictions=False,\n",
    "            only_primary_section=True)\n",
    "\n",
    "    print(f\"prediction,confusion based: {prediction_EC_primary_section[0],confusion_EC_primary_section[0]}\")\n",
    "\n",
    "user_no_shared_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,False, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, # these do not get used if looking at user labels.\n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=False,\n",
    "        only_primary_section=True)\n",
    "print(f\"User EC: {user_no_shared_EC_primary_section[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell: \n",
    "# The primary mode is applied to the entire trip.\n",
    "# I ignore shared rides.\n",
    "# Car load factor to create the EI moments dataframe: 1\n",
    "# Car precision is increased stepwise by 0.1, with bus taking the rest of the labels. (see store_errors.ipynb).\n",
    "# In this analysis, the adjusted car precision is the same for both ios and android.\n",
    "\n",
    "# Ensure that a predicted car trip is treated as drove alone\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "load_factor = 1\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/load_factor})\n",
    "\n",
    "# drop shared rides.\n",
    "elt = expanded_labeled_trips.copy()\n",
    "no_shared_rides = elt.drop(elt[elt.mode_confirm == \"shared_ride\"].index)\n",
    "\n",
    "prediction_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, # these do not get used when we only use the prediction.\n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=True,\n",
    "        only_primary_section=False)\n",
    "\n",
    "for j in range(0,4):\n",
    "    print(f\"car precision: {0.45+ 0.1*(j+1)}\")\n",
    "    precision_adj_android_EI_moments_df = pd.read_csv(\"android_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "    precision_adj_ios_EI_moments_df = pd.read_csv(\"ios_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "\n",
    "    # Looking only at the primary section EC consumption and applying the user or sensed label to it.\n",
    "    confusion_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "            precision_adj_android_EI_moments_df, \n",
    "            precision_adj_ios_EI_moments_df, \n",
    "            gis_sensed_modes,energy_dict,\n",
    "            using_predictions=False,\n",
    "            only_primary_section=False)\n",
    "\n",
    "    print(f\"prediction,confusion based: {prediction_EC_primary_section[0],confusion_EC_primary_section[0]}\")\n",
    "\n",
    "user_no_shared_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,False, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, # these do not get used if looking at user labels.\n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=False,\n",
    "        only_primary_section=False)\n",
    "print(f\"User EC: {user_no_shared_EC_primary_section[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell: \n",
    "# All sections are used.\n",
    "# I ignore shared rides.\n",
    "# Car load factor to create the EI moments dataframe: 1\n",
    "# Car precision is increased stepwise by 0.1, with bus taking the rest of the labels. (see store_errors.ipynb).\n",
    "# In this analysis, the adjusted car precision is the same for both ios and android.\n",
    "\n",
    "# Ensure that a predicted car trip is treated as drove alone\n",
    "drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "load_factor = 1\n",
    "energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/load_factor})\n",
    "\n",
    "# drop shared rides.\n",
    "elt = expanded_labeled_trips.copy()\n",
    "no_shared_rides = elt.drop(elt[elt.mode_confirm == \"shared_ride\"].index)\n",
    "\n",
    "mean_EC_naive_no_shared, var_EC_naive_no_shared, avg_EI_no_shared= get_aggregate_EC_with_extras(no_shared_rides,True, unit_dist_MCS_df, \n",
    "        android_EI_moments_df, # not used in prediction based calculation.\n",
    "        ios_EI_moments_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        use_naive_sensing_prediction=True,\n",
    "        car_load_factor = 1)\n",
    "\n",
    "for j in range(0,4):\n",
    "    print(f\"car precision: {0.45+ 0.1*(j+1)}\")\n",
    "    precision_adj_android_EI_moments_df = pd.read_csv(\"android_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "    precision_adj_ios_EI_moments_df = pd.read_csv(\"ios_EI_moments_no_shared_ride_car_precision_adjustment_\"+ str(j) + \".csv\").set_index(\"mode\")\n",
    "\n",
    "\n",
    "    mean_EC_no_shared_expected, var_EC_no_shared_expected = get_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df,\n",
    "            precision_adj_android_EI_moments_df, \n",
    "            precision_adj_ios_EI_moments_df, \n",
    "            gis_sensed_modes,energy_dict)\n",
    "\n",
    "    print(f\"prediction,confusion based: {mean_EC_naive_no_shared,mean_EC_no_shared_expected}\")\n",
    "\n",
    "\n",
    "mean_EC_no_shared_users,_ = get_aggregate_EC(no_shared_rides,False, unit_dist_MCS_df,\n",
    "        precision_adj_android_EI_moments_df, \n",
    "        precision_adj_ios_EI_moments_df, \n",
    "        gis_sensed_modes,energy_dict)\n",
    "print(f\"User EC: {mean_EC_no_shared_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look at the values for primary sections when we have no shared rides and the confusion matrices in Gabe's paper.\n",
    "# ie load factor 1 for sensed car.\n",
    "android_EI_moments_no_shared_ride_df = pd.read_csv(\"android_EI_moments_no_shared_ride.csv\").set_index(\"mode\")\n",
    "ios_EI_moments_no_shared_ride_df = pd.read_csv(\"ios_EI_moments_no_shared_ride.csv\").set_index(\"mode\")\n",
    "\n",
    "# drop shared rides.\n",
    "elt = expanded_labeled_trips.copy()\n",
    "no_shared_rides = elt.drop(elt[elt.mode_confirm == \"shared_ride\"].index)\n",
    "\n",
    "prediction_no_shared_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, \n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=True,\n",
    "        only_primary_section=True)\n",
    "\n",
    "confusion_no_shared_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, \n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=False,\n",
    "        only_primary_section=True)\n",
    "\n",
    "user_no_shared_EC_primary_section = get_primary_mode_aggregate_EC(no_shared_rides,False, unit_dist_MCS_df, \n",
    "        android_EI_moments_no_shared_ride_df, \n",
    "        ios_EI_moments_no_shared_ride_df, \n",
    "        gis_sensed_modes,energy_dict,\n",
    "        using_predictions=False,\n",
    "        only_primary_section=True)\n",
    "\n",
    "print(\"prediction, confusion EC for no shared rides and only primary sections\")\n",
    "prediction_no_shared_EC_primary_section[0],confusion_no_shared_EC_primary_section[0], user_no_shared_EC_primary_section[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_EI_moments_no_shared_ride_df = pd.read_csv(\"android_EI_moments_no_shared_ride.csv\").set_index(\"mode\")\n",
    "ios_EI_moments_no_shared_ride_df = pd.read_csv(\"ios_EI_moments_no_shared_ride.csv\").set_index(\"mode\")\n",
    "android_EI_moments_no_shared_ride_df,ios_EI_moments_no_shared_ride_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_EC_primary_section[0],user_EC[0],confusion_EC_primary_section[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff([prediction_EC_primary_section[0],user_EC[0],confusion_EC_primary_section[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_EC_primary_trip = get_primary_mode_aggregate_EC(expanded_labeled_trips,True, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict,using_predictions=True,only_primary_section=False)\n",
    "#confusion_EC_primary_trip = get_primary_mode_aggregate_EC(expanded_labeled_trips,True, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict,False,False)\n",
    "#user_EC_trip = get_primary_mode_aggregate_EC(expanded_labeled_trips,False, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict,False,False)\n",
    "prediction_EC_primary_trip[0],user_EC_trip[0],confusion_EC_primary_trip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff([prediction_EC_primary_trip[0],user_EC_trip[0],confusion_EC_primary_trip[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop air trips\n",
    "# Constructing the propagation function.\n",
    "\n",
    "use_sensing_only = True\n",
    "\n",
    "# probably should get segments ahead of time and store in the database.\n",
    "\n",
    "# get_aggregate_EC(trips_df, only_sensing, unit_dist_MCS, android_EI_moments, ios_EI_moments,gis_sensed_modes, energy_dict):\n",
    "mean_EC_all_sensing_vail, var_EC_all_sensing_vail = get_aggregate_EC(expanded_labeled_trips,use_sensing_only, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict)\n",
    "\n",
    "mean_EC_all_user_labeled_vail, var_EC_all_user_labeled_vail = get_aggregate_EC(expanded_labeled_trips,False, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with no shared rides.\n",
    "elt = expanded_labeled_trips.copy()\n",
    "no_shared_rides = elt.drop(elt[elt.mode_confirm == \"shared_ride\"].index)\n",
    "\n",
    "# use a confusion matrix that has \n",
    "android_EI_moments_no_shared_ride, ios_EI_moments_no_shared_ride = (pd.read_csv(\"android_EI_moments_no_shared_ride.csv\").set_index(\"mode\"),pd.read_csv(\"ios_EI_moments_no_shared_ride.csv\").set_index(\"mode\"))\n",
    "mean_EC_no_shared, var_EC_no_shared = get_aggregate_EC(no_shared_rides,True, unit_dist_MCS_df, android_EI_moments_no_shared_ride, ios_EI_moments_no_shared_ride, gis_sensed_modes,energy_dict)\n",
    "mean_EC_no_shared_users, var_EC_no_shared_users = get_aggregate_EC(no_shared_rides,False, unit_dist_MCS_df, android_EI_moments_no_shared_ride, ios_EI_moments_no_shared_ride, gis_sensed_modes,energy_dict)\n",
    "mean_EC_naive_no_shared, var_EC_naive_no_shared, avg_EI_no_shared= get_aggregate_EC_with_extras(no_shared_rides,True, unit_dist_MCS_df, android_EI_moments_no_shared_ride, ios_EI_moments_no_shared_ride, gis_sensed_modes,energy_dict,use_naive_sensing_prediction=True)\n",
    "print(f\"EC from: sensing with confusion, sensing prediction, user labels:{mean_EC_no_shared,mean_EC_naive_no_shared,mean_EC_no_shared_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_EC_naive_no_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_EC_naive_no_shared, var_EC_naive_no_shared, avg_EI_no_shared= get_aggregate_EC_with_extras(no_shared_rides,True, unit_dist_MCS_df, android_EI_moments_no_shared_ride, ios_EI_moments_no_shared_ride, gis_sensed_modes,energy_dict,use_naive_sensing_prediction=True,car_load_factor = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_EC_with_extras(trips_df, only_sensing, unit_dist_MCS, android_EI_moments, ios_EI_moments,gis_sensed_modes, energy_dict, use_naive_sensing_prediction=False, car_load_factor=1.5):\n",
    "    # requires the trips dataframe to have expanded labeled trips\n",
    "\n",
    "    # The load factor here only updates the predicted mode EI, not the confusion EI. See store_errors.ipynb to save EI_moments dataframes with different load factors.\n",
    "    drove_alone_EI = energy_dict[\"Gas Car, drove alone\"]\n",
    "    energy_dict.update({\"Gas Car, sensed\": drove_alone_EI/car_load_factor})\n",
    "\n",
    "    mean_EC_agg = 0    # aggregate energy consumption\n",
    "    var_EC_agg = 0  \n",
    "    sum_sensed_mean_EI = 0\n",
    "    N_sections = 0\n",
    "\n",
    "    sum_labeled_mean_EI = 0\n",
    "    n_trips = 0\n",
    "\n",
    "    ios_count = 0\n",
    "    android_count = 0\n",
    "\n",
    "    for  _,ct in trips_df.iterrows():\n",
    "        # Get operating system\n",
    "        u = ecwu.User(ct.user_id)\n",
    "        os = u.getProfile()[\"curr_platform\"]\n",
    "\n",
    "        if os == \"ios\": \n",
    "            ios_count+=1 \n",
    "        else: \n",
    "            android_count += 1\n",
    "\n",
    "        # Get OS specific trip length info.\n",
    "        mean_for_unit_L = unit_dist_MCS_df[os][\"mean\"]\n",
    "        var_for_unit_L = unit_dist_MCS_df[os][\"var\"]\n",
    "\n",
    "\n",
    "        # Get trip mode info.\n",
    "        # Later the condition will be whether the model chosen is sensing.\n",
    "        if only_sensing == True:\n",
    "            # Get segments for the trip.\n",
    "            n_sections = len(ct[\"section_modes\"])\n",
    "            section_modes = ct[\"section_modes\"]\n",
    "            sections_lengths = np.array(ct[\"section_distances\"])*METERS_TO_MILES   # 1 meter = 0.000621371 miles\n",
    "\n",
    "            mean_L = sections_lengths*mean_for_unit_L\n",
    "            var_L = sections_lengths**2 * var_for_unit_L\n",
    "            \n",
    "            for s in range(0,n_sections):\n",
    "                # EI mean and variance.\n",
    "                # Perhaps it would be better to keep the moments in the same file?\n",
    "\n",
    "                if section_modes[s] == \"air_or_hsr\": continue\n",
    "\n",
    "                if use_naive_sensing_prediction:\n",
    "                    #mean_EI = energy_dict[MODE_MAPPING_DICT[section_modes[s]]]\n",
    "                    if section_modes[s] == 'car':\n",
    "                        mean_EI = energy_dict['Gas Car, sensed']\n",
    "                    else:\n",
    "                        mean_EI = energy_dict[MODE_MAPPING_DICT[section_modes[s]]]\n",
    "                    var_EI = 0\n",
    "                else:\n",
    "                    # Later: switch to a map style function.\n",
    "                    mean_EI, var_EI = get_EI_moments_for_trip(section_modes[s],os,android_EI_moments,ios_EI_moments)\n",
    "\n",
    "                sum_sensed_mean_EI += mean_EI\n",
    "                N_sections += 1\n",
    "\n",
    "                # Propagate variance for the trip\n",
    "                mean_EC = mean_L[s]*mean_EI\n",
    "                var_EC = var_EI*mean_L[s]**2 + var_L[s]*mean_EI**2\n",
    "\n",
    "                # Add to total - follows from assumed independence of section errors.\n",
    "                mean_EC_agg += mean_EC\n",
    "                var_EC_agg += var_EC\n",
    "        \n",
    "        # use user labels.\n",
    "        else:\n",
    "            mode = ct[\"mode_confirm\"]  # need to make sure you convert it to an appropriate energy intensity.\n",
    "\n",
    "            if mode not in MODE_MAPPING_DICT or mode == np.nan: continue\n",
    "            if MODE_MAPPING_DICT[mode] == \"Air\": continue\n",
    "            EI = energy_dict[MODE_MAPPING_DICT[mode]]\n",
    "\n",
    "            sum_labeled_mean_EI += EI\n",
    "            n_trips += 1\n",
    "\n",
    "            length = ct[\"distance\"]*METERS_TO_MILES\n",
    "            mean_L = length* mean_for_unit_L  \n",
    "            var_L = length**2 * var_for_unit_L\n",
    "\n",
    "            mean_EC_agg += EI*mean_L\n",
    "            var_EC_agg +=  EI*var_L\n",
    "\n",
    "        avg_EI = sum_sensed_mean_EI/N_sections if only_sensing == True else sum_labeled_mean_EI/n_trips\n",
    "\n",
    "    #print(f\"ios vs android trip count: {ios_count,android_count}\")\n",
    "    #print(f\"Sum of EIs (sensed, user labeled): {sum_sensed_mean_EI,sum_labeled_mean_EI}\")   # could weight by distance\n",
    "    #print(f\"number of sections or trips: {N_sections,n_trips}\")\n",
    "    #print(air_count)\n",
    "    return mean_EC_agg, var_EC_agg, avg_EI\n",
    "\n",
    "#mean_EC_naive_sensing_vail, var_EC_naive_sensing_vail, avg_EI_sensed_naive = get_aggregate_EC_with_extras(expanded_labeled_trips,use_sensing_only, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict,use_naive_sensing_prediction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## OLD SENSITIVITY ANALYSIS\n",
    "##########\n",
    "# Split the data.\n",
    "# 10^3 NMC takes 10 seconds on vail to create all 4 splits.\n",
    "proportion_sensed = [0.2,0.4,0.6,0.8]\n",
    "NMC = 10#**2#**3\n",
    "\n",
    "summary_df_map = {}\n",
    "for ps in proportion_sensed:\n",
    "    \n",
    "    mean_EC_agg = []\n",
    "    var_EC_agg = []\n",
    "    for j in range(0,NMC):\n",
    "        rand_state = np.random.RandomState(1+j)\n",
    "\n",
    "        # Split the labeled trips into a user labeled dataframe and a sensed dataframe\n",
    "        user_labeled,sensed  = skm.train_test_split(expanded_labeled_trips, \n",
    "                                                    test_size = ps, # sensed\n",
    "                                                    train_size = 1-ps,  # user_labeled\n",
    "                                                    random_state= rand_state)\n",
    "        mean_EC_sensed, var_EC_sensed = \\\n",
    "            get_aggregate_EC(sensed,True, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict)\n",
    "        \n",
    "        mean_EC_user_labeled, var_EC_user_labeled = \\\n",
    "            get_aggregate_EC(user_labeled,False, unit_dist_MCS_df, android_EI_moments_df, ios_EI_moments_df, gis_sensed_modes,energy_dict)\n",
    "\n",
    "        mean_EC_agg.append(mean_EC_sensed + mean_EC_user_labeled)\n",
    "        var_EC_agg.append(var_EC_sensed + var_EC_user_labeled)\n",
    "\n",
    "        sd_EC_agg = np.sqrt(np.array(var_EC_agg))\n",
    "\n",
    "        summary_df_map[ps] = pd.DataFrame({\"mean\": mean_EC_agg, \"sd\": sd_EC_agg})\n",
    "        \n",
    "        # prop var sensed\n",
    "        # prop var user labeled\n",
    "average_summaries = {}\n",
    "for ps in proportion_sensed:\n",
    "    average_across_splits_mean = np.mean(summary_df_map[ps][\"mean\"])\n",
    "    average_across_splits_sd = np.mean(summary_df_map[ps][\"sd\"])\n",
    "    average_summaries[ps] = {\"mean\": average_across_splits_mean, \"sd\": average_across_splits_sd}\n",
    "average_summaries\n",
    "\n",
    "sd_sensed = np.sqrt(var_EC_all_sensing_vail)\n",
    "sd_users = np.sqrt(var_EC_all_user_labeled_vail)\n",
    "\n",
    "def get_interval(mean,sd):\n",
    "    return [mean -sd, mean,mean + sd]\n",
    "\n",
    "interval_sensed_vail = get_interval(mean_EC_all_sensing_vail,sd_sensed)\n",
    "interval_users_vail = get_interval(mean_EC_all_user_labeled_vail,sd_users)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_figheight(6)\n",
    "\n",
    "ax.plot([0]*3,interval_users_vail,'bo') \n",
    "j = 1\n",
    "for ps in proportion_sensed:\n",
    "    summary = average_summaries[ps]\n",
    "    x = [ps]*3\n",
    "    y = get_interval(summary[\"mean\"],summary[\"sd\"])\n",
    "    ax.plot(x,y,'bo')\n",
    "    j+=1\n",
    "ax.plot([1]*3,interval_sensed_vail,'bo')\n",
    "ax.set_ylim([4000,12000])\n",
    "ax.set_xlabel(\"Proportion of trips using sensing as opposed to user labels\")\n",
    "\n",
    "fig.suptitle(\"Energy consumption mean +- 1 sd as percent of sensed trips increases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal version of the plots\n",
    "import matplotlib.pyplot as plt\n",
    "fig,axs = plt.subplots(6,sharex=True)\n",
    "fig.set_figheight(10)\n",
    "y = [0,0,0]\n",
    "axs[0].plot(interval_users_vail,y,'bo') \n",
    "j = 1\n",
    "for ps in proportion_sensed:\n",
    "    summary = average_summaries[ps]\n",
    "    x = [ps]*3\n",
    "    y = get_interval(summary[\"mean\"],summary[\"sd\"])\n",
    "    axs[j].plot(x,y,'bo')\n",
    "    j+=1\n",
    "axs[5].plot(interval_sensed_vail,y,'bo')\n",
    "\n",
    "fig.suptitle(\"0 -> 1 proportion sensed in increments of 0.2 (mean +- 1 sd)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_EC_agg = np.sqrt(np.array(var_EC_agg))\n",
    "\n",
    "summary_df = pd.DataFrame({\"mean\": mean_EC_agg, \"sd\": sd_EC_agg}).set_index(proportion_sensed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('emission-private-eval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73ac5b45931ab4dd3f8e07a8d0e5daf0146eed4821bf42374f6ac6fa4af28c83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
