{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013ae92f",
   "metadata": {},
   "source": [
    "# TSDC Data Cleaning\n",
    "\n",
    "This notebook is set up to intake the files from the TSDC records and process them according to the data cleaning outlined in our paper\n",
    "\n",
    "Current count is precise num users and up by 3 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b5e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path configuration\n",
    "to_data_parent = \"../Data/abby_ceo\" #path to the parent folder, should contain program subfolders\n",
    "to_mini_data = \"../Data/mini_pilot/data\" #path to the mini data folder, contains an analysis trips file\n",
    "to_data_folder = \"../Data\" #data folder, where composite data files will be written/read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ed2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from data_utilities import *\n",
    "\n",
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "%store -r df_ei\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "%store -r dic_fuel\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_fuel = defaultdict(lambda: 'Other',dic_fuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9386ed",
   "metadata": {},
   "source": [
    "## Mini Pilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2125c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_confirmed_trips = pd.read_csv(to_mini_data + '/analysis_confirmed_trip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ed4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492 total minipilot trips\n",
      "13 total minipilot users\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_confirmed_trips), \"total minipilot trips\")\n",
    "print(mini_confirmed_trips.perno.nunique(), \"total minipilot users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4446b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2403 labeled minipilot trips\n",
      "12 minipilot users who labeled\n"
     ]
    }
   ],
   "source": [
    "## remove trips with no label and count again\n",
    "labeled_mini = mini_confirmed_trips[mini_confirmed_trips.data_user_input_mode_confirm.notna()]\n",
    "labeled_mini = mini_confirmed_trips[mini_confirmed_trips.data_user_input_purpose_confirm.notna()]\n",
    "\n",
    "print(len(labeled_mini), \"labeled minipilot trips\") #only 25 over data used in paper\n",
    "print(labeled_mini.perno.nunique(), \"minipilot users who labeled\")#same as data used in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = labeled_mini.copy()\n",
    "\n",
    "#first, add the cleaned mode\n",
    "mini_data['Mode_confirm']= mini_data['data_user_input_mode_confirm'].map(dic_re)\n",
    "\n",
    "#second, add the cleaned replaced mode ASSUMES PROGRAM\n",
    "mini_data['Replaced_mode']= mini_data['data_user_input_replaced_mode'].map(dic_re)\n",
    "\n",
    "#third, add the cleaned purpose\n",
    "mini_data['Trip_purpose']= mini_data['data_user_input_purpose_confirm'].map(dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb50807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2354 trips once not a trip is removed\n"
     ]
    }
   ],
   "source": [
    "# Combine variable categories\n",
    "mini_data = mini_data.replace('Gas Car, drove alone', 'Car')\n",
    "mini_data = mini_data.replace('Gas Car, with others', 'Shared Car')\n",
    "mini_data = mini_data.replace('Bikeshare', 'Shared Micromobility')\n",
    "mini_data = mini_data.replace('Scooter share', 'Shared Micromobility')\n",
    "mini_data = mini_data.replace('Regular Bike', 'Personal Micromobility')\n",
    "mini_data = mini_data.replace('Skate board', 'Personal Micromobility')\n",
    "mini_data = mini_data.replace('Train', 'Transit')\n",
    "mini_data = mini_data.replace('Free Shuttle', 'Transit')\n",
    "mini_data = mini_data.replace('Bus', 'Transit')\n",
    "mini_data = mini_data.replace('Walk', 'Walk')\n",
    "mini_data = mini_data.replace('Taxi/Uber/Lyft', 'Ridehail')\n",
    "mini_data = mini_data.replace('Pilot ebike', 'E-Bike')\n",
    "\n",
    "#filter out 'not a trip' trips\n",
    "mini_data = mini_data[~mini_data['Mode_confirm'].isin(['Not a Trip'])]\n",
    "mini_data = mini_data[~mini_data['Replaced_mode'].isin(['Not a Trip'])]\n",
    "mini_data = mini_data[~mini_data['Trip_purpose'].isin(['not_a_trip'])]\n",
    "\n",
    "print(len(mini_data), \"trips once not a trip is removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b90e0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data.loc[mini_data['Mode_confirm']=='Personal Micromobility', 'Mode_confirm'] = 'Other'\n",
    "mini_data.loc[mini_data['Mode_confirm']=='Shared Micromobility', 'Mode_confirm'] = 'Other'\n",
    "\n",
    "all_trips = mini_data.groupby(['Mode_confirm'], as_index=False).count()[['Mode_confirm','data_distance']]\n",
    "all_trips['proportion'] = all_trips['data_distance'] / np.sum(all_trips.data_distance)\n",
    "all_trips['trip_type'] = 'All Trips'\n",
    "\n",
    "work_trips = mini_data[mini_data['Trip_purpose']=='Work'].copy()\n",
    "work_trips = work_trips.groupby(['Mode_confirm'], as_index=False).count()[['Mode_confirm','data_distance']]\n",
    "work_trips['proportion'] = work_trips['data_distance'] / np.sum(work_trips.data_distance)\n",
    "work_trips['trip_type'] = 'Work Trips'\n",
    "work_trips.loc[1.5] = 'Other', 0, 0, 'Work Trips'\n",
    "work_trips = work_trips.sort_index().reset_index(drop=True)\n",
    "\n",
    "mini_data = pd.concat([all_trips,work_trips])\n",
    "mini_data['Dataset'] = 'Minipilot'\n",
    "mini_data.columns = ['Mode','Count','Proportion','Trip Type', \"Dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fccc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>Trip Type</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>477</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E-bike</td>\n",
       "      <td>776</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>28</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridehail</td>\n",
       "      <td>65</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shared Car</td>\n",
       "      <td>685</td>\n",
       "      <td>0.290994</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transit</td>\n",
       "      <td>155</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walk</td>\n",
       "      <td>168</td>\n",
       "      <td>0.071368</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>110</td>\n",
       "      <td>0.295699</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E-bike</td>\n",
       "      <td>134</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridehail</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shared Car</td>\n",
       "      <td>101</td>\n",
       "      <td>0.271505</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transit</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walk</td>\n",
       "      <td>23</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mode  Count  Proportion   Trip Type    Dataset\n",
       "0         Car    477    0.202634   All Trips  Minipilot\n",
       "1      E-bike    776    0.329652   All Trips  Minipilot\n",
       "2       Other     28    0.011895   All Trips  Minipilot\n",
       "3    Ridehail     65    0.027613   All Trips  Minipilot\n",
       "4  Shared Car    685    0.290994   All Trips  Minipilot\n",
       "5     Transit    155    0.065845   All Trips  Minipilot\n",
       "6        Walk    168    0.071368   All Trips  Minipilot\n",
       "0         Car    110    0.295699  Work Trips  Minipilot\n",
       "1      E-bike    134    0.360215  Work Trips  Minipilot\n",
       "2       Other      0    0.000000  Work Trips  Minipilot\n",
       "3    Ridehail      1    0.002688  Work Trips  Minipilot\n",
       "4  Shared Car    101    0.271505  Work Trips  Minipilot\n",
       "5     Transit      3    0.008065  Work Trips  Minipilot\n",
       "6        Walk     23    0.061828  Work Trips  Minipilot"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_data #trip breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb06aa",
   "metadata": {},
   "source": [
    "### matching minis to survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4538cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492 minpilot trips\n",
      "15 minpilot surveys\n",
      "13 minpilot users\n",
      "15 surveys after dropping null\n",
      "12 minipilot users with surveys\n",
      "3662 trips after pairing with surveys\n"
     ]
    }
   ],
   "source": [
    "mini_trips = pd.read_csv(to_mini_data + '/analysis_confirmed_trip.csv')\n",
    "mini_surveys = pd.read_csv(to_mini_data + '/survey_household.csv')\n",
    "\n",
    "print(len(mini_trips), \"minpilot trips\")\n",
    "print(len(mini_surveys), \"minpilot surveys\") #15 surveys\n",
    "print(mini_trips.perno.nunique(), \"minpilot users\") #13 unique users\n",
    "\n",
    "socio_data = mini_surveys[~mini_surveys.perno.isnull()]\n",
    "print(len(socio_data), \"surveys after dropping null\")\n",
    "\n",
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['perno', 'timestamp'])\n",
    "socio_data.drop_duplicates(subset=['perno'], keep='last', inplace=True)\n",
    "socio_data['user_id_socio'] = socio_data.perno\n",
    "socio_data.user_id_socio = [i.replace('-','') for i in socio_data.user_id_socio] # remove all dashes from strings\n",
    "socio_data = socio_data.drop(labels='perno', axis=1)\n",
    "\n",
    "# Lose some trips due to people with no survey responses\n",
    "mini_trips['user_id_socio'] = mini_trips.perno.astype(str)\n",
    "mini_trips.user_id_socio = [i.replace('-','') for i in mini_trips.user_id_socio] # remove all dashes from strings\n",
    "mini_trips = mini_trips.merge(socio_data, on='user_id_socio')\n",
    "\n",
    "print(mini_trips.user_id_socio.nunique(), \"minipilot users with surveys\")\n",
    "print(len(mini_trips), \"trips after pairing with surveys\")\n",
    "\n",
    "mini_trips.to_csv(to_data_folder + \"/minipilot_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd27a69",
   "metadata": {},
   "source": [
    "## Full Pilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d027a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting with  4c\n",
      "14424 trips\n",
      "15 people\n",
      "28 surveys\n",
      "28 surveys after dropping null ids\n",
      "15 surveys 15 users after dropping duplicates\n",
      "12707 trips after merging\n",
      "14 people after merging\n",
      "\n",
      "starting with  cc\n",
      "75199 trips\n",
      "52 people\n",
      "72 surveys\n",
      "72 surveys after dropping null ids\n",
      "50 surveys 50 users after dropping duplicates\n",
      "72275 trips after merging\n",
      "47 people after merging\n",
      "\n",
      "starting with  fc\n",
      "32442 trips\n",
      "30 people\n",
      "47 surveys\n",
      "47 surveys after dropping null ids\n",
      "30 surveys 30 users after dropping duplicates\n",
      "32341 trips after merging\n",
      "29 people after merging\n",
      "\n",
      "starting with  pc\n",
      "51196 trips\n",
      "39 people\n",
      "65 surveys\n",
      "65 surveys after dropping null ids\n",
      "39 surveys 39 users after dropping duplicates\n",
      "50693 trips after merging\n",
      "38 people after merging\n",
      "\n",
      "starting with  sc\n",
      "17989 trips\n",
      "22 people\n",
      "29 surveys\n",
      "29 surveys after dropping null ids\n",
      "15 surveys 15 users after dropping duplicates\n",
      "15565 trips after merging\n",
      "14 people after merging\n",
      "\n",
      "starting with  vail_22\n",
      "9133 trips\n",
      "12 people\n",
      "11 surveys\n",
      "11 surveys after dropping null ids\n",
      "9 surveys 9 users after dropping duplicates\n",
      "7447 trips after merging\n",
      "9 people after merging\n"
     ]
    }
   ],
   "source": [
    "#loop over\n",
    "folders = ['4c', 'cc', 'fc', 'pc', 'sc', 'vail_22']\n",
    "datasets = []\n",
    "\n",
    "for program in folders:\n",
    "    print('\\nstarting with ', program)\n",
    "    \n",
    "    #create dataset with surveys and trips\n",
    "    trips = pd.read_csv(to_data_parent + '/' + program + '/analysis_confirmed_trip.csv')\n",
    "    print(len(trips), 'trips')\n",
    "    print(trips.perno.nunique(), 'people')\n",
    "\n",
    "    surveys = pd.read_csv(to_data_parent + '/' + program + '/' + program + '_survey_household.csv')\n",
    "    print(len(surveys), 'surveys')\n",
    "\n",
    "    #drop any null ids\n",
    "    socio_data = surveys[~surveys['unique_user_id_autofilled_do_not_edit'].isnull()]\n",
    "    print(len(socio_data), 'surveys after dropping null ids')\n",
    "\n",
    "    #drop duplicates\n",
    "    socio_data = socio_data.sort_values(by=['unique_user_id_autofilled_do_not_edit', 'timestamp'])\n",
    "    socio_data.drop_duplicates(subset=['unique_user_id_autofilled_do_not_edit'], keep='last', inplace=True)\n",
    "    print(len(socio_data),'surveys', socio_data['unique_user_id_autofilled_do_not_edit'].nunique(), 'users after dropping duplicates')\n",
    "\n",
    "    #prepare survey ids for merging\n",
    "    socio_data['user_id_socio'] = socio_data['unique_user_id_autofilled_do_not_edit'].astype(str)\n",
    "    socio_data['user_id_socio'] = socio_data['user_id_socio'].str.strip() #remove leading or trailing whitespace!!\n",
    "    socio_data['user_id_socio'] = socio_data['user_id_socio']\n",
    "    socio_data = socio_data.drop(labels='unique_user_id_autofilled_do_not_edit', axis=1)\n",
    "    \n",
    "    \n",
    "    #prepare trip ids for merging\n",
    "    trips['user_id_socio'] = trips.perno.astype(str)\n",
    "    trips['user_id_socio'] = trips['user_id_socio'].str.strip() #remove leading or trailing whitespace!!\n",
    "    trips.user_id_socio = [i.replace('-','') for i in trips.user_id_socio] # remove all dashes from strings\n",
    "    \n",
    "    #merge the data\n",
    "    data = trips.merge(socio_data, on='user_id_socio')\n",
    "    print(len(data), 'trips after merging')\n",
    "    print(data.user_id_socio.nunique(), 'people after merging')\n",
    "    \n",
    "    data['program'] = program.split('_')[0]\n",
    "    \n",
    "    #add to list of datasets\n",
    "    datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd1424cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191028 trips\n",
      "151 users\n"
     ]
    }
   ],
   "source": [
    "#merge them all together\n",
    "full_data = pd.concat(datasets)\n",
    "print(len(full_data), 'trips')\n",
    "print(full_data.perno.nunique(), 'users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5179563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75689 labeled trips\n",
      "147 users who labeled\n"
     ]
    }
   ],
   "source": [
    "#filter out unlabeled trips -- accept partial labels -- needed for proper user count\n",
    "labeled_data = full_data[full_data.data_user_input_mode_confirm.notna() | \n",
    "                         full_data.data_user_input_purpose_confirm.notna() |\n",
    "                         full_data.data_user_input_replaced_mode.notna()]\n",
    "\n",
    "print(len(labeled_data), 'labeled trips')\n",
    "print(labeled_data.user_id_socio.nunique(), 'users who labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd2824b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3087769200.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data.rename(columns={'user_id_socio':'user_id',\n"
     ]
    }
   ],
   "source": [
    "labeled_data.rename(columns={'user_id_socio':'user_id',\n",
    "                          'please_identify_which_category_represents_your_total_household_':'HHINC',\n",
    "                          'how_many_motor_vehicles_are_owned_leased_or_available_for_regul':'VEH',\n",
    "                            ' how_many_motor_vehicles_are_owned_leased_or_available_for_regul':'VEH',\n",
    "                             'how_many_motor_vehicles_are_owned_leased_or_available_for_regul ':'VEH',\n",
    "                           'in_which_year_were_you_born?':'AGE',\n",
    "                          'including_yourself_how_many_people_live_in_your_home?':'HHSIZE',\n",
    "                          'how_many_children_under_age_18_live_in_your_home?':'CHILDREN',\n",
    "                          'what_is_your_gender?':'GENDER',\n",
    "                          'if_you_were_unable_to_use_your_household_vehicles_which_of_the_':'available_modes',\n",
    "                          'are_you_a_student?':'STUDENT',\n",
    "                         'data_duration':'duration', \n",
    "                         'data_distance':'distance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d08302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 users in 4c\n",
      "4458 trips in 4c\n",
      "46 users in cc\n",
      "28058 trips in cc\n",
      "29 users in fc\n",
      "11751 trips in fc\n",
      "36 users in pc\n",
      "17767 trips in pc\n",
      "14 users in sc\n",
      "8432 trips in sc\n",
      "9 users in vail\n",
      "5223 trips in vail\n"
     ]
    }
   ],
   "source": [
    "data = labeled_data.copy()\n",
    "programs = [\"4c\", \"cc\", \"fc\", \"pc\", \"sc\", \"vail\"]\n",
    "returned_dfs = separate_and_count_programs(data, programs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4826b",
   "metadata": {},
   "source": [
    "so far so good, we're looking for at least 122 users and at least 61,496 trips after ALL cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9ab2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labeled_data.copy()\n",
    "\n",
    "#first, add the cleaned mode\n",
    "data['Mode_confirm']= data['data_user_input_mode_confirm'].map(dic_re)\n",
    "\n",
    "#second, add the cleaned replaced mode ASSUMES PROGRAM\n",
    "data['Replaced_mode']= data['data_user_input_replaced_mode'].map(dic_re)\n",
    "\n",
    "#third, add the cleaned purpose\n",
    "data['Trip_purpose']= data['data_user_input_purpose_confirm'].map(dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157dc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data for later\n",
    "data.to_csv(to_data_folder + \"/expanded_ct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0a6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'data_start_local_dt_year':'year','data_start_local_dt_month':'month','data_start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "\n",
    "# Fix age (birth year to age)\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Number of workers (size of HH - kids)\n",
    "data['WORKERS'] = data['HHSIZE'] - data['CHILDREN']\n",
    "\n",
    "# Duration in minutes (hours to minutes)\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# duration in miles (meters to miles)\n",
    "data['distance_miles'] = data['distance'] * 0.0006213712\n",
    "\n",
    "# E-bike/not E-Bike variable\n",
    "data['is_ebike'] = \"E-Bike Trips\"\n",
    "data.loc[data['Mode_confirm']!=\"E-bike\", 'is_ebike'] = \"Non E-Bike Trips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc12fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75689 trips\n",
      "147 users\n",
      "68483 trips after dropping non responses\n",
      "135 users after dropping non responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/3002470374.py:40: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data.mode_confirm = pd.Categorical(data.data_user_input_mode_confirm, ordered=True, categories=np.unique(list(dic_re.keys())))\n"
     ]
    }
   ],
   "source": [
    "print(len(data), \"trips\")\n",
    "print(data.user_id.nunique(), \"users\")\n",
    "\n",
    "#loose some users that did not give this information (and their trips)\n",
    "#records that had ’prefer not to say’ as a response for household income, household vehicles, and other available modes\n",
    "data = data[~data['HHINC'].isin(['Prefer not to say'])]\n",
    "data = data[~data['VEH'].isin(['Prefer not to say / Prefiero no decir.'])]\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "\n",
    "print(len(data), \"trips after dropping non responses\")\n",
    "print(data.user_id.nunique(), \"users after dropping non responses\")\n",
    "\n",
    "data['HHINC_NUM'] = data.HHINC.replace(['Less than $24,999',\n",
    "                                       '$25,000-$49,999',\n",
    "                                       '$50,000-$99,999',\n",
    "                                       '$100,000 -$149,999',\n",
    "                                       '$150,000-$199,999',\n",
    "                                       '$200,000 or more'], [12500,37500,75000,125000,175000,250000])\n",
    "\n",
    "# Calculate average income per adult in the household\n",
    "data['PINC'] = data['HHINC_NUM'] / data['WORKERS']\n",
    "\n",
    "# Combine variable categories\n",
    "data = data.replace('Gas Car, drove alone', 'Car')\n",
    "data = data.replace('Gas Car, with others', 'Shared Car')\n",
    "data = data.replace('Bikeshare', 'Shared Micromobility')\n",
    "data = data.replace('Scooter share', 'Shared Micromobility')\n",
    "data = data.replace('Regular Bike', 'Personal Micromobility')\n",
    "data = data.replace('Skate board', 'Personal Micromobility')\n",
    "data = data.replace('Train', 'Transit')\n",
    "data = data.replace('Free Shuttle', 'Transit')\n",
    "data = data.replace('Bus', 'Transit')\n",
    "data = data.replace('Walk', 'Walk')\n",
    "data = data.replace('Taxi/Uber/Lyft', 'Ridehail')\n",
    "data = data.replace('Pilot ebike', 'E-Bike')\n",
    "\n",
    "# Categorical type will include all days/modes in groupby even if there is no data for a particular tabulation\n",
    "data.user_id = pd.Categorical(data.user_id)\n",
    "data.date_time = pd.Categorical(data.date_time)\n",
    "data.mode_confirm = pd.Categorical(data.data_user_input_mode_confirm, ordered=True, categories=np.unique(list(dic_re.keys())))\n",
    "\n",
    "# Add order to categorical variables\n",
    "data.HHINC = pd.Categorical(data.HHINC, ordered=True)\n",
    "data['Mode'] = pd.Categorical(data.Mode_confirm, ordered=True, categories=[\n",
    "    'E-bike',\n",
    "    'Car',\n",
    "    'Shared Car',\n",
    "    'Walk',\n",
    "    'Transit',\n",
    "    'Personal Micromobility',\n",
    "    'Shared Micromobility',\n",
    "    'Ridehail',\n",
    "    'Other'])\n",
    "data.VEH = data.VEH.astype(str)\n",
    "data.VEH = pd.Categorical(data.VEH, ordered=True, categories=['0','1','2','3','4+'])\n",
    "data['PINC_NUM'] = data['PINC']\n",
    "data.PINC = pd.cut(data.PINC, bins=[0,10000,20000,30000,40000,50000,60000,70000,999999],\n",
    "                  labels=[\"$0-9\",\n",
    "                         \"$10-19\",\n",
    "                         \"$20-29\",\n",
    "                         \"$30-39\",\n",
    "                         \"$40-49\",\n",
    "                         \"$50-59\",\n",
    "                         \"$60-69\",\n",
    "                         \"$70+\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7269e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered out ages that were greater than 100\n",
    "data = data[data['AGE'] < 100]\n",
    "\n",
    "#filter out durations longer than 8 hours\n",
    "data = data[data['duration']<480]\n",
    "\n",
    "#distances more than 50 miles \n",
    "data = data[data['distance_miles']<50]\n",
    "\n",
    "#filter household sizes smaller than the number of kids\n",
    "data = data[data['HHSIZE']>data['CHILDREN']]\n",
    "\n",
    "#filter out households greater than 10\n",
    "data = data[data['HHSIZE']<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f547dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63999 trips after filtering\n",
      "132 users after filtering\n"
     ]
    }
   ],
   "source": [
    "# Vehicles per driver\n",
    "data = data[data['VEH'].notna()] #vails VEH nums were not strings?\n",
    "data['VEH_num'] = data['VEH'].replace(['1','2','3','4+'],[1,2,3,4]).astype(int)\n",
    "data['DRIVERS'] = data[\"including_yourself_how_many_people_have_a_driver's_license_in_y\"]\n",
    "data['DRIVERS_num'] = data['DRIVERS'].replace\n",
    "data['veh_per_driver'] = (data['VEH_num'] / data['DRIVERS']).fillna(0)\n",
    "data.loc[data['veh_per_driver']==np.inf, 'veh_per_driver'] = 0\n",
    "\n",
    "#filter out 'not a trip' trips\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip'])]\n",
    "data = data[~data['Replaced_mode'].isin(['Not a Trip'])]\n",
    "data = data[~data['Trip_purpose'].isin(['not_a_trip'])]\n",
    "\n",
    "print(len(data), 'trips after filtering') #around 63,000\n",
    "print(data.user_id.nunique(), 'users after filtering') #132"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3da64",
   "metadata": {},
   "source": [
    "# filtering out trips before first e-bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2762330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 users in 4c\n",
      "3358 trips in 4c\n",
      "43 users in cc\n",
      "25410 trips in cc\n",
      "26 users in fc\n",
      "10952 trips in fc\n",
      "32 users in pc\n",
      "13071 trips in pc\n",
      "13 users in sc\n",
      "6887 trips in sc\n",
      "8 users in vail\n",
      "4321 trips in vail\n",
      "processing ['4c']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 users before filtering\n",
      "10 users who traveled by ebike\n",
      "processing ['cc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 users before filtering\n",
      "42 users who traveled by ebike\n",
      "processing ['fc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 users before filtering\n",
      "22 users who traveled by ebike\n",
      "processing ['pc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 users before filtering\n",
      "29 users who traveled by ebike\n",
      "processing ['sc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 users before filtering\n",
      "11 users who traveled by ebike\n",
      "processing ['vail']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/src/app/saved-notebooks/PaperVizualizations/Abby/data_utilities.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  program_df['start_ts']= pd.to_datetime(program_df['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 users before filtering\n",
      "8 users who traveled by ebike\n",
      "10 users in 4c\n",
      "2242 trips in 4c\n",
      "42 users in cc\n",
      "25152 trips in cc\n",
      "22 users in fc\n",
      "10656 trips in fc\n",
      "29 users in pc\n",
      "12619 trips in pc\n",
      "11 users in sc\n",
      "6516 trips in sc\n",
      "8 users in vail\n",
      "4314 trips in vail\n",
      "61499 trips in combined df\n",
      "122 users in combined df\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns = {'data_start_ts':'start_ts'}, inplace=True)\n",
    "\n",
    "programs = [\"4c\", \"cc\", \"fc\", \"pc\", \"sc\", \"vail\"]\n",
    "program_dfs = separate_and_count_programs(data, programs)\n",
    "\n",
    "#filtering each of them\n",
    "from datetime import datetime\n",
    "\n",
    "after_ebike_dfs = []\n",
    "for program_df in program_dfs:\n",
    "    print(\"processing\", program_df.program.unique())\n",
    "    after_first_ebike_trips = filter_before_ebike(program_df)\n",
    "    after_ebike_dfs.append(after_first_ebike_trips)\n",
    "    \n",
    "#combining the filtered datasets\n",
    "filtered_merged = pd.concat(after_ebike_dfs, axis=0)\n",
    "\n",
    "#check number of trips and users\n",
    "separate_and_count_programs(filtered_merged, programs)\n",
    "\n",
    "print(len(filtered_merged), \"trips in combined df\") #\n",
    "print(filtered_merged['user_id'].nunique(), \"users in combined df\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b5e0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61499.000000</td>\n",
       "      <td>61499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6342.273239</td>\n",
       "      <td>24.148134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9654.301203</td>\n",
       "      <td>30.704004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.021226</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1163.724712</td>\n",
       "      <td>9.174054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3199.192205</td>\n",
       "      <td>15.289935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7003.226418</td>\n",
       "      <td>28.071791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80444.735420</td>\n",
       "      <td>479.495935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           distance      duration\n",
       "count  61499.000000  61499.000000\n",
       "mean    6342.273239     24.148134\n",
       "std     9654.301203     30.704004\n",
       "min      100.021226      0.000068\n",
       "25%     1163.724712      9.174054\n",
       "50%     3199.192205     15.289935\n",
       "75%     7003.226418     28.071791\n",
       "max    80444.735420    479.495935"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary statistics table\n",
    "stat_data = filtered_merged[['distance','duration']]\n",
    "stat_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a csv, to be used as input to analysis!\n",
    "filtered_merged.to_csv(to_data_folder + \"/tsdc_filtered_merged_trips.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
