{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate calibration of phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook retrieves the calibration results for a particular experiment and validates them. It does so during the experiment so that we can bail if it turns out that the experiment is not working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to run experiments, you only need to edit these variables. The notebook will retrieve the appropriate spec, use it to find the calibration periods from the database and validate the calibration. You probably want to publish this notebook along with your results so that others can examine it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASTORE_URL = \"http://cardshark.cs.berkeley.edu\"\n",
    "AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\"\n",
    "CURR_SPEC_ID = \"sfba_trial_3\"\n",
    "CURR_TRIP_ID = \"high_accuracy_stationary\"\n",
    "MAX_DURATION_VARIATION = 5 * 60 # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import arrow\n",
    "import pandas as pd\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.plugins as fpl\n",
    "import branca.element as bre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some simple utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(n_maps, cols):\n",
    "    rows = int(n_maps / cols)\n",
    "    if (n_maps % cols != 0):\n",
    "        rows = rows + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the ability to make calls to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_from_server(user_label, key_list, start_ts, end_ts):\n",
    "    post_msg = {\n",
    "        \"user\": user_label,\n",
    "        \"key_list\": key_list,\n",
    "        \"start_time\": start_ts,\n",
    "        \"end_time\": end_ts\n",
    "    }\n",
    "    # print(\"About to retrieve messages using %s\" % post_msg)\n",
    "    response = requests.post(DATASTORE_URL+\"/datastreams/find_entries/timestamp\", json=post_msg)\n",
    "    # print(\"response = %s\" % response)\n",
    "    response.raise_for_status()\n",
    "    ret_list = response.json()[\"phone_data\"]\n",
    "    # print(\"Found %d entries\" % len(ret_list))\n",
    "    return ret_list\n",
    "\n",
    "def retrieve_all_data_from_server(user_label, key_list):\n",
    "    return retrieve_data_from_server(user_label, key_list, 0, arrow.get().timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the current spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spec_entry_list = retrieve_all_data_from_server(AUTHOR_EMAIL, [\"config/evaluation_spec\"])\n",
    "curr_spec_entry = None\n",
    "for s in all_spec_entry_list:\n",
    "    if s[\"data\"][\"label\"][\"id\"] == CURR_SPEC_ID:\n",
    "        curr_spec_entry = s\n",
    "curr_spec_wrapper = curr_spec_entry[\"data\"]\n",
    "curr_spec = curr_spec_wrapper[\"label\"]\n",
    "curr_spec[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all evaluation transitions within the start and end times of this spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_start_ts = curr_spec_wrapper[\"start_ts\"]\n",
    "eval_end_ts = curr_spec_wrapper[\"end_ts\"]\n",
    "print(\"Evaluation ran from %s -> %s\" % (arrow.get(eval_start_ts), arrow.get(eval_end_ts)))\n",
    "phone_labels = curr_spec[\"phones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data model here is:\n",
    "\n",
    "```\n",
    "eval_transitions\n",
    "    - android\n",
    "        - ucb.sdb.android.1\n",
    "            - list of evaluation transitions\n",
    "        - ....\n",
    "    - ios\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transitions = copy.copy(phone_labels)\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Reading data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        print(\"Loading transitions for phone %s\" % phone_label)\n",
    "        curr_phone_transitions = retrieve_data_from_server(phone_label, [\"manual/evaluation_transition\"], eval_start_ts, eval_end_ts)\n",
    "        phone_map[phone_label] = {}\n",
    "        phone_map[phone_label][\"transitions\"] = curr_phone_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find calibration transitions, validate and map them to ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards, we will add the results of manipulation to each phone entry - e.g.\n",
    "\n",
    "```\n",
    "eval_transitions\n",
    "    - android\n",
    "        - ucb.sdb.android.1\n",
    "            - transitions (all transition entries, added in previous step)\n",
    "            - calibration_transitions (calibration transitions, will be added in this step)\n",
    "        - ....\n",
    "    - ios\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        print(\"Processing transitions for phone %s\" % phone_label)\n",
    "        curr_phone_transitions = [t[\"data\"] for t in phone_map[phone_label][\"transitions\"]]\n",
    "        # print(curr_phone_transitions)\n",
    "        curr_calibration_transitions = [t for t in curr_phone_transitions if t[\"transition\"] in [\"START_CALIBRATION_PERIOD\", \"STOP_CALIBRATION_PERIOD\", 0, 1]]\n",
    "        print(\"Filtered %d total -> %d calibration transitions \" % (len(curr_phone_transitions), len(curr_calibration_transitions)))\n",
    "        phone_map[phone_label][\"calibration_transitions\"] = curr_calibration_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_1_transitions = eval_transitions[\"ios\"][\"ucb-sdb-ios-1\"][\"calibration_transitions\"]\n",
    "[(t[\"transition\"], arrow.get(t[\"ts\"])) for t in ios_1_transitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect that the transition will be odd, since the existing test will not have a stop\n",
    "def transitions_to_ranges(transition_list):\n",
    "    if len(transition_list) % 2 != 1:\n",
    "        print(\"Transitions occur in pairs, but so for the current trip the transition count (%d) must be odd, returning empty list\" % len(transition_list))\n",
    "        return []\n",
    "    s = transition_list[-1]\n",
    "    curr_ts = arrow.get().timestamp\n",
    "    range_list = []\n",
    "    # print(\"------------------------------------- \\n %s -> \\n %s\" % (s, e))\n",
    "    assert s[\"transition\"] == \"START_CALIBRATION_PERIOD\" or s[\"transition\"] == 0, \"Start transition has %s transition\" % s[\"transition\"]\n",
    "    assert s[\"trip_id\"] == CURR_TRIP_ID, \"Last start transition is for %s, expected %s\" % (s[\"trip_id\"], CURR_TRIP_ID)\n",
    "    assert curr_ts > s[\"ts\"], \"end %s is before start %s\" % (arrow.get(e[\"ts\"]), arrow.get(s[\"ts\"]))\n",
    "    curr_range = {\"trip_id\": s[\"trip_id\"], \"start_ts\": s[\"ts\"], \"end_ts\": curr_ts, \"duration\": (curr_ts - s[\"ts\"])}\n",
    "    range_list.append(curr_range)\n",
    "    return range_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_to_ranges(eval_transitions[\"ios\"][\"ucb-sdb-ios-1\"][\"calibration_transitions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_calibration_ranges = transitions_to_ranges(phone_map[phone_label][\"calibration_transitions\"])\n",
    "        print(\"Found %d ranges for phone %s\" % (len(curr_calibration_ranges), phone_label))\n",
    "        phone_map[phone_label][\"calibration_ranges\"] = curr_calibration_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the ranges for individual phones\n",
    "\n",
    "This involves two main checks:\n",
    "- that we have at least one calibration range for each test in the spec. Note that we do not currently enforce that we have exactly one calibration range for each test, on the theory that more calibration is always good. But I am open to argument about this\n",
    "- that the settings in the calibration range are consistent with the spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_config_map = {}\n",
    "for ct in curr_spec[\"calibration_tests\"]:\n",
    "    expected_config_map[ct[\"id\"]] = ct[\"config\"][\"sensing_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current accuracy constants\n",
    "# Since we can't read these from the phone, we hardcoded them from the documentation\n",
    "# If there are validation failures, these need to be updated\n",
    "# In the future, we could upload the options from the phone (maybe the accuracy control)\n",
    "# but that seems like overkill here\n",
    "\n",
    "accuracy_options = {\n",
    "    \"android\": {\n",
    "        \"PRIORITY_HIGH_ACCURACY\": 100,\n",
    "        \"PRIORITY_BALANCED_POWER_ACCURACY\": 102,\n",
    "        \"PRIORITY_LOW_POWER\": 104,\n",
    "        \"PRIORITY_NO_POWER\": 105\n",
    "    },\n",
    "    \"ios\": {\n",
    "        \"kCLLocationAccuracyBestForNavigation\": -2,\n",
    "        \"kCLLocationAccuracyBest\": -1,\n",
    "        \"kCLLocationAccuracyNearestTenMeters\": 10,\n",
    "        \"kCLLocationAccuracyHundredMeters\": 100,\n",
    "        \"kCLLocationAccuracyKilometer\": 1000,\n",
    "        \"kCLLocationAccuracyThreeKilometers\": 3000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_array_idx = lambda phoneOS: 0 if phoneOS == \"android\" else 1\n",
    "\n",
    "def validate_filter(phoneOS, config_during_test, expected_config):\n",
    "    # filter checking is a bit tricky because the expected value has two possible values and the real config has two possible values\n",
    "    expected_filter = expected_config[\"filter\"]\n",
    "    if type(expected_filter) == int:\n",
    "        ev = expected_filter\n",
    "    else:\n",
    "        assert type(expected_filter) == list, \"platform specific filters should be specified in array, not %s\" % expected_filter\n",
    "        ev = expected_filter[opt_array_idx(phoneOS)]\n",
    "        \n",
    "    if phoneOS == \"android\":\n",
    "        cvf = \"filter_time\"\n",
    "    elif phoneOS == \"ios\":\n",
    "        cvf = \"filter_distance\"\n",
    "        \n",
    "    assert config_during_test[cvf] == ev, \"Field filter mismatch! %s != %s\" % (config_during_test, expected_config)\n",
    "    \n",
    "def validate_accuracy(phoneOS, config_during_test, expected_config):\n",
    "    # expected config accuracy is an array of strings [\"PRIORITY_BALANCED_POWER_ACCURACY\", \"kCLLocationAccuracyNearestTenMeters\"]\n",
    "    # so we find the string at the correct index and then map it to the value from the options\n",
    "    ev = accuracy_options[phoneOS][expected_config[\"accuracy\"][opt_array_idx(phoneOS)]]\n",
    "    assert config_during_test[\"accuracy\"] == ev, \"Field accuracy mismatch! %s != %s\" % (config_during_test[accuracy], ev)\n",
    "\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        all_test_ids = [r[\"trip_id\"] for r in curr_calibration_ranges]\n",
    "        unique_test_ids = sorted(list(set(all_test_ids)))\n",
    "        spec_test_ids = sorted([ct[\"id\"] for ct in curr_spec[\"calibration_tests\"]])\n",
    "        # assert unique_test_ids == spec_test_ids, \"Missing calibration test while comparing %s, %s\" % (unique_test_ids, spec_test_ids)\n",
    "        for r in curr_calibration_ranges:\n",
    "            config_during_test_entries = retrieve_data_from_server(phone_label, [\"config/sensor_config\"], r[\"start_ts\"], r[\"end_ts\"])\n",
    "            assert len(config_during_test_entries) == 1, \"Out of band configuration? Found %d config changes\" % len(config_during_test_entries)\n",
    "            config_during_test = config_during_test_entries[0][\"data\"]\n",
    "            expected_config = expected_config_map[r[\"trip_id\"]]\n",
    "            # print(config_during_test, expected_config)\n",
    "            validate_filter(phoneOS, config_during_test, expected_config)\n",
    "            validate_accuracy(phoneOS, config_during_test, expected_config)\n",
    "            for f in expected_config:\n",
    "                if f != \"accuracy\" and f != \"filter\":\n",
    "                    assert config_during_test[f] == expected_config[f], \"Field %s mismatch! %s != %s\" % (f, config_during_test[f], expected_config[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate ranges across phones\n",
    "\n",
    "This effectively has one test right now - is the duration of the tests across phones consistent?\n",
    "TODO: We should add a reasonable fuzz factor based on real calibration.\n",
    "\n",
    "We are going to create a pandas dataframe with the following structure\n",
    "\n",
    "```\n",
    "                    android_<phone_1> android_<phone_2> android_<phone_3> ....\n",
    "<trip_id_1>\n",
    "<trip_id_2>\n",
    "...\n",
    "```\n",
    "\n",
    "Then, we can transpose it to get\n",
    "\n",
    "```\n",
    "                    <trip_id_1> <trip_id_2> <trip_id_3> ....\n",
    "android_<phone_1>\n",
    "android_<phone_2>\n",
    "...\n",
    "```\n",
    "\n",
    "then, we can get a series of durations for each `trip_id` as a series and compare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_map = {}\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_duration_map = {}\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            curr_phone_duration_map[r[\"trip_id\"]] = r[\"duration\"]\n",
    "        duration_map[phoneOS+\"_\"+phone_label] = curr_phone_duration_map\n",
    "        \n",
    "duration_df = pd.DataFrame(duration_map).transpose()\n",
    "duration_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are not statistical samples, the regular standard deviation/variation don't have much meaning. The variation is really caused by human control of the evaluation start/stop and the durations should be within a few minutes of each other. The expected variation defined in `MAX_DURATION_VARIATION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_variation = duration_df[CURR_TRIP_ID] - duration_df[CURR_TRIP_ID].median(); duration_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert duration_variation.abs().max() < MAX_DURATION_VARIATION,\\\n",
    "    \"INVALID: duration_variation.abs().max() > threshold\" % (duration_variation.abs().max(), MAX_DURATION_VARIATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Battery drain over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the format\n",
    "\n",
    "```\n",
    "android:\n",
    "    - <phone_1>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "    - <phone_2>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "...\n",
    "ios:\n",
    "    - <phone_1>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "    - <phone_2>:\n",
    "        - <trip_id>\n",
    "          - dataframe with index = ts, columns = other fields\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            battery_entries = retrieve_data_from_server(phone_label, [\"background/battery\"], r[\"start_ts\"], r[\"end_ts\"])\n",
    "            # ios entries before running the pipeline are marked with battery_level_ratio, which is a float from 0 ->1\n",
    "            # convert it to % to be consistent with android and easier to understand\n",
    "            if phoneOS == \"ios\":\n",
    "                for e in battery_entries:\n",
    "                    if \"battery_level_pct\" not in e[\"data\"]:\n",
    "                        e[\"data\"][\"battery_level_pct\"] = e[\"data\"][\"battery_level_ratio\"] * 100\n",
    "                        del e[\"data\"][\"battery_level_ratio\"]\n",
    "            battery_df = pd.DataFrame([e[\"data\"] for e in battery_entries])\n",
    "            battery_df[\"hr\"] = (battery_df.ts-r[\"start_ts\"])/3600.0\n",
    "            if phoneOS == \"ios\":\n",
    "                battery_df[\"battery_level_pct\"] = battery_df.battery_level_ratio * 100\n",
    "            r[\"battery_df\"] = battery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_battery_df = eval_transitions[\"ios\"][\"ucb-sdb-ios-1\"][\"calibration_ranges\"][0][\"battery_df\"]; test_battery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curves(ax, phone_map):\n",
    "    for phone_label in phone_map:\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            battery_df = r[\"battery_df\"]\n",
    "            ret_axes = battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=phone_label+\"_\"+r[\"trip_id\"], ylim=(0,100), sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure((16,6))\n",
    "android_axes = fig.add_subplot(1,2,1)\n",
    "ios_axes = fig.add_subplot(1,2,2)\n",
    "plot_calibration_curves(ios_axes, eval_transitions[\"ios\"])\n",
    "plot_calibration_curves(android_axes, eval_transitions[\"android\"])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location points over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we download the location points and check to see that the density is largely consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            all_done = False\n",
    "            location_entries = []\n",
    "            curr_start_ts = r[\"start_ts\"]\n",
    "            prev_retrieved_count = 0\n",
    "\n",
    "            while not all_done:\n",
    "                print(\"About to retrieve data for %s from %s -> %s\" % (phone_label, curr_start_ts, r[\"end_ts\"]))\n",
    "                curr_location_entries = retrieve_data_from_server(phone_label, [\"background/location\"], curr_start_ts, r[\"end_ts\"])\n",
    "                print(\"Retrieved %d entries with timestamps %s...\" % (len(curr_location_entries), [cle[\"data\"][\"ts\"] for cle in curr_location_entries[0:10]]))\n",
    "                if len(curr_location_entries) == 0 or len(curr_location_entries) == 1 or len(curr_location_entries) == prev_retrieved_count:\n",
    "                    all_done = True\n",
    "                else:\n",
    "                    location_entries.extend(curr_location_entries)\n",
    "                    curr_start_ts = curr_location_entries[-1][\"data\"][\"ts\"]\n",
    "                    prev_retrieved_count = len(curr_location_entries)\n",
    "            location_df = pd.DataFrame([e[\"data\"] for e in location_entries])\n",
    "            location_df[\"hr\"] = (location_df.ts-r[\"start_ts\"])/3600.0\n",
    "            r[\"location_df\"] = location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_map = {}\n",
    "for phoneOS, phone_map in eval_transitions.items():\n",
    "    print(\"Processing data for %s phones\" % phoneOS)\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_count_map = {}\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            curr_phone_count_map[r[\"trip_id\"]] = len(r[\"location_df\"])\n",
    "        count_map[phoneOS+\"_\"+phone_label] = curr_phone_count_map\n",
    "        \n",
    "count_df = pd.DataFrame(count_map).transpose()\n",
    "count_df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_density_df(phone_map, sel_trip_id):\n",
    "    density_map = {}\n",
    "    for phone_label in phone_map:\n",
    "        curr_phone_density_map = {}\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            if r[\"trip_id\"] == CURR_TRIP_ID:\n",
    "                density_map[phone_label] = r[\"location_df\"].hr\n",
    "        \n",
    "    density_df = pd.DataFrame(density_map)\n",
    "    return density_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "android_density_df = get_location_density_df(eval_transitions[\"android\"], CURR_TRIP_ID)\n",
    "nRows = get_row_count(len(eval_transitions[\"android\"].keys()), 2)\n",
    "print(nRows)\n",
    "android_density_df.plot(kind='density', subplots=True, layout=(nRows, 2), figsize=(10,10), sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_vs_power_curves(fig, nRows, phone_map, sel_trip_id):\n",
    "    for i, phone_label in enumerate(phone_map.keys()):\n",
    "        ax = fig.add_subplot(nRows, 2, i+1)\n",
    "        curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "        for r in curr_calibration_ranges:\n",
    "            if r[\"trip_id\"] == CURR_TRIP_ID:\n",
    "                battery_df = r[\"battery_df\"]\n",
    "                location_df = r[\"location_df\"]\n",
    "                battery_df.plot(x=\"hr\", y=\"battery_level_pct\", ax=ax, label=phone_label, sharex=True, sharey=True)\n",
    "                location_df.hr.plot(ax=ax, kind=\"density\", secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure((16, 16))\n",
    "plot_density_vs_power_curves(fig, nRows, eval_transitions[\"android\"], \"high_accuracy\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_density_df = get_location_density_df(eval_transitions[\"ios\"], \"high_accuracy\")\n",
    "nRows = get_row_count(len(eval_transitions[\"ios\"].keys()), 2)\n",
    "print(nRows)\n",
    "ios_density_df.plot(kind='density', subplots=True, layout=(nRows, 2), figsize=(10,10), sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure((16, 16))\n",
    "plot_density_vs_power_curves(fig, nRows, eval_transitions[\"ios\"], \"high_accuracy\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location points over space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_list_for_trip(sel_trip_id):\n",
    "    map_list = []\n",
    "    for phoneOS, phone_map in eval_transitions.items():\n",
    "        print(\"Processing data for %s phones\" % phoneOS)\n",
    "        for phone_label in phone_map:\n",
    "            curr_map = folium.Map()\n",
    "            curr_calibration_ranges = phone_map[phone_label][\"calibration_ranges\"]\n",
    "            for r in curr_calibration_ranges:\n",
    "                if r[\"trip_id\"] == sel_trip_id:\n",
    "                    location_df = r[\"location_df\"]\n",
    "                    latlng_route_coords = list(zip(location_df.latitude, location_df.longitude))\n",
    "                    print(latlng_route_coords[0:10])\n",
    "                    pl = folium.PolyLine(latlng_route_coords,\n",
    "                        popup=\"%s: %s\" % (phoneOS, phone_label))\n",
    "                    pl.add_to(curr_map)\n",
    "                    fpl.MarkerCluster(latlng_route_coords).add_to(curr_map)\n",
    "#                    for i, c in enumerate(latlng_route_coords):\n",
    "#                        folium.CircleMarker(c, radius=5, popup=\"%d: %s\" % (i, c)).add_to(curr_map)\n",
    "                    curr_map.fit_bounds(pl.get_bounds())\n",
    "            map_list.append(curr_map)\n",
    "    return map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ha_map_list = get_map_list_for_trip(CURR_TRIP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = get_row_count(len(ha_map_list), 2)\n",
    "evaluation_maps = bre.Figure(ratio=\"100%\")\n",
    "for i, curr_map in enumerate(ha_map_list):\n",
    "    evaluation_maps.add_subplot(rows, 2, i+1).add_child(curr_map)\n",
    "evaluation_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
