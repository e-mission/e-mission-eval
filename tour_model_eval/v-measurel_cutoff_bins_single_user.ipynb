{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aging-evaluation",
   "metadata": {},
   "source": [
    "This notebook is for evaluating bins above cutoff and exploring the data for a single user after first round clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Our imports\n",
    "import emission.core.get_database as edb\n",
    "import emission.analysis.modelling.tour_model.cluster_pipeline as pipeline\n",
    "import emission.analysis.modelling.tour_model.similarity as similarity\n",
    "import emission.analysis.modelling.tour_model.featurization as featurization\n",
    "import emission.analysis.modelling.tour_model.representatives as representatives\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import confirmed_trips_eval_bins_clusters as evaluation\n",
    "from sklearn import metrics\n",
    "from pandas.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_uuid_obj = list(edb.get_profile_db().find({\"install_group\": \"participant\"}, {\"user_id\": 1, \"_id\": 0}))\n",
    "all_users = [u[\"user_id\"] for u in participant_uuid_obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-nomination",
   "metadata": {},
   "source": [
    "## Choose one user for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = all_users[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data from the database. We choose key=esda.CONFIRMED_TRIP_KEY to get confirmed trips here\n",
    "trips = pipeline.read_data(uuid=user,key=esda.CONFIRMED_TRIP_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select trips that have user_input to analyze\n",
    "non_empty_trips = [t for t in trips if t[\"data\"][\"user_input\"] != {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_empty_trips),non_empty_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out trips that are not fully labeled(contain NaN in user_input)\n",
    "non_empty_trips_df = pd.DataFrame(t[\"data\"][\"user_input\"]for t in non_empty_trips)\n",
    "valid_trips_df = non_empty_trips_df.dropna(axis=0,how='any',thresh=None,subset=None,inplace=False)\n",
    "valid_trips_idx_ls = valid_trips_df.index.tolist()\n",
    "valid_trips = [non_empty_trips[i]for i in valid_trips_idx_ls]\n",
    "len(valid_trips),valid_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = similarity.similarity(valid_trips, radius)\n",
    "filter_trips = sim.data\n",
    "sim.bin_data()\n",
    "sim.delete_bins()\n",
    "bin_trips = sim.newdata\n",
    "bins = sim.bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug('The list of bins is %s' % bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-diesel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show all user labels in all bins\n",
    "for bin in bins:\n",
    "    bin_user_input = (filter_trips[i].data[\"user_input\"] for i in bin)\n",
    "    bin_df = pd.DataFrame(data = bin_user_input)\n",
    "    print(bin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-feeling",
   "metadata": {},
   "source": [
    "### Original output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_trips_df = pd.DataFrame(data=[i[\"data\"][\"user_input\"] for i in bin_trips])\n",
    "bin_trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-connectivity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# turn all user_input into list without binning\n",
    "bin_trips_user_input_ls = bin_trips_df.values.tolist()\n",
    "bin_trips_user_input_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-sense",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate user_input\n",
    "no_dup_df=bin_trips_df.drop_duplicates()\n",
    "no_dup_df,len(no_dup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-rings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turn non-duplicate user_input into list\n",
    "no_dup_list = no_dup_df.values.tolist()\n",
    "no_dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_true based on user_input\n",
    "labels_true =[]\n",
    "for trip in bin_trips_user_input_ls:\n",
    "    if trip in no_dup_list:\n",
    "        labels_true.append(no_dup_list.index(trip))\n",
    "labels_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_pred based on bins\n",
    "labels_pred = []\n",
    "for i in range(len(bins)):\n",
    "    for trip in bins[i]:\n",
    "        labels_pred.append(i)\n",
    "labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-welcome",
   "metadata": {},
   "source": [
    "Note: the trips order in labels_true and labels_pred should be the same. Using timestamp to compare the trips in bin_trips and those in bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_trips_ts = pd.DataFrame(data=[trip[\"data\"][\"start_ts\"]for trip in bin_trips])\n",
    "bin_input = pd.DataFrame(data=[trip[\"data\"][\"user_input\"]for trip in bin_trips])\n",
    "len(bin_trips_ts)\n",
    "bin_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ls =[]\n",
    "for bin in bins:\n",
    "    for index in bin:\n",
    "        bin_ls.append(index)\n",
    "bins_ts = pd.DataFrame(data=[filter_trips[i][\"data\"][\"start_ts\"]for i in bin_ls])\n",
    "bins_input = pd.DataFrame(data=[filter_trips[num][\"data\"][\"user_input\"]for num in bin_ls])\n",
    "len(bins_ts)\n",
    "bins_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare two data frames, return nothing if two data frames are the same\n",
    "assert_frame_equal(bins_ts,bin_trips_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.homogeneity_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.completeness_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-investment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.v_measure_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-baghdad",
   "metadata": {},
   "source": [
    "### After changing language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_eng_dict = {'revisado_bike':'test ride with bike','placas_de carro':'car plates','aseguranza':'insurance',\n",
    " 'iglesia':'church','curso':'course','mi_hija reci√©n aliviada':'my daughter just had a new baby',\n",
    " 'servicio_comunitario':'community service','pago_de aseguranza':'insurance payment',\n",
    " 'grupo_comunitario':'community group','caminata_comunitaria':'community walk'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dict to replace the values in Spanish in the bin(this step just for showing the trips in each bin)\n",
    "for bin in bins:\n",
    "    bin_user_input = (filter_trips[i].data[\"user_input\"] for i in bin)\n",
    "    bin_df = pd.DataFrame(data = bin_user_input)\n",
    "    sp2en_bin_df = bin_df.replace(span_eng_dict)\n",
    "    print(sp2en_bin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn all user_input into list without binning\n",
    "bin_trips_sp2en_df = bin_trips_df.replace(span_eng_dict)\n",
    "bin_trips_sp2en_ls = bin_trips_sp2en_df.values.tolist()\n",
    "bin_trips_sp2en_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-spanish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop duplicate user_input\n",
    "no_dup_sp2en_df=bin_trips_sp2en_df.drop_duplicates()\n",
    "no_dup_sp2en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn non-duplicate user_input into list\n",
    "no_dup_sp2en_list = no_dup_sp2en_df.values.tolist()\n",
    "no_dup_sp2en_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_true based on user_input\n",
    "labels_true_sp2en =[]\n",
    "for trip in bin_trips_sp2en_ls:\n",
    "    if trip in no_dup_sp2en_list:\n",
    "        labels_true_sp2en.append(no_dup_sp2en_list.index(trip))\n",
    "labels_true_sp2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_pred based on bins\n",
    "labels_pred = []\n",
    "for i in range(len(bins)):\n",
    "    for trip in bins[i]:\n",
    "        labels_pred.append(i)\n",
    "labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.homogeneity_score(labels_true_sp2en, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.completeness_score(labels_true_sp2en, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.v_measure_score(labels_true_sp2en, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-heater",
   "metadata": {},
   "source": [
    "### After converting purposes and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pur_dict = {'course':'school','work_- lunch break':'lunch_break','on_the way home':'home',\n",
    "               'insurance_payment':'insurance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert purpose\n",
    "bin_trips_cvt_pur_df = bin_trips_sp2en_df.replace(map_pur_dict)\n",
    "# convert mode\n",
    "bin_trips_cvt_pur_mo_df = bin_trips_cvt_pur_df\n",
    "for i in range(len(bin_trips_cvt_pur_mo_df)):\n",
    "    if bin_trips_cvt_pur_mo_df.iloc[i][\"replaced_mode\"] == \"same_mode\":\n",
    "        print(bin_trips_cvt_pur_mo_df.iloc[i]) # to see which row will be converted\n",
    "        bin_trips_cvt_pur_mo_df.iloc[i][\"replaced_mode\"] = bin_trips_cvt_pur_mo_df.iloc[i]['mode_confirm']\n",
    "print(bin_trips_cvt_pur_mo_df)\n",
    "bin_trips_cvt_pur_mode_ls = bin_trips_cvt_pur_mo_df.values.tolist()\n",
    "bin_trips_cvt_pur_mode_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-position",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate user_input\n",
    "no_dup_cvt_pur_mode_df = bin_trips_cvt_pur_mo_df.drop_duplicates()\n",
    "no_dup_cvt_pur_mode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn non-duplicate user_input into list\n",
    "no_dup_cvt_pur_mo_ls = no_dup_cvt_pur_mode_df.values.tolist()\n",
    "no_dup_cvt_pur_mo_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_true based on user_input\n",
    "labels_true_cvt =[]\n",
    "for trip in bin_trips_cvt_pur_mode_ls:\n",
    "    if trip in no_dup_cvt_pur_mo_ls:\n",
    "        labels_true_cvt.append(no_dup_cvt_pur_mo_ls.index(trip))\n",
    "labels_true_cvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect labels_pred based on bins\n",
    "labels_pred = []\n",
    "for i in range(len(bins)):\n",
    "    for trip in bins[i]:\n",
    "        labels_pred.append(i)\n",
    "labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.homogeneity_score(labels_true_cvt, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.completeness_score(labels_true_cvt, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.v_measure_score(labels_true_cvt, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
